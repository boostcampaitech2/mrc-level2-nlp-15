{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==1.7.1\n",
    "# !pip install transformers==4.11.3\n",
    "# !pip install huggingface-hub==0.0.19\n",
    "# !pip install datasets==1.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BertModel, RobertaModel,\n",
    "    BertPreTrainedModel,\n",
    "    AdamW, get_linear_schedule_with_warmup,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import (\n",
    "    Dataset,\n",
    "    load_from_disk,\n",
    "    concatenate_datasets,\n",
    ")\n",
    "\n",
    "from typing import List\n",
    "from torch.utils.data import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 난수 고정\n",
    "def set_seed(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "set_seed(42) # magic number :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:[1.7.1].\n",
      "device:[cuda:0].\n"
     ]
    }
   ],
   "source": [
    "print (\"PyTorch version:[%s].\"%(torch.__version__))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (\"device:[%s].\"%(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEncoder(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertEncoder, self).__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.init_weights()\n",
    "        classifier_dropout=(\n",
    "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = torch.nn.Dropout(classifier_dropout)\n",
    "        self.linear = torch.nn.Linear(config.hidden_size, 1)\n",
    "      \n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids, \n",
    "            attention_mask=None,\n",
    "            token_type_ids=None\n",
    "        ): \n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        output = self.linear(pooled_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('/opt/ml/data/train_dataset')\n",
    "train_dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSampler(Sampler) :\n",
    "    def __init__(self, data_source, batch_size) :\n",
    "        self.data_source = data_source\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self) :\n",
    "        n = len(self.data_source)\n",
    "        index_list = []\n",
    "        while True :\n",
    "            out = True\n",
    "            for i in range(self.batch_size) :\n",
    "                tmp_data = random.randint(0, n-1)\n",
    "                index_list.append(tmp_data)\n",
    "            for f, s in zip(index_list, index_list[1:]) :\n",
    "                if abs(s-f) <= 2 :\n",
    "                    out = False\n",
    "            if out == True :\n",
    "                break\n",
    "\n",
    "        while True : # 추가 삽입\n",
    "            tmp_data = random.randint(0, n-1)\n",
    "            if (tmp_data not in index_list) and \\\n",
    "                (abs(tmp_data-index_list[-i]) > 2 for i in range(1,self.batch_size+1)) \\\n",
    "            : \n",
    "                index_list.append(tmp_data)\n",
    "            if len(index_list) == n :\n",
    "                break\n",
    "        return iter(index_list)\n",
    "\n",
    "    def __len__(self) :\n",
    "        return len(self.data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwer\n",
    "class DenseRetrieval:\n",
    "    def __init__(self,\n",
    "        args,\n",
    "        dataset,\n",
    "        tokenizer,\n",
    "        cross_encoder,\n",
    "        sampler\n",
    "    ):\n",
    "        \"\"\"\n",
    "        학습과 추론에 사용될 여러 셋업을 마쳐봅시다.\n",
    "        \"\"\"\n",
    "\n",
    "        self.args = args\n",
    "        self.dataset = dataset\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.cross_encoder = cross_encoder\n",
    "        self.sampler = sampler\n",
    "\n",
    "    def train(self, args=None, tokenizer = None):\n",
    "        if args is None:\n",
    "            args = self.args\n",
    "        if tokenizer is None :\n",
    "            tokenizer = self.tokenizer\n",
    "        \n",
    "        tokenized_examples = tokenizer(\n",
    "            self.dataset['question'],\n",
    "            self.dataset['context'],\n",
    "            truncation=\"only_second\",\n",
    "            max_length=512,\n",
    "            stride=128,\n",
    "            return_overflowing_tokens=True,\n",
    "            return_offsets_mapping=True,\n",
    "            # return_token_type_ids=False,  # roberta모델을 사용할 경우 False, bert를 사용할 경우 True로 표기해야합니다.\n",
    "            padding=\"max_length\",\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        train_dataset = TensorDataset(\n",
    "            tokenized_examples['input_ids'],\n",
    "            tokenized_examples['attention_mask'],\n",
    "            tokenized_examples['token_type_ids']\n",
    "        )\n",
    "\n",
    "        sampler = self.sampler(train_dataset, args.per_device_train_batch_size)\n",
    "        train_dataloader = DataLoader(train_dataset,\n",
    "                                      batch_size=args.per_device_train_batch_size,\n",
    "                                      sampler = sampler,\n",
    "                                      drop_last = True)\n",
    "                                      \n",
    "        no_decay = [\"bias\" ,\"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\"params\": [p for n, p in self.cross_encoder.named_parameters() if not any(nd in n for nd in no_decay)], \"weight_decay\": args.weight_decay},\n",
    "            {\"params\": [p for n, p in self.cross_encoder.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "        ]\n",
    "        optimizer = AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=args.learning_rate,\n",
    "            # eps=args.adam_epsilon\n",
    "        )\n",
    "\n",
    "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total)\n",
    "        \n",
    "        self.cross_encoder.zero_grad()\n",
    "        \n",
    "        train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\")\n",
    "        self.cross_encoder.train()\n",
    "        for epoch, _ in enumerate(train_iterator) :\n",
    "            epoch_iterator = tqdm(train_dataloader, desc = 'Iteration')\n",
    "            losses = 0\n",
    "            for step, batch in enumerate(epoch_iterator) :\n",
    "                # if torch.cuda.is_available() :\n",
    "                #     batch = tuple(t.cuda() for t in batch)\n",
    "                \n",
    "                cross_inputs = {\n",
    "                    'input_ids': batch[0],\n",
    "                    'attention_mask' : batch[1],\n",
    "                    'token_type_ids' : batch[2]\n",
    "                }\n",
    "                for k in cross_inputs.keys() :\n",
    "                    cross_inputs[k] = cross_inputs[k].tolist()\n",
    "\n",
    "                new_input_ids = []\n",
    "                new_attention_mask = []\n",
    "                new_token_type_ids = []\n",
    "                for i in range(len(cross_inputs['input_ids'])) :\n",
    "                    sep_index = cross_inputs['input_ids'][i].index(3) # [SEP] token의 index\n",
    "\n",
    "                    for j in range(len(cross_inputs['input_ids'])) :\n",
    "                        query_id = cross_inputs['input_ids'][i][:sep_index]\n",
    "                        query_att = cross_inputs['attention_mask'][i][:sep_index]\n",
    "                        query_tok = cross_inputs['token_type_ids'][i][:sep_index]\n",
    "        \n",
    "                        context_id = cross_inputs['input_ids'][j][sep_index:]\n",
    "                        context_att = cross_inputs['attention_mask'][j][sep_index:]\n",
    "                        context_tok = cross_inputs['token_type_ids'][j][sep_index:]\n",
    "                        query_id.extend(context_id)\n",
    "                        query_att.extend(context_att)\n",
    "                        query_tok.extend(context_tok)\n",
    "                        new_input_ids.append(query_id)\n",
    "                        new_attention_mask.append(query_att)\n",
    "                        new_token_type_ids.append(query_tok)\n",
    "\n",
    "                change_cross_inputs = {\n",
    "                    'input_ids' : torch.tensor(new_input_ids).to('cuda'),\n",
    "                    'attention_mask' : torch.tensor(new_attention_mask).to('cuda'),\n",
    "                    'token_type_ids' : torch.tensor(new_token_type_ids).to('cuda')\n",
    "                }\n",
    "\n",
    "                cross_output = self.cross_encoder(**change_cross_inputs)\n",
    "                cross_output = cross_output.view(-1, args.per_device_train_batch_size)\n",
    "                targets = torch.arange(0, args.per_device_train_batch_size).long()\n",
    "                                \n",
    "                if torch.cuda.is_available():\n",
    "                    targets = targets.to('cuda')\n",
    "\n",
    "                score = F.log_softmax(cross_output, dim = 1)\n",
    "                loss = F.nll_loss(score, targets)\n",
    "                #########################No ACCUMULATION#########################\n",
    "                # losses += loss.item()\n",
    "                # if step % 100 == 0 :\n",
    "                #     print(f'{epoch}epoch loss: {losses/(step+1)}') # Accumulation할 경우 주석처리\n",
    "                \n",
    "                # self.cross_encoder.zero_grad()\n",
    "                # loss.backward()\n",
    "                # optimizer.step()\n",
    "                # scheduler.step()\n",
    "                #################################################################\n",
    "\n",
    "                #############################ACCUMULATION#########################\n",
    "                loss.backward()\n",
    "                if (step+1) % args.gradient_accumulation_steps == 0 :\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()\n",
    "                    self.cross_encoder.zero_grad()\n",
    "\n",
    "                losses += loss.item()\n",
    "                if (step+1) % 100 == 0 :\n",
    "                    train_loss = losses / 100\n",
    "                    print(f'training loss: {train_loss:4.4}')\n",
    "                    losses = 0\n",
    "                ##################################################################\n",
    "        \n",
    "        return self.cross_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertEncoder were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['linear.weight', 'linear.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"dense_retireval\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=40,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "model_checkpoint = \"klue/bert-base\"\n",
    "\n",
    "# 혹시 위에서 사용한 encoder가 있다면 주석처리 후 진행해주세요 (CUDA ...)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "cross_encoder = BertEncoder.from_pretrained(model_checkpoint).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f152d1ef7e4352b9d1e53ff3f97400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.3505\n",
      "training loss: 0.0798\n",
      "training loss: 0.0634\n",
      "training loss: 0.02339\n",
      "training loss: 0.01976\n",
      "training loss: 0.01066\n",
      "training loss: 0.01028\n",
      "training loss: 0.01023\n",
      "training loss: 0.01002\n",
      "training loss: 0.007944\n",
      "training loss: 0.009278\n",
      "training loss: 0.008298\n",
      "training loss: 0.005324\n",
      "training loss: 0.007314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   2%|▎         | 1/40 [12:06<7:51:55, 726.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68038afe1bce4d1abc81fece2d44a227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.007787\n",
      "training loss: 0.002427\n",
      "training loss: 0.00171\n",
      "training loss: 0.0009209\n",
      "training loss: 0.007005\n",
      "training loss: 0.003466\n",
      "training loss: 0.001762\n",
      "training loss: 0.001404\n",
      "training loss: 0.001284\n",
      "training loss: 0.0008469\n",
      "training loss: 0.0007349\n",
      "training loss: 0.008568\n",
      "training loss: 0.002439\n",
      "training loss: 0.004033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   5%|▌         | 2/40 [24:11<7:39:42, 725.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c835b7fb714a482b87c39d8aca5d6bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.002342\n",
      "training loss: 0.002154\n",
      "training loss: 0.0003874\n",
      "training loss: 0.004067\n",
      "training loss: 0.001495\n",
      "training loss: 0.003042\n",
      "training loss: 0.003225\n",
      "training loss: 0.002308\n",
      "training loss: 0.001339\n",
      "training loss: 0.001433\n",
      "training loss: 0.008992\n",
      "training loss: 0.001328\n",
      "training loss: 0.001717\n",
      "training loss: 0.0006858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   8%|▊         | 3/40 [36:17<7:27:40, 725.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7bb0da760a54c80949fdbd8b0cf1a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.001086\n",
      "training loss: 0.002971\n",
      "training loss: 0.002006\n",
      "training loss: 0.0007831\n",
      "training loss: 0.001253\n",
      "training loss: 0.008128\n",
      "training loss: 0.0005222\n",
      "training loss: 0.004348\n",
      "training loss: 0.003308\n",
      "training loss: 0.003969\n",
      "training loss: 0.001107\n",
      "training loss: 0.007538\n",
      "training loss: 0.001356\n",
      "training loss: 0.0004068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 4/40 [48:22<7:15:25, 725.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9322c258ba2c42eeb21b80bae7427a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.001041\n",
      "training loss: 0.001102\n",
      "training loss: 0.0006416\n",
      "training loss: 0.0005035\n",
      "training loss: 0.0008136\n",
      "training loss: 0.0009362\n",
      "training loss: 0.0004269\n",
      "training loss: 0.001646\n",
      "training loss: 0.0002132\n",
      "training loss: 0.0004679\n",
      "training loss: 0.0009488\n",
      "training loss: 0.004387\n",
      "training loss: 0.001558\n",
      "training loss: 0.0007145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  12%|█▎        | 5/40 [1:00:26<7:02:59, 725.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f0f48cb90f24f64939f21d352579b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.0002177\n",
      "training loss: 0.002533\n",
      "training loss: 0.000258\n",
      "training loss: 0.001007\n",
      "training loss: 0.001799\n",
      "training loss: 0.0003331\n",
      "training loss: 0.0003569\n",
      "training loss: 0.003693\n",
      "training loss: 0.0004952\n",
      "training loss: 0.001425\n",
      "training loss: 0.0002621\n",
      "training loss: 0.0005605\n",
      "training loss: 0.002447\n",
      "training loss: 0.0001875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  15%|█▌        | 6/40 [1:12:29<6:50:34, 724.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4651c820244f4f2a9edbb73f0103e69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.0001969\n",
      "training loss: 0.0009694\n",
      "training loss: 0.0003521\n",
      "training loss: 0.0003656\n",
      "training loss: 0.004948\n",
      "training loss: 0.0005442\n",
      "training loss: 0.0001471\n",
      "training loss: 0.0004391\n",
      "training loss: 0.0001453\n",
      "training loss: 0.0001747\n",
      "training loss: 0.0002683\n",
      "training loss: 0.0003567\n",
      "training loss: 0.008905\n",
      "training loss: 0.0003699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  18%|█▊        | 7/40 [1:24:33<6:38:18, 724.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96681a1e059549939e6099ec5dc3722e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.001427\n",
      "training loss: 0.002409\n",
      "training loss: 0.0005248\n",
      "training loss: 0.0004248\n",
      "training loss: 0.000239\n",
      "training loss: 0.0002524\n",
      "training loss: 7.74e-05\n",
      "training loss: 0.0006951\n",
      "training loss: 5.222e-05\n",
      "training loss: 7.559e-05\n",
      "training loss: 0.0004297\n",
      "training loss: 0.0002785\n",
      "training loss: 0.001017\n",
      "training loss: 0.003409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 8/40 [1:36:36<6:26:09, 724.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8735d2fc8bc94c0b8bed99442572cef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.00377\n",
      "training loss: 0.0006355\n",
      "training loss: 0.0002538\n",
      "training loss: 0.0006935\n",
      "training loss: 0.0005247\n",
      "training loss: 6.654e-05\n",
      "training loss: 0.001272\n",
      "training loss: 0.0001693\n",
      "training loss: 0.000369\n",
      "training loss: 0.001372\n",
      "training loss: 4.026e-05\n",
      "training loss: 0.000114\n",
      "training loss: 0.0001726\n",
      "training loss: 0.0001016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  22%|██▎       | 9/40 [1:48:41<6:14:10, 724.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c9292015204f8291dc456c1fd8bf6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.0032\n",
      "training loss: 0.001085\n",
      "training loss: 0.002624\n",
      "training loss: 0.0001307\n",
      "training loss: 7.584e-05\n",
      "training loss: 0.003107\n",
      "training loss: 0.0008919\n",
      "training loss: 0.000364\n",
      "training loss: 0.001271\n",
      "training loss: 0.0005053\n",
      "training loss: 3.187e-05\n",
      "training loss: 0.005179\n",
      "training loss: 0.0003564\n",
      "training loss: 0.0002757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 10/40 [2:00:44<6:01:59, 723.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72a6a6cc3a94c6daf3e6d1c7e312420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.0003902\n",
      "training loss: 4.071e-05\n",
      "training loss: 0.003874\n",
      "training loss: 0.001587\n",
      "training loss: 0.000473\n",
      "training loss: 8.921e-05\n",
      "training loss: 0.004937\n",
      "training loss: 0.001061\n",
      "training loss: 0.00507\n",
      "training loss: 0.001584\n",
      "training loss: 0.001534\n",
      "training loss: 0.0005116\n",
      "training loss: 0.000334\n",
      "training loss: 0.01157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  28%|██▊       | 11/40 [2:12:49<5:49:57, 724.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2ee8a783cf413cbb57ad7e2fb33581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.0004293\n",
      "training loss: 0.003299\n",
      "training loss: 5.423e-05\n",
      "training loss: 6.387e-05\n",
      "training loss: 0.001355\n",
      "training loss: 1.914e-05\n",
      "training loss: 0.000104\n",
      "training loss: 4.987e-05\n",
      "training loss: 0.0005306\n",
      "training loss: 0.003811\n",
      "training loss: 0.004983\n",
      "training loss: 0.00024\n",
      "training loss: 0.003989\n",
      "training loss: 0.0002248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 12/40 [2:24:53<5:37:55, 724.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a65f7cdac090431f904688d7678f1195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 3.855e-05\n",
      "training loss: 0.0002369\n",
      "training loss: 0.001533\n",
      "training loss: 8.149e-05\n",
      "training loss: 0.0007819\n",
      "training loss: 1.622e-05\n",
      "training loss: 4.696e-05\n",
      "training loss: 5.638e-05\n",
      "training loss: 0.000303\n",
      "training loss: 0.001329\n",
      "training loss: 0.0002316\n",
      "training loss: 0.0008193\n",
      "training loss: 0.0002188\n",
      "training loss: 3.11e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  32%|███▎      | 13/40 [2:36:57<5:25:51, 724.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c3bee0e47c43de8ee7f20586ac6d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.0001875\n",
      "training loss: 0.0003357\n",
      "training loss: 5.633e-05\n",
      "training loss: 0.0002197\n",
      "training loss: 6.111e-05\n",
      "training loss: 0.0007435\n",
      "training loss: 0.0005621\n",
      "training loss: 0.0002745\n",
      "training loss: 1.181e-05\n",
      "training loss: 2.955e-05\n",
      "training loss: 0.0002014\n",
      "training loss: 0.0003657\n",
      "training loss: 6.319e-05\n",
      "training loss: 3.666e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  35%|███▌      | 14/40 [2:49:01<5:13:46, 724.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff9648a45814ea38c66c65ee6177cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 5.278e-05\n",
      "training loss: 3.229e-05\n",
      "training loss: 0.01447\n",
      "training loss: 0.002361\n",
      "training loss: 0.001795\n",
      "training loss: 0.0003298\n",
      "training loss: 5.309e-05\n",
      "training loss: 0.008066\n",
      "training loss: 0.004494\n",
      "training loss: 0.003607\n",
      "training loss: 0.0001025\n",
      "training loss: 0.003733\n",
      "training loss: 0.0004976\n",
      "training loss: 7.054e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  38%|███▊      | 15/40 [3:01:04<5:01:36, 723.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3773b6ce5e94ad781528adacd05dd24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 3.416e-05\n",
      "training loss: 9.99e-05\n",
      "training loss: 4.667e-05\n",
      "training loss: 4.478e-05\n",
      "training loss: 0.0001289\n",
      "training loss: 0.003132\n",
      "training loss: 0.0001834\n",
      "training loss: 0.002526\n",
      "training loss: 0.0006992\n",
      "training loss: 0.0001326\n",
      "training loss: 0.0003289\n",
      "training loss: 0.0001061\n",
      "training loss: 3.385e-05\n",
      "training loss: 0.000167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 16/40 [3:13:08<4:49:27, 723.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29401ce72e324161bc03f0865db5ef1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 6.801e-05\n",
      "training loss: 5.803e-05\n",
      "training loss: 9.799e-05\n",
      "training loss: 0.003174\n",
      "training loss: 0.0002081\n",
      "training loss: 6.215e-05\n",
      "training loss: 6.815e-05\n",
      "training loss: 2.941e-05\n",
      "training loss: 0.0001565\n",
      "training loss: 9.991e-05\n",
      "training loss: 0.0002029\n",
      "training loss: 0.001852\n",
      "training loss: 0.0001041\n",
      "training loss: 9.781e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  42%|████▎     | 17/40 [3:25:12<4:37:29, 723.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2594ce2a8144bcf8854ae5db10252f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 4.822e-05\n",
      "training loss: 2.19e-05\n",
      "training loss: 2.672e-05\n",
      "training loss: 6.142e-05\n",
      "training loss: 0.0003118\n",
      "training loss: 3.865e-05\n",
      "training loss: 7.622e-05\n",
      "training loss: 0.0001078\n",
      "training loss: 0.005495\n",
      "training loss: 8.457e-05\n",
      "training loss: 3.411e-05\n",
      "training loss: 0.0002521\n",
      "training loss: 0.001793\n",
      "training loss: 0.007513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  45%|████▌     | 18/40 [3:37:16<4:25:27, 723.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d1c92bfe334c0aa8b4b2bbe5ea482e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.001637\n",
      "training loss: 0.0002192\n",
      "training loss: 0.006405\n",
      "training loss: 4.204e-05\n",
      "training loss: 4.422e-05\n",
      "training loss: 0.001489\n",
      "training loss: 0.0005255\n",
      "training loss: 9.397e-05\n",
      "training loss: 2.994e-05\n",
      "training loss: 9.491e-05\n",
      "training loss: 0.0008316\n",
      "training loss: 1.936e-05\n",
      "training loss: 0.001095\n",
      "training loss: 0.0006553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  48%|████▊     | 19/40 [3:49:20<4:13:21, 723.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a1fbfebc9a44eb970e8ddc72910535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 1.947e-05\n",
      "training loss: 0.005049\n",
      "training loss: 0.002862\n",
      "training loss: 0.0002204\n",
      "training loss: 0.0002051\n",
      "training loss: 0.0006704\n",
      "training loss: 0.0001622\n",
      "training loss: 0.0001382\n",
      "training loss: 4.776e-05\n",
      "training loss: 3.332e-05\n",
      "training loss: 0.000456\n",
      "training loss: 8.366e-06\n",
      "training loss: 2.107e-05\n",
      "training loss: 0.00104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 20/40 [4:01:24<4:01:18, 723.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb74877fc1f749e9b7d897a99b051474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.00245\n",
      "training loss: 0.0002455\n",
      "training loss: 0.0001415\n",
      "training loss: 3.691e-05\n",
      "training loss: 0.0001752\n",
      "training loss: 9.692e-05\n",
      "training loss: 2.576e-05\n",
      "training loss: 1.542e-05\n",
      "training loss: 0.004616\n",
      "training loss: 7.137e-05\n",
      "training loss: 0.0002435\n",
      "training loss: 0.002687\n",
      "training loss: 5.116e-05\n",
      "training loss: 3.143e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  52%|█████▎    | 21/40 [4:13:28<3:49:14, 723.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae02a6eb2f34282b96e3eea8dcbbf8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.0003854\n",
      "training loss: 4.08e-05\n",
      "training loss: 4.277e-05\n",
      "training loss: 0.001202\n",
      "training loss: 4.864e-05\n",
      "training loss: 0.000137\n",
      "training loss: 4.186e-05\n",
      "training loss: 0.004008\n",
      "training loss: 0.0004\n",
      "training loss: 0.000417\n",
      "training loss: 4.793e-05\n",
      "training loss: 6.979e-05\n",
      "training loss: 4.95e-05\n",
      "training loss: 0.0002307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  55%|█████▌    | 22/40 [4:25:31<3:37:08, 723.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e678b8ffdd5d421a9f3c83f3a55ec0a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.001241\n",
      "training loss: 2.004e-05\n",
      "training loss: 0.0003174\n",
      "training loss: 2.78e-05\n",
      "training loss: 2.786e-05\n",
      "training loss: 0.0001504\n",
      "training loss: 0.0001866\n",
      "training loss: 1.433e-05\n",
      "training loss: 0.0001144\n",
      "training loss: 0.0008227\n",
      "training loss: 1.629e-05\n",
      "training loss: 0.0002608\n",
      "training loss: 5.758e-06\n",
      "training loss: 9.11e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  57%|█████▊    | 23/40 [4:37:35<3:25:04, 723.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397a98be4d2b44088bb03d26fca6adb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 2.185e-05\n",
      "training loss: 2.327e-05\n",
      "training loss: 2.603e-05\n",
      "training loss: 9.641e-05\n",
      "training loss: 3.928e-05\n",
      "training loss: 0.005552\n",
      "training loss: 0.004783\n",
      "training loss: 1.844e-05\n",
      "training loss: 0.004616\n",
      "training loss: 0.0007286\n",
      "training loss: 0.0003371\n",
      "training loss: 7.842e-05\n",
      "training loss: 0.004854\n",
      "training loss: 0.001918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 24/40 [4:49:39<3:13:00, 723.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f3908bf02b46e7beb2f3f10b02a092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.0001182\n",
      "training loss: 0.00311\n",
      "training loss: 0.0002064\n",
      "training loss: 0.0002379\n",
      "training loss: 0.003165\n",
      "training loss: 0.0001685\n",
      "training loss: 1.381e-05\n",
      "training loss: 7.732e-06\n",
      "training loss: 2.815e-05\n",
      "training loss: 9.496e-05\n",
      "training loss: 2.398e-05\n",
      "training loss: 2.245e-05\n",
      "training loss: 0.01037\n",
      "training loss: 6.193e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  62%|██████▎   | 25/40 [5:01:43<3:00:59, 723.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4994217936149889f71d65a7ef00ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.000158\n",
      "training loss: 0.0002663\n",
      "training loss: 0.0002359\n",
      "training loss: 0.008378\n",
      "training loss: 0.0004428\n",
      "training loss: 0.0002418\n",
      "training loss: 0.004264\n",
      "training loss: 8.535e-05\n",
      "training loss: 0.0001838\n",
      "training loss: 0.0004271\n",
      "training loss: 0.0005582\n",
      "training loss: 0.0002043\n",
      "training loss: 0.0001847\n",
      "training loss: 0.0003118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  65%|██████▌   | 26/40 [5:13:48<2:48:57, 724.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230084d759294bc0bde35c5cdb3140b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 1.84e-05\n",
      "training loss: 0.0002231\n",
      "training loss: 1.995e-05\n",
      "training loss: 0.0008134\n",
      "training loss: 1.798e-05\n",
      "training loss: 2.245e-05\n",
      "training loss: 1.192e-05\n",
      "training loss: 0.0001432\n",
      "training loss: 0.001195\n",
      "training loss: 0.003376\n",
      "training loss: 7.274e-05\n",
      "training loss: 3.601e-05\n",
      "training loss: 0.0001614\n",
      "training loss: 4.06e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  68%|██████▊   | 27/40 [5:25:51<2:36:50, 723.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9e7a9848994434cb0382aad8b17f63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.002204\n",
      "training loss: 8.163e-05\n",
      "training loss: 0.0005679\n",
      "training loss: 0.0001615\n",
      "training loss: 0.001744\n",
      "training loss: 5.213e-05\n",
      "training loss: 3.213e-05\n",
      "training loss: 0.004149\n",
      "training loss: 0.0001344\n",
      "training loss: 0.0002419\n",
      "training loss: 0.0003039\n",
      "training loss: 3.663e-05\n",
      "training loss: 3.085e-05\n",
      "training loss: 2.287e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 28/40 [5:37:54<2:24:44, 723.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c713065c35a41a09c074ec970645bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.0001181\n",
      "training loss: 0.00359\n",
      "training loss: 0.0008065\n",
      "training loss: 3.833e-05\n",
      "training loss: 0.003734\n",
      "training loss: 2.715e-05\n",
      "training loss: 6.239e-05\n",
      "training loss: 1.074e-05\n",
      "training loss: 2.941e-05\n",
      "training loss: 0.004575\n",
      "training loss: 6.001e-05\n",
      "training loss: 2.708e-05\n",
      "training loss: 0.007172\n",
      "training loss: 5.03e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  72%|███████▎  | 29/40 [5:49:58<2:12:42, 723.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2675c06d2a4b443a936b1b5a6b31d401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.0005449\n",
      "training loss: 3.247e-06\n",
      "training loss: 7.748e-05\n",
      "training loss: 0.00833\n",
      "training loss: 8.24e-05\n",
      "training loss: 0.0006284\n",
      "training loss: 0.003671\n",
      "training loss: 3.933e-06\n",
      "training loss: 0.0008329\n",
      "training loss: 0.0002434\n",
      "training loss: 0.0004809\n",
      "training loss: 0.0001319\n",
      "training loss: 0.0001727\n",
      "training loss: 5.503e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  75%|███████▌  | 30/40 [6:02:02<2:00:37, 723.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f071d6145a654ff0886c7a5011b13fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 6.357e-05\n",
      "training loss: 3.211e-05\n",
      "training loss: 0.002569\n",
      "training loss: 0.0001236\n",
      "training loss: 0.002123\n",
      "training loss: 4.966e-05\n",
      "training loss: 1.966e-06\n",
      "training loss: 0.0001368\n",
      "training loss: 2.347e-05\n",
      "training loss: 7.517e-05\n",
      "training loss: 0.0006265\n",
      "training loss: 0.0007982\n",
      "training loss: 4.347e-05\n",
      "training loss: 2.195e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  78%|███████▊  | 31/40 [6:14:06<1:48:34, 723.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a11a878b38f407bb670040687e8a9de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.002003\n",
      "training loss: 1.408e-05\n",
      "training loss: 0.003017\n",
      "training loss: 4.902e-06\n",
      "training loss: 0.003926\n",
      "training loss: 1.194e-05\n",
      "training loss: 4.011e-06\n",
      "training loss: 0.005143\n",
      "training loss: 0.001303\n",
      "training loss: 0.003604\n",
      "training loss: 1.981e-05\n",
      "training loss: 5.223e-05\n",
      "training loss: 6.534e-06\n",
      "training loss: 1.126e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 32/40 [6:26:10<1:36:31, 723.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a7d3a0ad3d45648be4bea4362e40b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.004037\n",
      "training loss: 2.049e-06\n",
      "training loss: 0.000147\n",
      "training loss: 6.309e-06\n",
      "training loss: 0.0003035\n",
      "training loss: 7.727e-06\n",
      "training loss: 7.828e-06\n",
      "training loss: 0.0008264\n",
      "training loss: 0.0002318\n",
      "training loss: 1.127e-05\n",
      "training loss: 7.573e-06\n",
      "training loss: 0.00225\n",
      "training loss: 1.424e-05\n",
      "training loss: 0.000622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  82%|████████▎ | 33/40 [6:38:14<1:24:26, 723.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14a8d29c0fb407684eb687c1fb635f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 2.202e-05\n",
      "training loss: 0.0001188\n",
      "training loss: 0.02028\n",
      "training loss: 0.0003871\n",
      "training loss: 0.0001118\n",
      "training loss: 1.143e-05\n",
      "training loss: 3.567e-05\n",
      "training loss: 1.098e-05\n",
      "training loss: 0.0003817\n",
      "training loss: 0.0001465\n",
      "training loss: 0.0001211\n",
      "training loss: 4.683e-05\n",
      "training loss: 0.002093\n",
      "training loss: 0.0001833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  85%|████████▌ | 34/40 [6:50:19<1:12:24, 724.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c99c999313614190a88570c4c88f4201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.001294\n",
      "training loss: 3.352e-06\n",
      "training loss: 1.453e-05\n",
      "training loss: 3.072e-06\n",
      "training loss: 3.855e-05\n",
      "training loss: 2.285e-05\n",
      "training loss: 0.003578\n",
      "training loss: 0.0007481\n",
      "training loss: 2.068e-05\n",
      "training loss: 3.525e-05\n",
      "training loss: 6.191e-06\n",
      "training loss: 0.000141\n",
      "training loss: 3.082e-06\n",
      "training loss: 0.00388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  88%|████████▊ | 35/40 [7:02:23<1:00:20, 724.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac32e6223c04e29a1adc23233d9ba56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.003266\n",
      "training loss: 2.702e-05\n",
      "training loss: 3.886e-05\n",
      "training loss: 8.95e-05\n",
      "training loss: 9.016e-06\n",
      "training loss: 0.0001198\n",
      "training loss: 3.098e-06\n",
      "training loss: 3.673e-06\n",
      "training loss: 0.003165\n",
      "training loss: 0.004281\n",
      "training loss: 0.0002946\n",
      "training loss: 0.005452\n",
      "training loss: 1.561e-05\n",
      "training loss: 0.000985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 36/40 [7:14:27<48:17, 724.29s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c08c2dcce9449f8b3cb395ef492305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 2.465e-05\n",
      "training loss: 2.735e-05\n",
      "training loss: 1.919e-05\n",
      "training loss: 4.198e-06\n",
      "training loss: 4.287e-06\n",
      "training loss: 1.09e-05\n",
      "training loss: 0.0001368\n",
      "training loss: 0.00149\n",
      "training loss: 0.004442\n",
      "training loss: 0.01746\n",
      "training loss: 2.167e-06\n",
      "training loss: 2.344e-05\n",
      "training loss: 2.894e-05\n",
      "training loss: 0.0002701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  92%|█████████▎| 37/40 [7:26:32<36:12, 724.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee3756070204ad9874d2892d23d6747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.00067\n",
      "training loss: 3.091e-06\n",
      "training loss: 0.007828\n",
      "training loss: 2.818e-05\n",
      "training loss: 0.0009956\n",
      "training loss: 0.0002\n",
      "training loss: 0.00065\n",
      "training loss: 0.005993\n",
      "training loss: 5.063e-05\n",
      "training loss: 0.0002076\n",
      "training loss: 0.0001719\n",
      "training loss: 3.02e-05\n",
      "training loss: 1.212e-05\n",
      "training loss: 8.095e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  95%|█████████▌| 38/40 [7:43:03<26:49, 804.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b4fd5897e7c40bea74ad71ffb34ccbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.002083\n",
      "training loss: 0.003962\n",
      "training loss: 0.0004586\n",
      "training loss: 2.468e-05\n",
      "training loss: 0.001955\n",
      "training loss: 0.003146\n",
      "training loss: 5.406e-05\n",
      "training loss: 4.448e-06\n",
      "training loss: 4.7e-06\n",
      "training loss: 0.005023\n",
      "training loss: 5.499e-06\n",
      "training loss: 9.262e-06\n",
      "training loss: 0.0002058\n",
      "training loss: 1.164e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  98%|█████████▊| 39/40 [7:55:30<13:07, 787.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dbe7381ba8c41e1a9426034876d56f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 4.615e-05\n",
      "training loss: 2.516e-05\n",
      "training loss: 5.389e-06\n",
      "training loss: 2.925e-06\n",
      "training loss: 1.48e-05\n",
      "training loss: 9.347e-06\n",
      "training loss: 0.0001307\n",
      "training loss: 9.974e-06\n",
      "training loss: 0.001009\n",
      "training loss: 2.184e-05\n",
      "training loss: 5.502e-05\n",
      "training loss: 1.904e-05\n",
      "training loss: 3.772e-05\n",
      "training loss: 3.033e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 40/40 [8:07:35<00:00, 731.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Retriever는 아래와 같이 사용할 수 있도록 코드를 짜봅시다.\n",
    "retriever = DenseRetrieval(\n",
    "    args=args,\n",
    "    dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    cross_encoder=cross_encoder,\n",
    "    sampler = CustomSampler\n",
    ")\n",
    "c_encoder = retriever.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(c_encoder, '/opt/ml/custom/c_encoder_e40_b16.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "볼드윈이 \"당신들은 나를 야유합니까?\"라는 말을 한 연도는?\n",
      "퇴임에서 볼드윈의 세월은 조용하였다. 네빌 체임벌린이 사망하면서 전쟁 이전의 유화 정책에서 볼드윈의 지각된 부분은 제2차 세계 대전이 일어난 동안과 그 후에 그를 인기없는 인물로 만들었다. 신문의 캠페인은 그를 전쟁 생산에 자신의 시골 저택의 철문을 기부하지 않은 것으로 사냥하였다. 전쟁이 일어난 동안 윈스턴 처칠은 에이먼 데 벌레라의 아일랜드의 지속적인 중립을 향한 더욱 힘든 경향을 취하는 영국의 조언에 그를 단 한번 상담하였다.\\n\\n1945년 6월 부인 루시 여사가 사망하였다. 이제 볼드윈 자신은 관절염을 겪어 걸어다는 데 지팡이가 필요하였다. 조지 5세의 동상의 공개식에 1947년 런던에서 자신의 최종 공개적인 출연을 이루었다. 관중들은 전직 총리를 알아주어 그를 응원하였으나 이 당시 볼드윈은 귀머거리였고, 그들에게 \"당신들은 나를 야유합니까?\"라고 의문하였다. 1930년 케임브리지 대학교의 총장으로 만들어진 그는 1947년 12월 14일 80세의 나이에 우스터셔주 스투어포트온세번 근처 애슬리홀에서 수면 중 자신의 사망까지 이 수용력에 지속하였다. 그는 화장되었고, 그의 재는 우스터 대성당에 안치되었다.\n"
     ]
    }
   ],
   "source": [
    "valid_corpus = list(set([example['context'] for example in dataset['validation']]))[:10]\n",
    "sample_idx = random.choice(range(len(dataset['validation'])))\n",
    "query = dataset['validation'][sample_idx]['question']\n",
    "ground_truth = dataset['validation'][sample_idx]['context']\n",
    "\n",
    "if not ground_truth in valid_corpus:\n",
    "  valid_corpus.append(ground_truth)\n",
    "\n",
    "print(query)\n",
    "print(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-411eda001f16>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'input_ids' : torch.tensor(tokenized_examples['input_ids'][i].unsqueeze(dim=0)).to('cuda'),\n",
      "<ipython-input-12-411eda001f16>:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'attention_mask' : torch.tensor(tokenized_examples['attention_mask'][i].unsqueeze(dim=0)).to('cuda'),\n",
      "<ipython-input-12-411eda001f16>:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'token_type_ids' : torch.tensor(tokenized_examples['token_type_ids'][i].unsqueeze(dim=0)).to('cuda')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad() :\n",
    "    c_encoder.eval()\n",
    "    \n",
    "    score_list = []\n",
    "    for i in range(len(valid_corpus)) :\n",
    "        passage = valid_corpus[i]\n",
    "        tokenized_examples = tokenizer(\n",
    "            query,\n",
    "            passage,\n",
    "            truncation=\"only_second\",\n",
    "            max_length=512,\n",
    "            stride=128,\n",
    "            return_overflowing_tokens=True,\n",
    "            return_offsets_mapping=True,\n",
    "            #return_token_type_ids=False,  # roberta모델을 사용할 경우 False, bert를 사용할 경우 True로 표기해야합니다.\n",
    "            padding=\"max_length\",\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        score = 0\n",
    "        for i in range(len(tokenized_examples['input_ids'])) :\n",
    "            c_input = {\n",
    "                'input_ids' : torch.tensor(tokenized_examples['input_ids'][i].unsqueeze(dim=0)).to('cuda'),\n",
    "                'attention_mask' : torch.tensor(tokenized_examples['attention_mask'][i].unsqueeze(dim=0)).to('cuda'),\n",
    "                'token_type_ids' : torch.tensor(tokenized_examples['token_type_ids'][i].unsqueeze(dim=0)).to('cuda')\n",
    "            }\n",
    "            tmp_score = c_encoder(**c_input).to('cpu')\n",
    "            score += tmp_score\n",
    "        score = score / len(tokenized_examples['input_ids'])\n",
    "        score_list.append(score)\n",
    "    sort_result = torch.sort(torch.tensor(score_list), descending=True)\n",
    "\n",
    "    scores, index_list = sort_result[0], sort_result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search query]\n",
      " 볼드윈이 \"당신들은 나를 야유합니까?\"라는 말을 한 연도는? \n",
      "\n",
      "[Ground truth passage]\n",
      "퇴임에서 볼드윈의 세월은 조용하였다. 네빌 체임벌린이 사망하면서 전쟁 이전의 유화 정책에서 볼드윈의 지각된 부분은 제2차 세계 대전이 일어난 동안과 그 후에 그를 인기없는 인물로 만들었다. 신문의 캠페인은 그를 전쟁 생산에 자신의 시골 저택의 철문을 기부하지 않은 것으로 사냥하였다. 전쟁이 일어난 동안 윈스턴 처칠은 에이먼 데 벌레라의 아일랜드의 지속적인 중립을 향한 더욱 힘든 경향을 취하는 영국의 조언에 그를 단 한번 상담하였다.\\n\\n1945년 6월 부인 루시 여사가 사망하였다. 이제 볼드윈 자신은 관절염을 겪어 걸어다는 데 지팡이가 필요하였다. 조지 5세의 동상의 공개식에 1947년 런던에서 자신의 최종 공개적인 출연을 이루었다. 관중들은 전직 총리를 알아주어 그를 응원하였으나 이 당시 볼드윈은 귀머거리였고, 그들에게 \"당신들은 나를 야유합니까?\"라고 의문하였다. 1930년 케임브리지 대학교의 총장으로 만들어진 그는 1947년 12월 14일 80세의 나이에 우스터셔주 스투어포트온세번 근처 애슬리홀에서 수면 중 자신의 사망까지 이 수용력에 지속하였다. 그는 화장되었고, 그의 재는 우스터 대성당에 안치되었다. \n",
      "\n",
      "Top-1 passage with score 9.6913\n",
      "퇴임에서 볼드윈의 세월은 조용하였다. 네빌 체임벌린이 사망하면서 전쟁 이전의 유화 정책에서 볼드윈의 지각된 부분은 제2차 세계 대전이 일어난 동안과 그 후에 그를 인기없는 인물로 만들었다. 신문의 캠페인은 그를 전쟁 생산에 자신의 시골 저택의 철문을 기부하지 않은 것으로 사냥하였다. 전쟁이 일어난 동안 윈스턴 처칠은 에이먼 데 벌레라의 아일랜드의 지속적인 중립을 향한 더욱 힘든 경향을 취하는 영국의 조언에 그를 단 한번 상담하였다.\\n\\n1945년 6월 부인 루시 여사가 사망하였다. 이제 볼드윈 자신은 관절염을 겪어 걸어다는 데 지팡이가 필요하였다. 조지 5세의 동상의 공개식에 1947년 런던에서 자신의 최종 공개적인 출연을 이루었다. 관중들은 전직 총리를 알아주어 그를 응원하였으나 이 당시 볼드윈은 귀머거리였고, 그들에게 \"당신들은 나를 야유합니까?\"라고 의문하였다. 1930년 케임브리지 대학교의 총장으로 만들어진 그는 1947년 12월 14일 80세의 나이에 우스터셔주 스투어포트온세번 근처 애슬리홀에서 수면 중 자신의 사망까지 이 수용력에 지속하였다. 그는 화장되었고, 그의 재는 우스터 대성당에 안치되었다.\n",
      "Top-2 passage with score -4.1026\n",
      "테일러 대사는 캐나다 외무 장관 맥도널드와 클라크 총리에 지원을 요청하고 그들은 미국인들을 모두 도울 것을 표명했다. 그들은 6명의 미국인에게 캐나다 여권을 주고 국제선 항공편에 의해 미국으로 비밀리에 탈출 시키기로 결정했다. 작전 수행을 위해 캐나다 치외법권 지역에 있던 미국인 외교관들에게 캐나다 여권을 발급하게 해주는 추밀원령이 내려졌다. 그 여권에는 CIA에 의해 위조된 이란 비자가 첨부되어 있으며, 후에 탈출을 위해 사용되게 되었다.\\n\\nCIA는 위장 · 탈출 공작 담당자였던 토니 멘데스의 협력을 얻어 체류 이유, 서류, 적절한 복장, 변장 공구를 제공했다. 멘데스는 오타와의 캐나다 정부 관계자와 긴밀히 협력했고 그들은 캐나다의 택배를 이용하여 여권과 기타 지원 물자를 캐나다 대사관에 전달하게 했다. 멘데스는 구출 작전을 지원하는 요원 한 명과 함께 테헤란에 도착하였고, 다양한 시나리오, 다른 여권도 준비되어 있었지만 마지막으로 선택된 위장 시나리오는 6명을 로케이션 헌팅을 위해 이란에 온 할리우드 영화 관계자로 위장하는 것이었다. 그 시나리오 중에는 가짜로 만들어진 '아르고'(Argo)라는 영화도 포함되어 있었다. 또한 할리우드의 유명 메이크업 아티스트인 존 챔버스의 지원을 받아 실제로 운영되는 사무실도 설립되었다. 영화의 각본은 \"신들의 사회\"라는 SF 소설을 원작으로 한 것이었다. 그들은 로스앤젤레스에있는 \"Studio Six\"에 전화가 오면 응대하는 역할을 맡았다. 할리우드에는 Studio Six의 이름으로 광고가 배치되고 또한 관련 기사가 게재된 신문이 위장에 대한 설득력을 실어주었다.\\n\\n작전 중에 비자 날짜에 오류가 있는 것이 발견되었다. 비자를 준비한 담당자가 이란의 새해가 3월 말에 시작하는 것을 주의하지 않은 것이 원인이었다. 캐나다 대사관 요원이 실수를 지적했고 여분의 여권을 이용하여 멘데스는 이란 달력에 근거한 새로운 비자를 위조 할 수 있었다. 일주일이 지나는 동안 외교관들은 책을 읽거나 게임을 하며 시간을 보냈다. 또한 테일러 대사는 공항의 출입국 관리를 속이기 위해 그들이 출국하는 이유를 날조하였다.\n",
      "Top-3 passage with score -6.1182\n",
      "이야기에서 성 프란체스코 수도회의 수도사 라고만 언급되나, 조반니 빌라니의 연대기와 대조해 보면, 그 이름이 피에트로 달라키임을 확인할 수 있다는 것이 알려져 있다.\\n\\n피에트로 달라키는 재물을 밝히는 수도사로, 어느 부자가 자기 집에 있는 포도주를 자랑하면서 술김에 \"예수 그리스도께서 마실 만한 포도주\"라는 표현을 썼다는 점을 트집 잡아서 돈을 뜯어내려고 한다. 피에트로 달라키는 이 부자가 \"그리스도가 술 주정뱅이라는 식으로 신성모독 표현을 사용했다\"고 하여, 종교 재판으로 화형에 처해버리려고 한다. 부자는 살려달라고 하면서 뇌물을 바치고, 피에트로 달라키는 많은 돈을 받고, 매일 수도원에서 경건히 기도하게 하는 조건으로 화형을 면해 준다.\\n\\n나중에 기도 생활의 소감을 한 번 말해 보라고 하자, 부자는 \"매일 수도원에 수프가 남아도는 것을 보았는데, '하나에 대해 백을 받게 될 것이다'라는 말이 있으니, 수도원 사람들은 지옥에서 수프의 바다에 빠져 죽지 않을까 걱정이다\"라고 말한다. 수도사는 부자를 꺼림칙하게 여겨, 기도를 멈추고 집에 그냥 돌아가게 한다.\\n\\n데카메론에서 언급된 이야기 중에는 \"돈은 욕심 많은 성직자의 악질 탐욕병에는 매우 큰 효과가 있는 법이다\", \"이 미약은 그 효과가 비할 것이 없어서, 갈레노스의 의학서에는 써 있지 않습니다만, 그 효험 덕분에 화형을 십자가로 바뀌었다\"라는 식으로 뇌물을 풍자하는 표현이 등장한다.\n",
      "Top-4 passage with score -7.7128\n",
      "2012년 5월 22일 시민운동 단체 남성연대는 굿보이의 음원유통금지 가처분 신청을 제기했다. 같은 날 남성연대 홈페이지에는 \"백지영의 '굿보이'는 연인 관계에 있는 연하남을 연상녀가 길들인다는 내용을 담고 있지만, 그 표현이 주인과 개의 관계처럼 남성을 비하하고 있다\"고 주장한 글이 게재됐다. 이어 남성연대 측은 \"남성이 여성에게 대든다는 표현을 '짖어댄다'거나 '주인을 문다' 등의 가사로 묘사하고 있고 뮤직비디오에서도 남성을 말 잘 듣는 개로 다룬다\"고 말했다. 이어 \"표현의 자유를 주장하는 이들이 있으리라 생각되지만, 남녀의 위치를 바꾸고도 표현의 자유를 말할 수 있겠느냐. 남성은 개가 될 수 있고 여성은 개가 될 수 없다고 주장한다면 당신의 사고방식은 개OO다\"라며 강도 높은 비난을 하며 \"정상적이고 건강한 남성들은 이런 노래에 불쾌감을 느낀다. 남성연대는 '굿보이'의 음원 유통을 반대한다\"라고 덧붙였다. 이에 백지영 측은 '남성'을 '개'로 여자를 우습게 보는 ‘나쁜 남자’에 대한 경고를 여자 입장에서 재치 있게 표현한 노랫말일 뿐 남성 비하 의도는 없다고 해명했다. 또한 비스트 용준형의 랩 부분은 오히려 남자가 여자에게 일침을 가하는 내용이라 당황스럽다는 입장이라고 해명해 상황은 일단락 되었다.\n",
      "Top-5 passage with score -8.8253\n",
      "셔틀콕은 그 재질에 따라 깃털 셔틀콕과 인조 셔틀콕으로 나뉜다. 깃털로 만들어진 셔틀콕은 내구성이 떨어져 시합 중에 수시로 교체해 주어야 하는 불편함이 있다. 인조 셔틀콕은 기존 셔틀콕의 깃털 부분을 플라스틱 재질로 대체하여 그러한 단점을 보완한 것이다. 좋은 품질의 깃털 셔틀콕과 인조 셔틀콕은 단가가 서로 비슷하면서 내구성은 인조 셔틀콕이 더 우수하기 때문에, 아마추어 동호인들은 오래 사용할 수 있는 인조 셔틀콕을 더 선호하기도 한다.\\n\\n깃털 셔틀콕과 인조 셔틀콕은 공중에서 보여주는 움직임에서 차이가 있다. 플라스틱으로 만들어진 셔틀콕은 최초 타격시에는 깃털 셔틀콕보다 좀더 느리게 날아가지만 속도의 감소는 상대적으로 적어 종속(終速)이 더 빠른 성질을 보인다. 반면 깃털 셔틀콕은 라켓에 의해 타격되는 순간 최고 320km/h에 이르는 빠른 속도로 날아가지만 속도의 감소율이 더 높아 땅에 떨어지는 순간에는 플라스틱 셔틀콕보다 속도가 더 느려진다. 이 때문에 깃털 셔틀콕을 사용하는 경우 경기의 진행 속도가 빨라 보이면서 랠리는 더 길어지는 효과가 있다.\\n\\n상급자 수준의 아마추어 혹은 어느 정도 규모 이상의 대회에서는 거의 예외 없이 깃털 셔틀콕을 쓰며, 전문 선수들 또한 항상 깃털 셔틀콕만을 사용한다. 이것은 그들이 깃털 셔틀콕의 타구감을 선호하고, 또한 플라스틱보다 깃털 셔틀콕이 정교한 컨트롤을 하기에 보다 더 적합하기 때문이다. 특히 깃털 셔틀콕은 그 특성상 더 적은 힘으로 더 빠르게 날아가게 타구할 수 있으므로 플라스틱 재질을 사용할 때보다 어깨에 부담이 적고 부상의 위험도 낮다. 이러한 이유로 국제 시니어 대회에서는 항상 최상 품질의 셔틀콕을 사용한다. 상대적으로 유럽이나 북미 지역에 비해 깃털 셔틀콕의 단가가 더 낮은 아시아 지역에서 깃털 셔틀콕의 사용 빈도가 더 높다.\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "print(\"[Search query]\\n\", query, \"\\n\")\n",
    "print(\"[Ground truth passage]\")\n",
    "print(ground_truth, \"\\n\")\n",
    "\n",
    "for i in range(k):\n",
    "  print(\"Top-%d passage with score %.4f\" % (i+1, scores[i]))\n",
    "  print(valid_corpus[index_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10,  0,  4,  1,  5,  9,  6,  3,  7,  2,  8])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_examples['input_ids'][0].unsqueeze(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_index_list = []\n",
    "for i in range(len(index_list)) :\n",
    "    temp = index_list[i][:k]\n",
    "    top_k_index_list.appedn(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/data/wikipedia_documents.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    wiki = json.load(f)\n",
    "\n",
    "corpus = list(\n",
    "    dict.fromkeys([v[\"text\"] for v in wiki.values()])\n",
    ")  # set 은 매번 순서가 바뀌므로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ad9a33471943ddbe0f2d5c26be899a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=240.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ba837f384349bd9c163d2ad49e9625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=56737.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-a97d169c2490>:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'input_ids' : torch.tensor(tokenized_examples['input_ids'][i].unsqueeze(dim=0)).to('cuda'),\n",
      "<ipython-input-32-a97d169c2490>:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'attention_mask' : torch.tensor(tokenized_examples['attention_mask'][i].unsqueeze(dim=0)).to('cuda'),\n",
      "<ipython-input-32-a97d169c2490>:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'token_type_ids' : torch.tensor(tokenized_examples['token_type_ids'][i].unsqueeze(dim=0)).to('cuda')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-a97d169c2490>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0;34m'token_type_ids'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_examples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 }\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mtmp_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mc_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtmp_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_examples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b9e1c199b1c1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m     18\u001b[0m         ): \n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m         )\n\u001b[0;32m--> 995\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    996\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    580\u001b[0m                 )\n\u001b[1;32m    581\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    583\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    511\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2328\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2330\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "question_data = dataset['validation']['question']\n",
    "with torch.no_grad() :\n",
    "    c_encoder.eval()\n",
    "\n",
    "    result_scores = []\n",
    "    result_indices = []\n",
    "    for i in tqdm(range(len(question_data))) :\n",
    "        question = question_data[i]\n",
    "\n",
    "        question_score = []\n",
    "        for i in tqdm(range(len(corpus))) :\n",
    "            passage = corpus[i]\n",
    "            tokenized_examples = tokenizer(\n",
    "                question,\n",
    "                passage,\n",
    "                truncation=\"only_second\",\n",
    "                max_length=512,\n",
    "                stride=128,\n",
    "                return_overflowing_tokens=True,\n",
    "                return_offsets_mapping=True,\n",
    "                #return_token_type_ids=False,  # roberta모델을 사용할 경우 False, bert를 사용할 경우 True로 표기해야합니다.\n",
    "                padding=\"max_length\",\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "            score = 0\n",
    "            for i in range(len(tokenized_examples['input_ids'])) :\n",
    "                c_input = {\n",
    "                    'input_ids' : torch.tensor(tokenized_examples['input_ids'][i].unsqueeze(dim=0)).to('cuda'),\n",
    "                    'attention_mask' : torch.tensor(tokenized_examples['attention_mask'][i].unsqueeze(dim=0)).to('cuda'),\n",
    "                    'token_type_ids' : torch.tensor(tokenized_examples['token_type_ids'][i].unsqueeze(dim=0)).to('cuda')\n",
    "                }\n",
    "                tmp_score = c_encoder(**c_input).to('cpu')\n",
    "                score += tmp_score\n",
    "            score = score / len(tokenized_examples['input_ids'])\n",
    "            question_score.append(score)\n",
    "\n",
    "        sort_result = torch.sort(torch.tensor(question_score), descending=True)\n",
    "        scores, index_list = sort_result[0], sort_result[1]\n",
    "\n",
    "        result_scores.append(scores)\n",
    "        result_indices.append(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_index_list = []\n",
    "for i in range(len(index_list)) :\n",
    "    temp = index_list[i][:k]\n",
    "    top_k_index_list.appedn(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = []\n",
    "for idx, example in enumerate(\n",
    "        tqdm(dataset['validation'], desc=\"Dense retrieval: \")\n",
    "    ):\n",
    "        tmp = {\n",
    "            # Query와 해당 id를 반환합니다.\n",
    "            \"question\": example[\"question\"],\n",
    "            \"id\": example[\"id\"],\n",
    "            # Retrieve한 Passage의 id, context를 반환합니다.\n",
    "            \"context_id\": top_k_index_list[idx],\n",
    "            \"context\": \" \".join(  # 기존에는 ' '.join()\n",
    "                [corpus[pid] for pid in top_k_index_list[idx]]\n",
    "            ),\n",
    "        }\n",
    "        if \"context\" in example.keys() and \"answers\" in example.keys():\n",
    "            # validation 데이터를 사용하면 ground_truth context와 answer도 반환합니다.\n",
    "            tmp[\"original_context\"] = example[\"context\"]\n",
    "            tmp[\"answers\"] = example[\"answers\"]\n",
    "        total.append(tmp)\n",
    "\n",
    "cqas_100 = pd.DataFrame(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('/opt/ml/data/train_dataset')\n",
    "train_dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/opt/ml/custom/top100_wikipedia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_indices = []\n",
    "for i in range(len(data)) :\n",
    "    tmp = eval(data['document_id'][i])\n",
    "    doc_indices.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/data/wikipedia_documents.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    wiki = json.load(f)\n",
    "\n",
    "corpus = []\n",
    "for v in wiki.values() :\n",
    "    corpus.append(v['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEncoder(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertEncoder, self).__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.init_weights()\n",
    "        classifier_dropout=(\n",
    "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = torch.nn.Dropout(classifier_dropout)\n",
    "        self.linear = torch.nn.Linear(config.hidden_size, 1)\n",
    "      \n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids, \n",
    "            attention_mask=None,\n",
    "            token_type_ids=None\n",
    "        ): \n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        output = self.linear(pooled_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_encoder = torch.load('/opt/ml/custom/c_encoder_e20.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"klue/bert-base\"\n",
    "# 혹시 위에서 사용한 encoder가 있다면 주석처리 후 진행해주세요 (CUDA ...)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_data = dataset['validation']['question']\n",
    "with torch.no_grad() : \n",
    "    c_encoder.eval()\n",
    "\n",
    "    result_scores = []\n",
    "    result_indices = []\n",
    "    for i in tqdm(range(len(question_data))) :\n",
    "        question = question_data[i]\n",
    "        question_score = []\n",
    "        for indice in tqdm(doc_indices[i]) :\n",
    "            passage = corpus[indice]\n",
    "            tokenized_examples = tokenizer(\n",
    "                question,\n",
    "                passage,\n",
    "                truncation=\"only_second\",\n",
    "                max_length=512,\n",
    "                stride=128,\n",
    "                return_overflowing_tokens=True,\n",
    "                return_offsets_mapping=True,\n",
    "                #return_token_type_ids=False,  # roberta모델을 사용할 경우 False, bert를 사용할 경우 True로 표기해야합니다.\n",
    "                padding=\"max_length\",\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            score = 0\n",
    "            for i in range(len(tokenized_examples['input_ids'])) :\n",
    "                c_input = {\n",
    "                    'input_ids' : torch.tensor(tokenized_examples['input_ids'][i].unsqueeze(dim=0)).to('cuda'),\n",
    "                    'attention_mask' : torch.tensor(tokenized_examples['attention_mask'][i].unsqueeze(dim=0)).to('cuda'),\n",
    "                    'token_type_ids' : torch.tensor(tokenized_examples['token_type_ids'][i].unsqueeze(dim=0)).to('cuda')\n",
    "                }\n",
    "                tmp_score = c_encoder(**c_input).to('cpu')\n",
    "                score += tmp_score\n",
    "            score = score / len(tokenized_examples['input_ids'])\n",
    "            question_score.append(score)\n",
    "        sort_result = torch.sort(torch.tensor(question_score), descending=True)\n",
    "        scores, index_list = sort_result[0], sort_result[1]\n",
    "\n",
    "        result_scores.append(scores.tolist())\n",
    "        result_indices.append(index_list.tolist())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_indices = []\n",
    "for i in range(len(doc_indices)) :\n",
    "    t_list = [doc_indices[i][result_indices[i][k]] for k in range(7)]\n",
    "    final_indices.append(t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8338d75cb954ed486845b7fcdd8ff45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dense retrieval: ', max=240.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total = []\n",
    "for idx, example in enumerate(\n",
    "        tqdm(dataset['validation'], desc=\"Dense retrieval: \")\n",
    "    ):\n",
    "        tmp = {\n",
    "            # Query와 해당 id를 반환합니다.\n",
    "            \"question\": example[\"question\"],\n",
    "            \"id\": example[\"id\"],\n",
    "            # Retrieve한 Passage의 id, context를 반환합니다.\n",
    "            \"context_id\": final_indices[idx],\n",
    "            \"context\": \" \".join(  # 기존에는 ' '.join()\n",
    "                [corpus[pid] for pid in final_indices[idx]]\n",
    "            ),\n",
    "        }\n",
    "        if \"context\" in example.keys() and \"answers\" in example.keys():\n",
    "            # validation 데이터를 사용하면 ground_truth context와 answer도 반환합니다.\n",
    "            tmp[\"original_context\"] = example[\"context\"]\n",
    "            tmp[\"answers\"] = example[\"answers\"]\n",
    "        total.append(tmp)\n",
    "\n",
    "cqas_50 = pd.DataFrame(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n"
     ]
    }
   ],
   "source": [
    "correct_length = []\n",
    "for i in range(len(cqas_50)) :\n",
    "    if cqas_50['original_context'][i] in cqas_50['context'][i] :\n",
    "        correct_length.append(i)\n",
    "print(len(correct_length) / len(dataset['validation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cqas_50.to_csv('b16_special_shuffle_elastic_ce40_t7.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('/opt/ml/data/test_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/opt/ml/custom/test_elastic_top100.csv')\n",
    "\n",
    "doc_indices = []\n",
    "for i in range(len(data)) :\n",
    "    tmp = eval(data['document_id'][i])\n",
    "    doc_indices.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72802becbc594868bd7f2290207a67b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# test에 대해서만 실행\n",
    "for i in tqdm(range(len(doc_indices))) :\n",
    "    for j in range(len(doc_indices[i])) :\n",
    "        doc_indices[i][j] = int(doc_indices[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/data/wikipedia_documents.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    wiki = json.load(f)\n",
    "\n",
    "corpus = []\n",
    "for v in wiki.values() :\n",
    "    corpus.append(v['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEncoder(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertEncoder, self).__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.init_weights()\n",
    "        classifier_dropout=(\n",
    "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = torch.nn.Dropout(classifier_dropout)\n",
    "        self.linear = torch.nn.Linear(config.hidden_size, 1)\n",
    "      \n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids, \n",
    "            attention_mask=None,\n",
    "            token_type_ids=None\n",
    "        ): \n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        output = self.linear(pooled_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_encoder = torch.load('/opt/ml/custom/c_encoder_e40_b16.pt')\n",
    "model_checkpoint = \"klue/bert-base\"\n",
    "# 혹시 위에서 사용한 encoder가 있다면 주석처리 후 진행해주세요 (CUDA ...)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_data = dataset['validation']['question']\n",
    "with torch.no_grad() : \n",
    "    c_encoder.eval()\n",
    "\n",
    "    result_scores = []\n",
    "    result_indices = []\n",
    "    for i in tqdm(range(len(question_data))) :\n",
    "        question = question_data[i]\n",
    "        question_score = []\n",
    "        for indice in tqdm(doc_indices[i]) :\n",
    "            passage = corpus[int(indice)]\n",
    "            tokenized_examples = tokenizer(\n",
    "                question,\n",
    "                passage,\n",
    "                truncation=\"only_second\",\n",
    "                max_length=512,\n",
    "                stride=128,\n",
    "                return_overflowing_tokens=True,\n",
    "                return_offsets_mapping=True,\n",
    "                #return_token_type_ids=False,  # roberta모델을 사용할 경우 False, bert를 사용할 경우 True로 표기해야합니다.\n",
    "                padding=\"max_length\",\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            score = 0\n",
    "            for i in range(len(tokenized_examples['input_ids'])) :\n",
    "                c_input = {\n",
    "                    'input_ids' : torch.tensor(tokenized_examples['input_ids'][i].unsqueeze(dim=0)).to('cuda'),\n",
    "                    'attention_mask' : torch.tensor(tokenized_examples['attention_mask'][i].unsqueeze(dim=0)).to('cuda'),\n",
    "                    'token_type_ids' : torch.tensor(tokenized_examples['token_type_ids'][i].unsqueeze(dim=0)).to('cuda')\n",
    "                }\n",
    "                tmp_score = c_encoder(**c_input).to('cpu')\n",
    "                score += tmp_score\n",
    "            score = score / len(tokenized_examples['input_ids'])\n",
    "            question_score.append(score)\n",
    "        sort_result = torch.sort(torch.tensor(question_score), descending=True)\n",
    "        scores, index_list = sort_result[0], sort_result[1]\n",
    "\n",
    "        result_scores.append(scores.tolist())\n",
    "        result_indices.append(index_list.tolist())        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### result_indices 저장 및 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('listfile.csv', 'w', newline='') as f: \n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(result_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('listfile.csv', 'r', encoding='utf-8') as f:\n",
    "    rdr = csv.reader(f)\n",
    "    for i, line in enumerate(rdr) :\n",
    "        if i == 0 :\n",
    "            kk = line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 끝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_indices = []\n",
    "for i in range(len(doc_indices)) :\n",
    "    t_list = [doc_indices[i][result_indices[i][k]] for k in range(5)]\n",
    "    final_indices.append(t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2dac73caa94c2b9705d216608590be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dense retrieval: ', max=600.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total = []\n",
    "for idx, example in enumerate(\n",
    "        tqdm(dataset['validation'], desc=\"Dense retrieval: \")\n",
    "    ):\n",
    "        tmp = {\n",
    "            # Query와 해당 id를 반환합니다.\n",
    "            \"question\": example[\"question\"],\n",
    "            \"id\": example[\"id\"],\n",
    "            # Retrieve한 Passage의 id, context를 반환합니다.\n",
    "            \"context_id\": final_indices[idx],\n",
    "            \"context\": [corpus[pid] for pid in final_indices[idx]]\n",
    "        }\n",
    "        if \"context\" in example.keys() and \"answers\" in example.keys():\n",
    "            # validation 데이터를 사용하면 ground_truth context와 answer도 반환합니다.\n",
    "            tmp[\"original_context\"] = example[\"context\"]\n",
    "            tmp[\"answers\"] = example[\"answers\"]\n",
    "        total.append(tmp)\n",
    "\n",
    "cqas_50 = pd.DataFrame(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cqas_50.to_csv('elastic_crossencoder.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e50a9433c874a2693c9469966b4f1b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dense retrieval: ', max=600.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total = []\n",
    "for idx, example in enumerate(\n",
    "        tqdm(dataset['validation'], desc=\"Dense retrieval: \")\n",
    "    ):\n",
    "        tmp = {\n",
    "            # Query와 해당 id를 반환합니다.\n",
    "            \"question\": example[\"question\"],\n",
    "            \"id\": example[\"id\"],\n",
    "            # Retrieve한 Passage의 id, context를 반환합니다.\n",
    "            \"context_id\": final_indices[idx],\n",
    "            \"context\": \" \".join(  # 기존에는 ' '.join()\n",
    "                [corpus[pid] for pid in final_indices[idx]]\n",
    "            ),\n",
    "        }\n",
    "        if \"context\" in example.keys() and \"answers\" in example.keys():\n",
    "            # validation 데이터를 사용하면 ground_truth context와 answer도 반환합니다.\n",
    "            tmp[\"original_context\"] = example[\"context\"]\n",
    "            tmp[\"answers\"] = example[\"answers\"]\n",
    "        total.append(tmp)\n",
    "\n",
    "cqas_50 = pd.DataFrame(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_length = []\n",
    "for i in range(len(cqas_50)) :\n",
    "    if cqas_50['original_context'][i] in cqas_50['context'][i] :\n",
    "        correct_length.append(i)\n",
    "print(len(correct_length) / len(dataset['validation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cqas_50.to_csv('test_b16_special_shuffle_elastic_ce40_t5.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
