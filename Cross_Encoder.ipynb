{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==1.7.1\n",
    "!pip install transformers==4.11.3\n",
    "!pip install huggingface-hub==0.0.19\n",
    "!pip install datasets==1.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BertModel, RobertaModel,\n",
    "    BertPreTrainedModel,\n",
    "    AdamW, get_linear_schedule_with_warmup,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import (\n",
    "    Dataset,\n",
    "    load_from_disk,\n",
    "    concatenate_datasets,\n",
    ")\n",
    "\n",
    "from typing import List\n",
    "from torch.utils.data import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 난수 고정\n",
    "def set_seed(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "set_seed(42) # magic number :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:[1.7.1].\n",
      "device:[cuda:0].\n"
     ]
    }
   ],
   "source": [
    "print (\"PyTorch version:[%s].\"%(torch.__version__))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (\"device:[%s].\"%(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEncoder(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertEncoder, self).__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.init_weights()\n",
    "        classifier_dropout=(\n",
    "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = torch.nn.Dropout(classifier_dropout)\n",
    "        self.linear = torch.nn.Linear(config.hidden_size, 1)\n",
    "      \n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids, \n",
    "            attention_mask=None,\n",
    "            token_type_ids=None\n",
    "        ): \n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        output = self.linear(pooled_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('/opt/ml/data/train_dataset')\n",
    "train_dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSampler(Sampler) :\n",
    "    def __init__(self, data_source, batch_size) :\n",
    "        self.data_source = data_source\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self) :\n",
    "        n = len(self.data_source)\n",
    "        index_list = []\n",
    "        while True :\n",
    "            out = True\n",
    "            for i in range(self.batch_size) :\n",
    "                tmp_data = random.randint(0, n-1)\n",
    "                index_list.append(tmp_data)\n",
    "            for f, s in zip(index_list, index_list[1:]) :\n",
    "                if abs(s-f) <= 2 :\n",
    "                    out = False\n",
    "            if out == True :\n",
    "                break\n",
    "\n",
    "        while True : # 추가 삽입\n",
    "            tmp_data = random.randint(0, n-1)\n",
    "            if (tmp_data not in index_list) and \\\n",
    "                (abs(tmp_data-index_list[-i]) > 2 for i in range(1,self.batch_size+1)) \\\n",
    "            : \n",
    "                index_list.append(tmp_data)\n",
    "            if len(index_list) == n :\n",
    "                break\n",
    "        return iter(index_list)\n",
    "\n",
    "    def __len__(self) :\n",
    "        return len(self.data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwer\n",
    "class DenseRetrieval:\n",
    "    def __init__(self,\n",
    "        args,\n",
    "        dataset,\n",
    "        tokenizer,\n",
    "        cross_encoder,\n",
    "        sampler\n",
    "    ):\n",
    "        \"\"\"\n",
    "        학습과 추론에 사용될 여러 셋업을 마쳐봅시다.\n",
    "        \"\"\"\n",
    "\n",
    "        self.args = args\n",
    "        self.dataset = dataset\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.cross_encoder = cross_encoder\n",
    "        self.sampler = sampler\n",
    "\n",
    "    def train(self, args=None, tokenizer = None):\n",
    "        if args is None:\n",
    "            args = self.args\n",
    "        if tokenizer is None :\n",
    "            tokenizer = self.tokenizer\n",
    "        \n",
    "        tokenized_examples = tokenizer(\n",
    "            self.dataset['question'],\n",
    "            self.dataset['context'],\n",
    "            truncation=\"only_second\",\n",
    "            max_length=512,\n",
    "            stride=128,\n",
    "            return_overflowing_tokens=True,\n",
    "            return_offsets_mapping=True,\n",
    "            # return_token_type_ids=False,  # roberta모델을 사용할 경우 False, bert를 사용할 경우 True로 표기해야합니다.\n",
    "            padding=\"max_length\",\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        train_dataset = TensorDataset(\n",
    "            tokenized_examples['input_ids'],\n",
    "            tokenized_examples['attention_mask'],\n",
    "            tokenized_examples['token_type_ids']\n",
    "        )\n",
    "\n",
    "        sampler = self.sampler(train_dataset, args.per_device_train_batch_size)\n",
    "        train_dataloader = DataLoader(train_dataset,\n",
    "                                      batch_size=args.per_device_train_batch_size,\n",
    "                                      sampler = sampler,\n",
    "                                      drop_last = True)\n",
    "                                      \n",
    "        no_decay = [\"bias\" ,\"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\"params\": [p for n, p in self.cross_encoder.named_parameters() if not any(nd in n for nd in no_decay)], \"weight_decay\": args.weight_decay},\n",
    "            {\"params\": [p for n, p in self.cross_encoder.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "        ]\n",
    "        optimizer = AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=args.learning_rate,\n",
    "            # eps=args.adam_epsilon\n",
    "        )\n",
    "\n",
    "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total)\n",
    "        \n",
    "        self.cross_encoder.zero_grad()\n",
    "        \n",
    "        train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\")\n",
    "        self.cross_encoder.train()\n",
    "        for epoch, _ in enumerate(train_iterator) :\n",
    "            epoch_iterator = tqdm(train_dataloader, desc = 'Iteration')\n",
    "            losses = 0\n",
    "            for step, batch in enumerate(epoch_iterator) :\n",
    "                # if torch.cuda.is_available() :\n",
    "                #     batch = tuple(t.cuda() for t in batch)\n",
    "                \n",
    "                cross_inputs = {\n",
    "                    'input_ids': batch[0],\n",
    "                    'attention_mask' : batch[1],\n",
    "                    'token_type_ids' : batch[2]\n",
    "                }\n",
    "                for k in cross_inputs.keys() :\n",
    "                    cross_inputs[k] = cross_inputs[k].tolist()\n",
    "\n",
    "                new_input_ids = []\n",
    "                new_attention_mask = []\n",
    "                new_token_type_ids = []\n",
    "                for i in range(len(cross_inputs['input_ids'])) :\n",
    "                    sep_index = cross_inputs['input_ids'][i].index(3) # [SEP] token의 index\n",
    "\n",
    "                    for j in range(len(cross_inputs['input_ids'])) :\n",
    "                        query_id = cross_inputs['input_ids'][i][:sep_index]\n",
    "                        query_att = cross_inputs['attention_mask'][i][:sep_index]\n",
    "                        query_tok = cross_inputs['token_type_ids'][i][:sep_index]\n",
    "        \n",
    "                        context_id = cross_inputs['input_ids'][j][sep_index:]\n",
    "                        context_att = cross_inputs['attention_mask'][j][sep_index:]\n",
    "                        context_tok = cross_inputs['token_type_ids'][j][sep_index:]\n",
    "                        query_id.extend(context_id)\n",
    "                        query_att.extend(context_att)\n",
    "                        query_tok.extend(context_tok)\n",
    "                        new_input_ids.append(query_id)\n",
    "                        new_attention_mask.append(query_att)\n",
    "                        new_token_type_ids.append(query_tok)\n",
    "\n",
    "                change_cross_inputs = {\n",
    "                    'input_ids' : torch.tensor(new_input_ids).to('cuda'),\n",
    "                    'attention_mask' : torch.tensor(new_attention_mask).to('cuda'),\n",
    "                    'token_type_ids' : torch.tensor(new_token_type_ids).to('cuda')\n",
    "                }\n",
    "\n",
    "                cross_output = self.cross_encoder(**change_cross_inputs)\n",
    "                cross_output = cross_output.view(-1, args.per_device_train_batch_size)\n",
    "                targets = torch.arange(0, args.per_device_train_batch_size).long()\n",
    "                                \n",
    "                if torch.cuda.is_available():\n",
    "                    targets = targets.to('cuda')\n",
    "\n",
    "                score = F.log_softmax(cross_output, dim = 1)\n",
    "                loss = F.nll_loss(score, targets)\n",
    "                \n",
    "                losses += loss.item()\n",
    "                if step % 100 == 0 :\n",
    "                    print(f'{epoch}epoch loss: {losses/(step+1)}') # Accumulation할 경우 주석처리\n",
    "                \n",
    "                self.cross_encoder.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "        \n",
    "        return self.cross_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertEncoder were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['linear.bias', 'linear.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"dense_retireval\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "model_checkpoint = \"klue/bert-base\"\n",
    "\n",
    "# 혹시 위에서 사용한 encoder가 있다면 주석처리 후 진행해주세요 (CUDA ...)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "cross_encoder = BertEncoder.from_pretrained(model_checkpoint).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54d827aa6854fd8a322f52dd07d2f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0epoch loss: 1.1035704612731934\n",
      "0epoch loss: 0.18624336721541562\n",
      "0epoch loss: 0.10813956529675839\n",
      "0epoch loss: 0.0786655272499881\n",
      "0epoch loss: 0.061980607657823386\n",
      "0epoch loss: 0.05149939898963824\n",
      "0epoch loss: 0.04353808492237893\n",
      "0epoch loss: 0.03798551275547434\n",
      "0epoch loss: 0.03382088217534439\n",
      "0epoch loss: 0.030704726455816195\n",
      "0epoch loss: 0.028170246483781525\n",
      "0epoch loss: 0.02641521077222254\n",
      "0epoch loss: 0.024651965653075203\n",
      "0epoch loss: 0.022974016423186878\n",
      "0epoch loss: 0.021735249884547246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 1/5 [12:34<50:19, 754.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d8df87b93e45c3a47ae5f454fcfb70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1epoch loss: 5.0275000830879435e-05\n",
      "1epoch loss: 0.005915985919669441\n",
      "1epoch loss: 0.003613268038649193\n",
      "1epoch loss: 0.0026920617997302694\n",
      "1epoch loss: 0.002090122697800983\n",
      "1epoch loss: 0.0025501002893540503\n",
      "1epoch loss: 0.002366891297763122\n",
      "1epoch loss: 0.0021212439260073494\n",
      "1epoch loss: 0.00194129908855773\n",
      "1epoch loss: 0.0017827807080122368\n",
      "1epoch loss: 0.0016300902424283103\n",
      "1epoch loss: 0.0015002492954128773\n",
      "1epoch loss: 0.0016055718124293166\n",
      "1epoch loss: 0.001540191611271861\n",
      "1epoch loss: 0.001608899648548943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 2/5 [25:10<37:45, 755.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c38dd7661f064faa83f6a2625ed99eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2epoch loss: 8.225406418205239e-06\n",
      "2epoch loss: 0.00205115335881718\n",
      "2epoch loss: 0.001699466115408527\n",
      "2epoch loss: 0.0011850692211891724\n",
      "2epoch loss: 0.0015586921321314514\n",
      "2epoch loss: 0.0014723290739507837\n",
      "2epoch loss: 0.0013297123628550002\n",
      "2epoch loss: 0.0012239024222480696\n",
      "2epoch loss: 0.0012932829900094357\n",
      "2epoch loss: 0.0011966741712059147\n",
      "2epoch loss: 0.0010902286077272218\n",
      "2epoch loss: 0.0016167552884366206\n",
      "2epoch loss: 0.001528676903431812\n",
      "2epoch loss: 0.0014924419716344395\n",
      "2epoch loss: 0.001410224513608528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 3/5 [37:45<25:09, 754.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cdafcb4e1f84b6dabb86e4b81e44245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3epoch loss: 0.0004370314709376544\n",
      "3epoch loss: 0.0002799427811939072\n",
      "3epoch loss: 0.002573312194297035\n",
      "3epoch loss: 0.0025495006939104995\n",
      "3epoch loss: 0.0020428936650939574\n",
      "3epoch loss: 0.0018965851498055082\n",
      "3epoch loss: 0.0027036759014070944\n",
      "3epoch loss: 0.0023838151372386524\n",
      "3epoch loss: 0.0025146828743072887\n",
      "3epoch loss: 0.0023959424109831692\n",
      "3epoch loss: 0.002415488747367142\n",
      "3epoch loss: 0.0022140688547954398\n",
      "3epoch loss: 0.0025566949302962133\n",
      "3epoch loss: 0.002432697453730541\n",
      "3epoch loss: 0.0022708003295246887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 4/5 [50:20<12:34, 754.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e40d8a58dd490c9963a1c8489f1fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1442.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4epoch loss: 2.2649737729807384e-06\n",
      "4epoch loss: 0.0004296058863674531\n",
      "4epoch loss: 0.0018704596437794578\n",
      "4epoch loss: 0.0013476845011312214\n",
      "4epoch loss: 0.001074609675461623\n",
      "4epoch loss: 0.0008875762978842666\n",
      "4epoch loss: 0.0007734266130895952\n",
      "4epoch loss: 0.0006721240544348424\n",
      "4epoch loss: 0.0006399781945218026\n",
      "4epoch loss: 0.0005796041422958585\n",
      "4epoch loss: 0.0005411629326906543\n",
      "4epoch loss: 0.000566605232685894\n",
      "4epoch loss: 0.000902799399744505\n",
      "4epoch loss: 0.0009050748027463063\n",
      "4epoch loss: 0.0008532462466982899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 5/5 [1:02:54<00:00, 754.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Retriever는 아래와 같이 사용할 수 있도록 코드를 짜봅시다.\n",
    "retriever = DenseRetrieval(\n",
    "    args=args,\n",
    "    dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    cross_encoder=cross_encoder,\n",
    "    sampler = CustomSampler\n",
    ")\n",
    "c_encoder = retriever.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(c_encoder, '/opt/ml/custom/c_encoder_e5.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동맹항에서의 교역에서 세금을 내지 않으려면 지참해야 하는 것은 무엇인가?\n",
      ":\\n; 교역\\n:* 첫 번째 시리즈처럼, 어느 도시에서 사들인 상품을 다른 도시로 수송해, 그 도시에서 다른 상품을 구매한 다음, 처음 상품을 샀던 도시로 가서 상품을 매각하면서 수익을 올려 가는 것이 초반의 기본 방식이다. 면세증을 가지고 있으면 해당 국가의 동맹항에서 교역할 때는 세금이 붙지 않는다. 주인공이 회계 또는 교섭 능력이 있거나 회계 능력을 가지고 있는 항해사를 경리주임에 임명하면 상품 구입 시 가격흥정이 가능하다.\\n:\\n; 조선\\n:* 파손된 배 수리, 중고선 매매, 선수상이나 대포 설치, 함선 건조를 할 수 있다. 투자를 반복해서 상업가치나 공업가치가 최대치가 되면 진귀한 선수상(천사·여신)이나 대포(카로네이드포) 구입이 가능하며, 일부 항구의 조선소에서는 특수한 배(바그, 프리게이트, 철갑선, 쉽)의 건조도 가능하다.\\n:\\n; 투자\\n:* 항구에 있는 교역소나 조선소에 투자를 하면, 다음달에 그 도시의 상업가치나 공업가치가 올라 교역소에 새로운 상품이 등장하거나 조선소에서 대형함선을 건조할 수 있다. 또한, 자국에 대한 지지율이 올라, 지지율이75%이상이 되면 그 항구는 자국의 동맹항이 된다. 단, 각국의 수도(리스본, 세빌리아, 런던, 암스테르담, 제노바, 이스탄불)에는 투자할 수 없다. 대항해시대에는 전 세계에 총 100개의 항구가 존재하는데, 여기서 각국의 수도를 제외하고 나면 자국의 동맹항으로 할 수 있는 최대 항구수는 95개 (나머지 항구 94개 + 자국의 수도) 가 된다.\\n:\\n;해전\\n:* 해적이나 다른 함대를 습격할 수 있다. 기본은 헥스(HEX)방식의 전략 시뮬레이션이지만, 기함끼리 인접하면 제독의 일기토로 승부를 붙이는 것이 가능하다.(자함대 갑판에 편성된 선원수가 타함대 갑판선원수보다 많이 부족한 경우에는 불가). 승리하면 적함대의 함선, 적하, 보물을 빼앗을 수 있다. 해적 명성이 일정치 이상이며, 모험이나 교역 명성보다 높은 경우, 자국의 국왕/총독으로부터 '사략허가서'를 교부받을 수 있으며, 이를 소지한 상태에서 적국의 배를 공격하면 자국에 대한 공헌도가 상승한다.\\n:\\n;탐색\\n:* 항해중, 연안에서 부락을 발견하는 경우가 있다. 부락에 상륙해 주민과의 우호도를 올려 주변을 탐색하면 보물이나 유적, 자연등을 발견하는 경우가 있다. 발견물을 수집가에게 보고하면 모험명성이 오른다.\n"
     ]
    }
   ],
   "source": [
    "valid_corpus = list(set([example['context'] for example in dataset['validation']]))[:10]\n",
    "sample_idx = random.choice(range(len(dataset['validation'])))\n",
    "query = dataset['validation'][sample_idx]['question']\n",
    "ground_truth = dataset['validation'][sample_idx]['context']\n",
    "\n",
    "if not ground_truth in valid_corpus:\n",
    "  valid_corpus.append(ground_truth)\n",
    "\n",
    "print(query)\n",
    "print(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-411eda001f16>:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'input_ids' : torch.tensor(tokenized_examples['input_ids'][i].unsqueeze(dim=0)).to('cuda'),\n",
      "<ipython-input-26-411eda001f16>:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'attention_mask' : torch.tensor(tokenized_examples['attention_mask'][i].unsqueeze(dim=0)).to('cuda'),\n",
      "<ipython-input-26-411eda001f16>:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'token_type_ids' : torch.tensor(tokenized_examples['token_type_ids'][i].unsqueeze(dim=0)).to('cuda')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad() :\n",
    "    c_encoder.eval()\n",
    "    \n",
    "    score_list = []\n",
    "    for i in range(len(valid_corpus)) :\n",
    "        passage = valid_corpus[i]\n",
    "        tokenized_examples = tokenizer(\n",
    "            query,\n",
    "            passage,\n",
    "            truncation=\"only_second\",\n",
    "            max_length=512,\n",
    "            stride=128,\n",
    "            return_overflowing_tokens=True,\n",
    "            return_offsets_mapping=True,\n",
    "            #return_token_type_ids=False,  # roberta모델을 사용할 경우 False, bert를 사용할 경우 True로 표기해야합니다.\n",
    "            padding=\"max_length\",\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        score = 0\n",
    "        for i in range(len(tokenized_examples['input_ids'])) :\n",
    "            c_input = {\n",
    "                'input_ids' : torch.tensor(tokenized_examples['input_ids'][i].unsqueeze(dim=0)).to('cuda'),\n",
    "                'attention_mask' : torch.tensor(tokenized_examples['attention_mask'][i].unsqueeze(dim=0)).to('cuda'),\n",
    "                'token_type_ids' : torch.tensor(tokenized_examples['token_type_ids'][i].unsqueeze(dim=0)).to('cuda')\n",
    "            }\n",
    "            tmp_score = c_encoder(**c_input).to('cpu')\n",
    "            score += tmp_score\n",
    "        score = score / len(tokenized_examples['input_ids'])\n",
    "        score_list.append(score)\n",
    "    sort_result = torch.sort(torch.tensor(score_list), descending=True)\n",
    "\n",
    "    scores, index_list = sort_result[0], sort_result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search query]\n",
      " 동맹항에서의 교역에서 세금을 내지 않으려면 지참해야 하는 것은 무엇인가? \n",
      "\n",
      "[Ground truth passage]\n",
      ":\\n; 교역\\n:* 첫 번째 시리즈처럼, 어느 도시에서 사들인 상품을 다른 도시로 수송해, 그 도시에서 다른 상품을 구매한 다음, 처음 상품을 샀던 도시로 가서 상품을 매각하면서 수익을 올려 가는 것이 초반의 기본 방식이다. 면세증을 가지고 있으면 해당 국가의 동맹항에서 교역할 때는 세금이 붙지 않는다. 주인공이 회계 또는 교섭 능력이 있거나 회계 능력을 가지고 있는 항해사를 경리주임에 임명하면 상품 구입 시 가격흥정이 가능하다.\\n:\\n; 조선\\n:* 파손된 배 수리, 중고선 매매, 선수상이나 대포 설치, 함선 건조를 할 수 있다. 투자를 반복해서 상업가치나 공업가치가 최대치가 되면 진귀한 선수상(천사·여신)이나 대포(카로네이드포) 구입이 가능하며, 일부 항구의 조선소에서는 특수한 배(바그, 프리게이트, 철갑선, 쉽)의 건조도 가능하다.\\n:\\n; 투자\\n:* 항구에 있는 교역소나 조선소에 투자를 하면, 다음달에 그 도시의 상업가치나 공업가치가 올라 교역소에 새로운 상품이 등장하거나 조선소에서 대형함선을 건조할 수 있다. 또한, 자국에 대한 지지율이 올라, 지지율이75%이상이 되면 그 항구는 자국의 동맹항이 된다. 단, 각국의 수도(리스본, 세빌리아, 런던, 암스테르담, 제노바, 이스탄불)에는 투자할 수 없다. 대항해시대에는 전 세계에 총 100개의 항구가 존재하는데, 여기서 각국의 수도를 제외하고 나면 자국의 동맹항으로 할 수 있는 최대 항구수는 95개 (나머지 항구 94개 + 자국의 수도) 가 된다.\\n:\\n;해전\\n:* 해적이나 다른 함대를 습격할 수 있다. 기본은 헥스(HEX)방식의 전략 시뮬레이션이지만, 기함끼리 인접하면 제독의 일기토로 승부를 붙이는 것이 가능하다.(자함대 갑판에 편성된 선원수가 타함대 갑판선원수보다 많이 부족한 경우에는 불가). 승리하면 적함대의 함선, 적하, 보물을 빼앗을 수 있다. 해적 명성이 일정치 이상이며, 모험이나 교역 명성보다 높은 경우, 자국의 국왕/총독으로부터 '사략허가서'를 교부받을 수 있으며, 이를 소지한 상태에서 적국의 배를 공격하면 자국에 대한 공헌도가 상승한다.\\n:\\n;탐색\\n:* 항해중, 연안에서 부락을 발견하는 경우가 있다. 부락에 상륙해 주민과의 우호도를 올려 주변을 탐색하면 보물이나 유적, 자연등을 발견하는 경우가 있다. 발견물을 수집가에게 보고하면 모험명성이 오른다. \n",
      "\n",
      "Top-1 passage with score 7.5275\n",
      ":\\n; 교역\\n:* 첫 번째 시리즈처럼, 어느 도시에서 사들인 상품을 다른 도시로 수송해, 그 도시에서 다른 상품을 구매한 다음, 처음 상품을 샀던 도시로 가서 상품을 매각하면서 수익을 올려 가는 것이 초반의 기본 방식이다. 면세증을 가지고 있으면 해당 국가의 동맹항에서 교역할 때는 세금이 붙지 않는다. 주인공이 회계 또는 교섭 능력이 있거나 회계 능력을 가지고 있는 항해사를 경리주임에 임명하면 상품 구입 시 가격흥정이 가능하다.\\n:\\n; 조선\\n:* 파손된 배 수리, 중고선 매매, 선수상이나 대포 설치, 함선 건조를 할 수 있다. 투자를 반복해서 상업가치나 공업가치가 최대치가 되면 진귀한 선수상(천사·여신)이나 대포(카로네이드포) 구입이 가능하며, 일부 항구의 조선소에서는 특수한 배(바그, 프리게이트, 철갑선, 쉽)의 건조도 가능하다.\\n:\\n; 투자\\n:* 항구에 있는 교역소나 조선소에 투자를 하면, 다음달에 그 도시의 상업가치나 공업가치가 올라 교역소에 새로운 상품이 등장하거나 조선소에서 대형함선을 건조할 수 있다. 또한, 자국에 대한 지지율이 올라, 지지율이75%이상이 되면 그 항구는 자국의 동맹항이 된다. 단, 각국의 수도(리스본, 세빌리아, 런던, 암스테르담, 제노바, 이스탄불)에는 투자할 수 없다. 대항해시대에는 전 세계에 총 100개의 항구가 존재하는데, 여기서 각국의 수도를 제외하고 나면 자국의 동맹항으로 할 수 있는 최대 항구수는 95개 (나머지 항구 94개 + 자국의 수도) 가 된다.\\n:\\n;해전\\n:* 해적이나 다른 함대를 습격할 수 있다. 기본은 헥스(HEX)방식의 전략 시뮬레이션이지만, 기함끼리 인접하면 제독의 일기토로 승부를 붙이는 것이 가능하다.(자함대 갑판에 편성된 선원수가 타함대 갑판선원수보다 많이 부족한 경우에는 불가). 승리하면 적함대의 함선, 적하, 보물을 빼앗을 수 있다. 해적 명성이 일정치 이상이며, 모험이나 교역 명성보다 높은 경우, 자국의 국왕/총독으로부터 '사략허가서'를 교부받을 수 있으며, 이를 소지한 상태에서 적국의 배를 공격하면 자국에 대한 공헌도가 상승한다.\\n:\\n;탐색\\n:* 항해중, 연안에서 부락을 발견하는 경우가 있다. 부락에 상륙해 주민과의 우호도를 올려 주변을 탐색하면 보물이나 유적, 자연등을 발견하는 경우가 있다. 발견물을 수집가에게 보고하면 모험명성이 오른다.\n",
      "Top-2 passage with score -6.3592\n",
      "혼동(混同)은 일상언어로는 대립되는 것을 뒤섞어서 생각하거나, 서로 뒤섞여 하나가 되는 것을 뜻한다. 법률용어로는 채권과 채무가 동일인에게 귀속되는 일로 후자를 혼동이라고 하며, 전자는 착오라고 한다. 대한민국 민법(제 507조)이 정하고 있는 채권의 소멸원인 중 하나로서 채권과 채무가 동일인에게 귀속하는 사실을 말한다. 혼동이 일어나는 사례로는 채권자가 채무자를 상속하거나 채권자인 회사와 채무자인 회사가 합병한 경우, 채무자가 채권을 양수한 경우, 세들어산 집을 구입하여 보증금 채무자가 세입자 자신이 된 경우 등을 들 수 있다. 이러한 경우 자기 자신에 대한 채권을 보유하는 것은 일반적으로 무의미하므로 채권은 원칙적으로 소멸한다. 하지만 채권을 존속시킬 필요가 있는 경우에는 채권이 소멸하지 않는데, 대한민국 민법은 그 채권이 제 3자의 권리의 목적인 때에는 소멸하지 않는다고 규정하고 있다. 또한 어음법과 수표법에 의하면 무기명채권, 지시채권, 사채 등 증권적 채권은 혼동에 의해 소멸하지 않는다.(민법 509조) 상속인이 한정승인을 한 때에도 피상속인에 대한 상속인의 권리의무가 소멸하지 않으므로 채권은 혼동에 의해 소멸하지 않는다.\n",
      "Top-3 passage with score -6.3911\n",
      "프랑스의 십자군 무훈시는 1099년 예루살렘 왕국의 통치자가 된 고드프루아 드 부용의 전설적인 선조로 백조 기사를 등장시킨다. 고드프루아는 중세 기독교 세계에서 전설적인 인물이 되었고 그의 신화적 혈통은 중세 작가들의 인기있는 주제였다.\\n\\n《백조 기사의 탄생》(La Naissance du Chevalier au Cygne)은 백조 아이 이야기를 십자군 무훈시에 도입한 첫번째 작품이다. 텍스트는 백조 기사 어머니의 이름에 따라 1) 엘리옥스, 2) 베아트릭스, 3) 엘리옥스와 베아트릭스의 혼합, 4) 이솜베르테의 네 가지 버전으로 분류 할 수 있다. 이 가운데 이솜브레테 계열의 이야기는 프랑스어 버전에는 없고 스페인의 《첫 해외 정복》(Gran conquista de Ultramar )에만 등장한다. (가스통 파리는 그가 버전 I로 부른 십자군과 구분된 백조-아이 이야기 원형도 비슷하게 분류하였다.)\\n\\n엘리옥스는 돌로파토스 이야기에 가장 가까운 버전이지만 길을 잃은 젊은 영주를 헝가리 너머의 동방의 통치자인 로타이르 왕으로, 처녀를 엘리옥스로 바꾸어 이야기를 보다 궁정식으로 바꾸었다. 로타이르는 길을 잃고 샘 옆에 멈추어 잠들고, 그 사이 산으로 나무를 하러 온 엘리옥스가 등장한다. 한눈에 반한 로타이르는 어머니의 반대를 무릅쓰고 그녀와 결혼하고, 엘리옥스는 자신이 일곱 아이를 낳고 죽을 것이며 그 아이들 가운데 한 명이 동방의 왕이 될 것이라 예언한다.\\n\\n로타이르가 전쟁에 나간 사이 엘리옥스는 일곱 아이를 낳는다. 시어머니 마트로시유는 엘리옥스를 죽이고 하인에게 아이들을 바구니 둘에 담아 숲에 버리라고 명령하고, 로타이르에게는 엘리옥스가 뱀을 낳고서 물려 죽었다고 거짓말을 한다. 그러나 하인은 은둔자의 오두막 옆에 아이들을 놓아두었고, 아이들은 살아 남아 있다가 7년 후 루데마르라는 탐욕스러운 시종에게 발견된다. 보고를 받은 대비는 아이들의 사슬을 빼앗아 없애라고 명령하지만 탐욕에 눈이 먼 시종은 자신의 것을 챙기느라 미처 누이의 사슬을 빼앗지 못한다. 사슬을 빼앗긴 여섯 소년은 백조의 모습으로 날아가고, 이 이야기를 누이로부터 전해 들은 아버지 로타이르는 백조를 죽이지 말라는 명령을 내린다. 왕의 조카가 백조 하나를 활로 쏘자 로타이르는 금대야를 던져 화살을 막았고 백조가 살아난 대신 금대야가 부서진다. 마트로시유는 대야를 수리하라고 사슬달린 목걸이 하나를 건내주고 이로 인해 진실이 드러난다. 결국 아이들은 사람의 모습을 되찾지만 시종이 사슬을 가져간 한 명만은 백조로 남게 되어 백조 기사가 된다. \\n\\n베아트릭스 버전에서 다태아 출산은 간음의 증거로 간주되어 무고를 당한 아이들의 어머니가 처벌받는다. 이 버전에서 어머니는 복수하여 정의를 실현한다.1969 이솜브르테 버전에서 여성은 혐오스러운 결혼 생활에서 도망진 공주로 묘사된다.\n",
      "Top-4 passage with score -6.4838\n",
      "알베르트 아인슈타인에 대해서는 그가 만년에 일본의 철학자인 시노하라 세이에이와 편지를 주고 받은 사실이 알려져 있다. 처음에 시노하라가 보낸 내용은 아인슈타인의 상대성이론을 바탕으로 원자폭탄이 개발된 것, 또는 제2차 세계 대전 중에 당시 미국 대통령인 프랭클린 루스벨트에게 원자폭탄 개발을 촉구하는 서신을 보낸 것, 또한 나치 독일을 증오한 아인슈타인의 태도가 평화주의자로서 있을 수 없는 것이라는 등의 비판적 내용이었다.\\n\\n이러한 비판에 대하여 아인슈타인은 스스로를 평화주의자인 것은 아니라고 밝힌 후에(아인슈타인 자신이 유대인이므로) 나치 독일에 대한 공격은 정의로운 행동이라고 자신을 변호하였고, 또한 원자폭탄에 대해서도 시노하라에게 “당신은 일본 국민으로서 일본의 아시아 침략에 대한 책임이 있다”라고 반론하였다. 또한 일본에 대한 원자폭탄 공격에 대해서는 자신이 일본에 대한 원폭투하를 막을 수 있는 권한이 없었음을 들어 해명하고 있다. 그는 또한 “상대를 비판하고 싶으면 그 상대에 대해서 잘 알아보고 나서 비판하라.”라는 취지의 글을 남겼다. (“나의 방정식은 원자폭탄과는 아무런 관련이 없다”라고 쓰여 있었다고 한다)\\n\\n이렇게 격렬한 비판을 주고 받았던 두 사람은 나중에 화해하여 그 후에는 근황을 주고 받는 편지나 선물 등을 교환했다고 한다. 2001년에 시노하라는 병으로 사망하였고, 2005년에는 유족들이 그들이 주고 받았던 서신을 전문가를 통하여 기증하고 싶다고 발표한 바가 있다. 아인슈타인의 자필 서신은 일본 국내에서는 거의 남아 있지 않아서, 이 서신 교환을 통해 남겨진 6통의 편지는 귀중한 사료적 가치가 있는 것으로 평가받고 있다.\n",
      "Top-5 passage with score -6.7714\n",
      "동아찬영회(東亞讚英會)는 이토 히로부미가 안중근에게 살해된 후 그의 공덕을 기리기 위해 동상을 세우고 표창을 만든다는 목적으로 조직된 단체이다.\\n\\n1909년 11월에 민영우(閔永雨)·이민영(李敏英)의 주도로 취지서를 반포하고 발족했다. 장석주의 주도로 며칠 앞서 출범한 이학재의 이등공송덕비건의소와 연합을 추진해, 함께 10개월 동안 대상으로 14만 환을 모금하기로 했다. 구체적인 사업 계획도 세워졌으나, 이학재와의 다툼 때문에 이등공송덕비건의소를 탈퇴한 윤진학이 동아찬영회에 들어온 뒤 기존 세력과 갈등을 일으키면서 사업은 시행되지 못했다.\\n\\n초기에 동아찬영회를 주도한 발기인은 민영우와 이민영이며, 총재는 장석주, 찬성장은 이완용이 맡았다. 민영휘와 이재곤은 각각 부총재와 회장에 추천되었으나 거절했다.\\n\\n1910년 초에는 민영우를 내몰고 회장을 맡은 윤진학이 한 명당 10전씩의 모금을 받아 관우의 남관왕묘와 같은 이토의 사당을 짓고 봄가을로 제사를 지내겠다는 내용의 예산표를 만들어 여러 곳에 청원했으나, 협잡으로 의심받아 허가를 받지 못했다. 같은 해 3월, 일본에 세워질 이토의 동상을 탐문하여 동상 건립 사업에 참고하기 위해 임원 세 명을 파견할 계획을 세우기도 했다.\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "print(\"[Search query]\\n\", query, \"\\n\")\n",
    "print(\"[Ground truth passage]\")\n",
    "print(ground_truth, \"\\n\")\n",
    "\n",
    "for i in range(k):\n",
    "  print(\"Top-%d passage with score %.4f\" % (i+1, scores[i]))\n",
    "  print(valid_corpus[index_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10,  0,  4,  1,  5,  9,  6,  3,  7,  2,  8])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_examples['input_ids'][0].unsqueeze(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_index_list = []\n",
    "for i in range(len(index_list)) :\n",
    "    temp = index_list[i][:k]\n",
    "    top_k_index_list.appedn(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/data/wikipedia_documents.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    wiki = json.load(f)\n",
    "\n",
    "corpus = list(\n",
    "    dict.fromkeys([v[\"text\"] for v in wiki.values()])\n",
    ")  # set 은 매번 순서가 바뀌므로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ad9a33471943ddbe0f2d5c26be899a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=240.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ba837f384349bd9c163d2ad49e9625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=56737.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-a97d169c2490>:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'input_ids' : torch.tensor(tokenized_examples['input_ids'][i].unsqueeze(dim=0)).to('cuda'),\n",
      "<ipython-input-32-a97d169c2490>:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'attention_mask' : torch.tensor(tokenized_examples['attention_mask'][i].unsqueeze(dim=0)).to('cuda'),\n",
      "<ipython-input-32-a97d169c2490>:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'token_type_ids' : torch.tensor(tokenized_examples['token_type_ids'][i].unsqueeze(dim=0)).to('cuda')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-a97d169c2490>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0;34m'token_type_ids'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_examples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 }\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mtmp_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mc_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtmp_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_examples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b9e1c199b1c1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m     18\u001b[0m         ): \n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m         )\n\u001b[0;32m--> 995\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    996\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    580\u001b[0m                 )\n\u001b[1;32m    581\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    583\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    511\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2328\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2330\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "question_data = dataset['validation']['question']\n",
    "with torch.no_grad() :\n",
    "    c_encoder.eval()\n",
    "\n",
    "    result_scores = []\n",
    "    result_indices = []\n",
    "    for i in tqdm(range(len(question_data))) :\n",
    "        question = question_data[i]\n",
    "\n",
    "        question_score = []\n",
    "        for i in tqdm(range(len(corpus))) :\n",
    "            passage = corpus[i]\n",
    "            tokenized_examples = tokenizer(\n",
    "                question,\n",
    "                passage,\n",
    "                truncation=\"only_second\",\n",
    "                max_length=512,\n",
    "                stride=128,\n",
    "                return_overflowing_tokens=True,\n",
    "                return_offsets_mapping=True,\n",
    "                #return_token_type_ids=False,  # roberta모델을 사용할 경우 False, bert를 사용할 경우 True로 표기해야합니다.\n",
    "                padding=\"max_length\",\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "            score = 0\n",
    "            for i in range(len(tokenized_examples['input_ids'])) :\n",
    "                c_input = {\n",
    "                    'input_ids' : torch.tensor(tokenized_examples['input_ids'][i].unsqueeze(dim=0)).to('cuda'),\n",
    "                    'attention_mask' : torch.tensor(tokenized_examples['attention_mask'][i].unsqueeze(dim=0)).to('cuda'),\n",
    "                    'token_type_ids' : torch.tensor(tokenized_examples['token_type_ids'][i].unsqueeze(dim=0)).to('cuda')\n",
    "                }\n",
    "                tmp_score = c_encoder(**c_input).to('cpu')\n",
    "                score += tmp_score\n",
    "            score = score / len(tokenized_examples['input_ids'])\n",
    "            question_score.append(score)\n",
    "\n",
    "        sort_result = torch.sort(torch.tensor(score_list), descending=True)\n",
    "        scores, index_list = sort_result[0], sort_result[1]\n",
    "\n",
    "        result_scores.append(scores)\n",
    "        result_indices.append(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_index_list = []\n",
    "for i in range(len(index_list)) :\n",
    "    temp = index_list[i][:k]\n",
    "    top_k_index_list.appedn(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = []\n",
    "for idx, example in enumerate(\n",
    "        tqdm(dataset['validation'], desc=\"Dense retrieval: \")\n",
    "    ):\n",
    "        tmp = {\n",
    "            # Query와 해당 id를 반환합니다.\n",
    "            \"question\": example[\"question\"],\n",
    "            \"id\": example[\"id\"],\n",
    "            # Retrieve한 Passage의 id, context를 반환합니다.\n",
    "            \"context_id\": top_k_index_list[idx],\n",
    "            \"context\": \" \".join(  # 기존에는 ' '.join()\n",
    "                [corpus[pid] for pid in top_k_index_list[idx]]\n",
    "            ),\n",
    "        }\n",
    "        if \"context\" in example.keys() and \"answers\" in example.keys():\n",
    "            # validation 데이터를 사용하면 ground_truth context와 answer도 반환합니다.\n",
    "            tmp[\"original_context\"] = example[\"context\"]\n",
    "            tmp[\"answers\"] = example[\"answers\"]\n",
    "        total.append(tmp)\n",
    "\n",
    "cqas_100 = pd.DataFrame(total)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
