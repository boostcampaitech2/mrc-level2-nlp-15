{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BertModel, RobertaModel,\n",
    "    BertPreTrainedModel,\n",
    "    AdamW, get_linear_schedule_with_warmup,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import (\n",
    "    Dataset,\n",
    "    load_from_disk,\n",
    "    concatenate_datasets,\n",
    ")\n",
    "\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 난수 고정\n",
    "def set_seed(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "set_seed(42) # magic number :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:[1.7.1].\n",
      "device:[cuda:0].\n"
     ]
    }
   ],
   "source": [
    "print (\"PyTorch version:[%s].\"%(torch.__version__))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (\"device:[%s].\"%(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('/opt/ml/data/train_dataset')\n",
    "train_dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEncoder(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertEncoder, self).__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.init_weights()\n",
    "      \n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids, \n",
    "            attention_mask=None,\n",
    "            token_type_ids=None\n",
    "        ): \n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        pooled_output = outputs[1]\n",
    "        return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/data/wikipedia_documents.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    wiki = json.load(f)\n",
    "\n",
    "corpus = list(\n",
    "    dict.fromkeys([v[\"text\"] for v in wiki.values()])\n",
    ")  # set 은 매번 순서가 바뀌므로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"klue/bert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/opt/ml/custom/passage_embedding_special_customsample_augmentation_20.bin', 'rb') as file :\n",
    "    p_embs = pickle.load(file)\n",
    "p_embs = p_embs\n",
    "\n",
    "q_encoder = torch.load('/opt/ml/custom/q_encoder_special_customsample_augmentation_20.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relavant_doc(queries, q_encoder, p_embs, k=1) :\n",
    "    with torch.no_grad() :\n",
    "        q_encoder.eval()\n",
    "        q_seqs_val = tokenizer(queries, padding='max_length',truncation=True,return_tensors='pt').to(device)\n",
    "        q_emb = q_encoder(**q_seqs_val).to('cpu')\n",
    "    dot_prod_scores = torch.mm(q_emb, p_embs.T)\n",
    "    sort_result = torch.sort(dot_prod_scores, dim=1, descending=True)\n",
    "\n",
    "    scores, ranks = sort_result[0], sort_result[1]\n",
    "\n",
    "    result_scores = []\n",
    "    result_indices = []\n",
    "    for i in range(len(ranks)) :\n",
    "        result_scores.append(scores[i].tolist()[:k])\n",
    "        result_indices.append(ranks[i].tolist()[:k])\n",
    "    \n",
    "    return result_scores, result_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_scores, doc_indices = get_relavant_doc(dataset['validation']['question'], q_encoder, p_embs, k = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del q_encder\n",
    "# del p_embs\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70832000e3b47e4bdc0b2124369674a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dense retrieval: ', max=240.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.9541666666666667\n"
     ]
    }
   ],
   "source": [
    "# Bi-Encoder Retrieval 정확도 출력\n",
    "a_total = []\n",
    "for idx, example in enumerate(\n",
    "        tqdm(dataset['validation'], desc=\"Dense retrieval: \")\n",
    "    ):\n",
    "        tmp = {\n",
    "            # Query와 해당 id를 반환합니다.\n",
    "            \"question\": example[\"question\"],\n",
    "            \"id\": example[\"id\"],\n",
    "            # Retrieve한 Passage의 id, context를 반환합니다.\n",
    "            \"context_id\": doc_indices[idx],\n",
    "            \"context\": \" \".join(  # 기존에는 ' '.join()\n",
    "                [corpus[pid] for pid in doc_indices[idx]]\n",
    "            ),\n",
    "        }\n",
    "        if \"context\" in example.keys() and \"answers\" in example.keys():\n",
    "            # validation 데이터를 사용하면 ground_truth context와 answer도 반환합니다.\n",
    "            tmp[\"original_context\"] = example[\"context\"]\n",
    "            tmp[\"answers\"] = example[\"answers\"]\n",
    "        a_total.append(tmp)\n",
    "\n",
    "b_cqas_50 = pd.DataFrame(a_total)\n",
    "correct_length = []\n",
    "for i in range(len(b_cqas_50)) :\n",
    "    if b_cqas_50['original_context'][i] in b_cqas_50['context'][i] :\n",
    "        correct_length.append(i)\n",
    "print(len(correct_length) / len(dataset['validation']))\n",
    "# 출력결과 0.916666"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross_Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"klue/roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, RobertaPreTrainedModel, RobertaModel\n",
    "\n",
    "class RoBertaEncoder(RobertaPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(RoBertaEncoder, self).__init__(config)\n",
    "\n",
    "        self.roberta = RobertaModel(config)\n",
    "        self.init_weights()\n",
    "        classifier_dropout=(\n",
    "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = torch.nn.Dropout(classifier_dropout)\n",
    "        self.linear = torch.nn.Linear(config.hidden_size, 1)\n",
    "      \n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids, \n",
    "            attention_mask=None,\n",
    "            #token_type_ids=None\n",
    "        ): \n",
    "\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            #token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        output = self.linear(pooled_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_encoder = torch.load('/opt/ml/custom/c_roberta_encoder_e40_b16.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Data의 경우 약 40분 소요\n",
    "question_data = dataset['validation']['question']\n",
    "with torch.no_grad() : \n",
    "    c_encoder.eval()\n",
    "\n",
    "    result_scores = []\n",
    "    result_indices = []\n",
    "    for i in tqdm(range(len(question_data))) :\n",
    "        question = question_data[i]\n",
    "        question_score = []\n",
    "        for indice in tqdm(doc_indices[i]) :\n",
    "            passage = corpus[indice]\n",
    "            tokenized_examples = tokenizer(\n",
    "                question,\n",
    "                passage,\n",
    "                truncation=\"only_second\",\n",
    "                max_length=512,\n",
    "                stride=128,\n",
    "                return_overflowing_tokens=True,\n",
    "                return_offsets_mapping=True,\n",
    "                return_token_type_ids=False,  # roberta모델을 사용할 경우 False, bert를 사용할 경우 True로 표기해야합니다.\n",
    "                padding=\"max_length\",\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            score = 0\n",
    "            for i in range(len(tokenized_examples['input_ids'])) :\n",
    "                c_input = {\n",
    "                    'input_ids' : torch.tensor(tokenized_examples['input_ids'][i].unsqueeze(dim=0)).to('cuda'),\n",
    "                    'attention_mask' : torch.tensor(tokenized_examples['attention_mask'][i].unsqueeze(dim=0)).to('cuda'),\n",
    "                    # 'token_type_ids' : torch.tensor(tokenized_examples['token_type_ids'][i].unsqueeze(dim=0)).to('cuda')\n",
    "                }\n",
    "                tmp_score = c_encoder(**c_input).to('cpu')\n",
    "                score += tmp_score\n",
    "            score = score / len(tokenized_examples['input_ids'])\n",
    "            question_score.append(score)\n",
    "        sort_result = torch.sort(torch.tensor(question_score), descending=True)\n",
    "        scores, index_list = sort_result[0], sort_result[1]\n",
    "\n",
    "        result_scores.append(scores.tolist())\n",
    "        result_indices.append(index_list.tolist())        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### result_scores & indices 저장 및 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('valid_bi_ce_indices_roberta.csv', 'w', newline='') as f: \n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(result_indices)\n",
    "with open('valid_bi_ce_scores_roberta.csv', 'w', newline='') as f: \n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(result_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('valid_bi_ce_indices_roberta.csv', 'r', encoding='utf-8') as f:\n",
    "    rdr = csv.reader(f)\n",
    "    for i, line in enumerate(rdr) :\n",
    "        if i == 0 :\n",
    "            check_indices = line\n",
    "with open('valid_bi_ce_scores_roberta.csv', 'r', encoding='utf-8') as f:\n",
    "    rdr = csv.reader(f)\n",
    "    for i, line in enumerate(rdr) :\n",
    "        if i == 0 :\n",
    "            check_scores = line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_indices = []\n",
    "result_scores = []\n",
    "for i in range(len(check_indices)) :\n",
    "    result_indices.append(eval(check_indices[i]))\n",
    "    result_scores.append(eval(check_scores[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 점수비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_indices = []\n",
    "final_scores = []\n",
    "for i in range(len(doc_indices)) :\n",
    "    t_list = [doc_indices[i][result_indices[i][k]] for k in range(100)]\n",
    "    s_list = result_scores[i][:100]\n",
    "    final_indices.append(t_list)\n",
    "    final_scores.append(s_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58fc16e5dca8486a95fcceef558fe623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dense retrieval: ', max=240.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross Encoder 정확도 출력\n",
    "total = []\n",
    "for idx, example in enumerate(\n",
    "        tqdm(dataset['validation'], desc=\"Dense retrieval: \")\n",
    "    ):\n",
    "        tmp = {\n",
    "            # Query와 해당 id를 반환합니다.\n",
    "            \"question\": example[\"question\"],\n",
    "            \"id\": example[\"id\"],\n",
    "            # Retrieve한 Passage의 id, context를 반환합니다.\n",
    "            \"context_id\": final_indices[idx],\n",
    "            \"context\": \" \".join(  # 기존에는 ' '.join()\n",
    "                [corpus[pid] for pid in final_indices[idx]]\n",
    "            ),\n",
    "        }\n",
    "        if \"context\" in example.keys() and \"answers\" in example.keys():\n",
    "            # validation 데이터를 사용하면 ground_truth context와 answer도 반환합니다.\n",
    "            tmp[\"original_context\"] = example[\"context\"]\n",
    "            tmp[\"answers\"] = example[\"answers\"]\n",
    "        total.append(tmp)\n",
    "\n",
    "cqas_50 = pd.DataFrame(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n"
     ]
    }
   ],
   "source": [
    "# 출력결과 0.8708\n",
    "correct_length = []\n",
    "for i in range(len(cqas_50)) :\n",
    "    if cqas_50['original_context'][i] in cqas_50['context'][i] :\n",
    "        correct_length.append(i)\n",
    "print(len(correct_length) / len(dataset['validation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cqas_50.to_csv('valid_roberta_augmentation_be_ce_t5.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only Elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/opt/ml/custom/new_modified_elastic_top100_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/data/wikipedia_documents.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    wiki = json.load(f)\n",
    "\n",
    "omit_corpus = list(\n",
    "    dict.fromkeys([v[\"text\"] for v in wiki.values()])\n",
    ")  # set 은 매번 순서가 바뀌므로\n",
    "\n",
    "corpus = []\n",
    "for v in wiki.values() :\n",
    "    corpus.append(v['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f846fe54aa7c4c95b8b7d9a6dad74208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=240.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "elastic_indices = []\n",
    "elastic_scores = []\n",
    "for i in tqdm(range(len(data))) :\n",
    "    tt = eval(data['candidate_ids'][i])\n",
    "    tmp_indices = []\n",
    "    tmp_scores = []\n",
    "    for j in range(4) :# range(len(tt)) :\n",
    "        original_index = omit_corpus.index(corpus[int(tt[j][0])])\n",
    "        tmp_indices.append(original_index)\n",
    "        tmp_scores.append(tt[j][1])\n",
    "    elastic_indices.append(tmp_indices)\n",
    "    elastic_scores.append(tmp_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6d0e2ddbad4fa69c27b6dd1a3d4e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dense retrieval: ', max=240.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Elastic\n",
    "total = []\n",
    "for idx, example in enumerate(\n",
    "        tqdm(dataset['validation'], desc=\"Dense retrieval: \")\n",
    "    ):\n",
    "        tmp = {\n",
    "            # Query와 해당 id를 반환합니다.\n",
    "            \"question\": example[\"question\"],\n",
    "            \"id\": example[\"id\"],\n",
    "            # Retrieve한 Passage의 id, context를 반환합니다.\n",
    "            \"context_id\": elastic_indices[idx],\n",
    "            \"context\": \" \".join(  # 기존에는 ' '.join()\n",
    "                [omit_corpus[pid] for pid in elastic_indices[idx]]\n",
    "            ),\n",
    "        }\n",
    "        if \"context\" in example.keys() and \"answers\" in example.keys():\n",
    "            # validation 데이터를 사용하면 ground_truth context와 answer도 반환합니다.\n",
    "            tmp[\"original_context\"] = example[\"context\"]\n",
    "            tmp[\"answers\"] = example[\"answers\"]\n",
    "        total.append(tmp)\n",
    "\n",
    "elasitc_data = pd.DataFrame(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8458333333333333\n"
     ]
    }
   ],
   "source": [
    "correct_length = []\n",
    "for i in range(len(elasitc_data)) :\n",
    "    if elasitc_data['original_context'][i] in elasitc_data['context'][i] :\n",
    "        correct_length.append(i)\n",
    "print(len(correct_length) / len(dataset['validation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "elasitc_data.to_csv('new_special_elastic_t4.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic with CrossEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/opt/ml/custom/es100valid_with_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/data/wikipedia_documents.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    wiki = json.load(f)\n",
    "\n",
    "omit_corpus = list(\n",
    "    dict.fromkeys([v[\"text\"] for v in wiki.values()])\n",
    ")  # set 은 매번 순서가 바뀌므로\n",
    "\n",
    "corpus = []\n",
    "for v in wiki.values() :\n",
    "    corpus.append(v['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875a52910d5f40f583486841923b1380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=240.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "elastic_indices = []\n",
    "elastic_scores = []\n",
    "for i in tqdm(range(len(data))) :\n",
    "    tt = eval(data['candidate_ids'][i])\n",
    "    tmp_indices = []\n",
    "    tmp_scores = []\n",
    "    for j in range(len(tt)) :\n",
    "        original_index = omit_corpus.index(corpus[tt[j][0]])\n",
    "        tmp_indices.append(original_index)\n",
    "        tmp_scores.append(tt[j][1])\n",
    "    elastic_indices.append(tmp_indices)\n",
    "    elastic_scores.append(tmp_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEncoder(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertEncoder, self).__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.init_weights()\n",
    "        classifier_dropout=(\n",
    "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = torch.nn.Dropout(classifier_dropout)\n",
    "        self.linear = torch.nn.Linear(config.hidden_size, 1)\n",
    "      \n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids, \n",
    "            attention_mask=None,\n",
    "            token_type_ids=None\n",
    "        ): \n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        output = self.linear(pooled_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_encoder = torch.load('/opt/ml/custom/c_encoder_e40_b16.pt')\n",
    "model_checkpoint = \"klue/bert-base\"\n",
    "# 혹시 위에서 사용한 encoder가 있다면 주석처리 후 진행해주세요 (CUDA ...)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_data = dataset['validation']['question']\n",
    "with torch.no_grad() : \n",
    "    c_encoder.eval()\n",
    "\n",
    "    elastic_result_scores = []\n",
    "    elastic_result_indices = []\n",
    "    for i in tqdm(range(len(question_data))) :\n",
    "        question = question_data[i]\n",
    "        question_score = []\n",
    "        for indice in elastic_indices[i] :\n",
    "            passage = omit_corpus[indice]\n",
    "            tokenized_examples = tokenizer(\n",
    "                question,\n",
    "                passage,\n",
    "                truncation=\"only_second\",\n",
    "                max_length=512,\n",
    "                stride=128,\n",
    "                return_overflowing_tokens=True,\n",
    "                return_offsets_mapping=True,\n",
    "                #return_token_type_ids=False,  # roberta모델을 사용할 경우 False, bert를 사용할 경우 True로 표기해야합니다.\n",
    "                padding=\"max_length\",\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            score = 0\n",
    "            for i in range(len(tokenized_examples['input_ids'])) :\n",
    "                c_input = {\n",
    "                    'input_ids' : torch.tensor(tokenized_examples['input_ids'][i].unsqueeze(dim=0)).to('cuda'),\n",
    "                    'attention_mask' : torch.tensor(tokenized_examples['attention_mask'][i].unsqueeze(dim=0)).to('cuda'),\n",
    "                    'token_type_ids' : torch.tensor(tokenized_examples['token_type_ids'][i].unsqueeze(dim=0)).to('cuda')\n",
    "                }\n",
    "                tmp_score = c_encoder(**c_input).to('cpu')\n",
    "                score += tmp_score\n",
    "            score = score / len(tokenized_examples['input_ids'])\n",
    "            question_score.append(score)\n",
    "        sort_result = torch.sort(torch.tensor(question_score), descending=True)\n",
    "        scores, index_list = sort_result[0], sort_result[1]\n",
    "\n",
    "        elastic_result_scores.append(scores.tolist())\n",
    "        elastic_result_indices.append(index_list.tolist())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_final_indices = []\n",
    "for i in range(len(elastic_indices)) :\n",
    "    t_list = [elastic_indices[i][elastic_result_indices[i][k]] for k in range(100)]\n",
    "    elastic_final_indices.append(t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3456f13199114c0eab91f79d7289988e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dense retrieval: ', max=240.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total = []\n",
    "for idx, example in enumerate(\n",
    "        tqdm(dataset['validation'], desc=\"Dense retrieval: \")\n",
    "    ):\n",
    "        tmp = {\n",
    "            # Query와 해당 id를 반환합니다.\n",
    "            \"question\": example[\"question\"],\n",
    "            \"id\": example[\"id\"],\n",
    "            # Retrieve한 Passage의 id, context를 반환합니다.\n",
    "            \"context_id\": elastic_final_indices[idx],\n",
    "            \"context\": \" \".join(  # 기존에는 ' '.join()\n",
    "                [omit_corpus[pid] for pid in elastic_final_indices[idx]]\n",
    "            ),\n",
    "        }\n",
    "        if \"context\" in example.keys() and \"answers\" in example.keys():\n",
    "            # validation 데이터를 사용하면 ground_truth context와 answer도 반환합니다.\n",
    "            tmp[\"original_context\"] = example[\"context\"]\n",
    "            tmp[\"answers\"] = example[\"answers\"]\n",
    "        total.append(tmp)\n",
    "\n",
    "cqas_50 = pd.DataFrame(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9708333333333333\n"
     ]
    }
   ],
   "source": [
    "correct_length = []\n",
    "for i in range(len(cqas_50)) :\n",
    "    if cqas_50['original_context'][i] in cqas_50['context'][i] :\n",
    "        correct_length.append(i)\n",
    "print(len(correct_length) / len(dataset['validation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastic indices: [4459, 5294, 45213, 45585, 42795, 11263, 16268, 38008, 27888, 27943]\n",
      "bi-cross encoder [5294, 4459, 18273, 40586, 29340, 9728, 18465, 16268, 8986, 56287]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print('elastic indices:', elastic_indices[i][:10])\n",
    "print('bi-cross encoder', final_indices[i][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f62417ca5e24f8f87724b2c2e985736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "scale_ce = []\n",
    "scale_elastic = []\n",
    "for ce, elastic in tqdm(zip(final_scores, elastic_scores)) :\n",
    "    temp_ce = np.array(ce).reshape(-1, 1)\n",
    "    temp_el = np.array(elastic).reshape(-1, 1)\n",
    "    scale_ce.append(scaler.fit_transform(temp_ce).reshape(-1).tolist())\n",
    "    scale_elastic.append(scaler.fit_transform(temp_el).reshape(-1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_scores = []\n",
    "real_indices = []\n",
    "for i in range(len(final_scores)) :\n",
    "    doc = {}\n",
    "    for j in range(len(final_scores[0])) :\n",
    "        doc[final_indices[i][j]] = final_scores[i][j] * 2\n",
    "    \n",
    "    for j in range(len(elastic_scores[i])) :\n",
    "        if elastic_indices[i][j] in doc.keys() :\n",
    "            doc[elastic_indices[i][j]] += elastic_scores[i][j]\n",
    "        else :\n",
    "            doc[elastic_indices[i][j]] = elastic_scores[i][j]\n",
    "    doc = dict(sorted(doc.items(), key = lambda x: x[1], reverse = True))\n",
    "    real_scores.append(list(doc.values()))\n",
    "    real_indices.append(list(doc.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_scores = []\n",
    "real_indices = []\n",
    "for i in range(len(scale_ce)) :\n",
    "    doc = {}\n",
    "    for j in range(len(scale_ce[0])) :\n",
    "        doc[final_indices[i][j]] = scale_ce[i][j]\n",
    "    \n",
    "    for j in range(len(scale_elastic[i])) :\n",
    "        if elastic_indices[i][j] in doc.keys() :\n",
    "            doc[elastic_indices[i][j]] += scale_elastic[i][j]\n",
    "        else :\n",
    "            doc[elastic_indices[i][j]] = scale_elastic[i][j]\n",
    "    doc = dict(sorted(doc.items(), key = lambda x: x[1], reverse = True))\n",
    "    real_scores.append(list(doc.values()))\n",
    "    real_indices.append(list(doc.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastic indices: [4459, 5294, 45213, 45585, 42795, 11263, 16268, 38008, 27888, 27943]\n",
      "bi-cross encoder [5294, 4459, 18273, 40586, 29340, 9728, 18465, 16268, 8986, 56287]\n",
      "ensemble: [5294, 4459, 16268, 18273, 5694, 29340, 1277, 22010, 20964, 11831]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print('elastic indices:', elastic_indices[i][:10])\n",
    "print('bi-cross encoder', final_indices[i][:10])\n",
    "print('ensemble:', real_indices[i][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_end_indices = []\n",
    "for i in range(len(real_indices)) :\n",
    "    t_list = [real_indices[i][k] for k in range(5)]\n",
    "    the_end_indices.append(t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0a820bcfe34391a061f26dd2358bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dense retrieval: ', max=240.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final = []\n",
    "for idx, example in enumerate(\n",
    "        tqdm(dataset['validation'], desc=\"Dense retrieval: \")\n",
    "    ):\n",
    "        tmp = {\n",
    "            # Query와 해당 id를 반환합니다.\n",
    "            \"question\": example[\"question\"],\n",
    "            \"id\": example[\"id\"],\n",
    "            # Retrieve한 Passage의 id, context를 반환합니다.\n",
    "            \"context_id\": the_end_indices[idx],\n",
    "            \"context\": \" \".join(  # 기존에는 ' '.join()\n",
    "                [omit_corpus[pid] for pid in the_end_indices[idx]]\n",
    "            ),\n",
    "        }\n",
    "        if \"context\" in example.keys() and \"answers\" in example.keys():\n",
    "            # validation 데이터를 사용하면 ground_truth context와 answer도 반환합니다.\n",
    "            tmp[\"original_context\"] = example[\"context\"]\n",
    "            tmp[\"answers\"] = example[\"answers\"]\n",
    "        final.append(tmp)\n",
    "\n",
    "cqas_50 = pd.DataFrame(final)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8916666666666667\n"
     ]
    }
   ],
   "source": [
    "correct_length = []\n",
    "for i in range(len(cqas_50)) :\n",
    "    if cqas_50['original_context'][i] in cqas_50['context'][i] :\n",
    "        correct_length.append(i)\n",
    "print(len(correct_length) / len(dataset['validation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cqas_50.to_csv('valid_roberta_dpr_ce_special_new_ela_ensemble_t2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastic indices: [14109, 14110, 4459, 5294, 45213, 45585, 42795, 11263, 16268, 38008]\n",
      "elastic final indices: [5294, 4459, 18273, 35047, 20964, 16268, 11263, 11831, 1277, 29340]\n",
      "bi-cross encoder [5294, 4459, 18273, 9728, 20964, 35270, 40128, 16268, 22010, 8986]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print('elastic indices:', elastic_indices[i][:10])\n",
    "print('elastic final indices:', elastic_final_indices[i][:10])\n",
    "print('bi-cross encoder', final_indices[i][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6796dfbf5a6473d90d8f6823063d16c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "scale_ce = []\n",
    "scale_elastic = []\n",
    "for ce, elastic in tqdm(zip(final_scores, elastic_final_indices)) :\n",
    "    temp_ce = np.array(ce).reshape(-1, 1)\n",
    "    temp_el = np.array(elastic).reshape(-1, 1)\n",
    "    scale_ce.append(scaler.fit_transform(temp_ce).reshape(-1).tolist())\n",
    "    scale_elastic.append(scaler.fit_transform(temp_el).reshape(-1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_scores = []\n",
    "real_indices = []\n",
    "for i in range(len(scale_ce)) :\n",
    "    doc = {}\n",
    "    for j in range(len(scale_ce[0])) :\n",
    "        doc[final_indices[i][j]] = scale_ce[i][j] * 3\n",
    "    \n",
    "    for j in range(len(scale_elastic[i])) :\n",
    "        if elastic_indices[i][j] in doc.keys() :\n",
    "            doc[elastic_indices[i][j]] += scale_elastic[i][j]\n",
    "        else :\n",
    "            doc[elastic_indices[i][j]] = scale_elastic[i][j]\n",
    "    doc = dict(sorted(doc.items(), key = lambda x: x[1], reverse = True))\n",
    "    real_scores.append(list(doc.values()))\n",
    "    real_indices.append(list(doc.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_end_indices = []\n",
    "for i in range(len(real_indices)) :\n",
    "    t_list = [real_indices[i][k] for k in range(4)]\n",
    "    the_end_indices.append(t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85319ae7415143eea36e3776ed6a3ac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dense retrieval: ', max=240.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final = []\n",
    "for idx, example in enumerate(\n",
    "        tqdm(dataset['validation'], desc=\"Dense retrieval: \")\n",
    "    ):\n",
    "        tmp = {\n",
    "            # Query와 해당 id를 반환합니다.\n",
    "            \"question\": example[\"question\"],\n",
    "            \"id\": example[\"id\"],\n",
    "            # Retrieve한 Passage의 id, context를 반환합니다.\n",
    "            \"context_id\": the_end_indices[idx],\n",
    "            \"context\": \" \".join(  # 기존에는 ' '.join()\n",
    "                [omit_corpus[pid] for pid in the_end_indices[idx]]\n",
    "            ),\n",
    "        }\n",
    "        if \"context\" in example.keys() and \"answers\" in example.keys():\n",
    "            # validation 데이터를 사용하면 ground_truth context와 answer도 반환합니다.\n",
    "            tmp[\"original_context\"] = example[\"context\"]\n",
    "            tmp[\"answers\"] = example[\"answers\"]\n",
    "        final.append(tmp)\n",
    "\n",
    "cqas_50 = pd.DataFrame(final)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8625\n"
     ]
    }
   ],
   "source": [
    "correct_length = []\n",
    "for i in range(len(cqas_50)) :\n",
    "    if cqas_50['original_context'][i] in cqas_50['context'][i] :\n",
    "        correct_length.append(i)\n",
    "print(len(correct_length) / len(dataset['validation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
