{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BertModel, RobertaModel,\n",
    "    BertPreTrainedModel,\n",
    "    AdamW, get_linear_schedule_with_warmup,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import (\n",
    "    Dataset,\n",
    "    load_from_disk,\n",
    "    concatenate_datasets,\n",
    ")\n",
    "\n",
    "from typing import List\n",
    "from torch.utils.data import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 난수 고정\n",
    "def set_seed(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "set_seed(42) # magic number :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:[1.7.1].\n",
      "device:[cuda:0].\n"
     ]
    }
   ],
   "source": [
    "print (\"PyTorch version:[%s].\"%(torch.__version__))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (\"device:[%s].\"%(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 'klue/bert-base'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "# num_added_toks = tokenizer.add_tokens(['\\\\n']) # 32000번째로 삽입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('/opt/ml/data/train_dataset')\n",
    "train_dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "unk_count = []\n",
    "for i in tqdm(range(len(train_dataset))) :\n",
    "    unk_count.append(tokenizer(train_dataset['context'][i], max_length = True)['input_ids'].count(1)) # 1 == UNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.median(unk_count))\n",
    "print(np.mean(unk_count))\n",
    "print(np.max(unk_count))\n",
    "print(np.min(unk_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEncoder(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertEncoder, self).__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.init_weights()\n",
    "      \n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids, \n",
    "            attention_mask=None,\n",
    "            token_type_ids=None\n",
    "        ): \n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        pooled_output = outputs[1]\n",
    "        return pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('/opt/ml/data/train_dataset')\n",
    "train_dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset = pd.read_csv('/opt/ml/data/train_dataset/Aug_Encoder.csv')\n",
    "dataset = Dataset.from_pandas(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSampler(Sampler) :\n",
    "    def __init__(self, data_source, batch_size) :\n",
    "        self.data_source = data_source\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self) :\n",
    "        n = len(self.data_source)\n",
    "        index_list = []\n",
    "        while True :\n",
    "            out = True\n",
    "            for i in range(self.batch_size) :\n",
    "                tmp_data = random.randint(0, n-1)\n",
    "                index_list.append(tmp_data)\n",
    "            for f, s in zip(index_list, index_list[1:]) :\n",
    "                if abs(s-f) <= 2 :\n",
    "                    out = False\n",
    "            if out == True :\n",
    "                break\n",
    "\n",
    "        while True : # 추가 삽입\n",
    "            tmp_data = random.randint(0, n-1)\n",
    "            if (tmp_data not in index_list) and \\\n",
    "                (abs(tmp_data-index_list[-i]) > 2 for i in range(1,self.batch_size+1)) \\\n",
    "            : \n",
    "                index_list.append(tmp_data)\n",
    "            if len(index_list) == n :\n",
    "                break\n",
    "        return iter(index_list)\n",
    "\n",
    "    def __len__(self) :\n",
    "        return len(self.data_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anwer\n",
    "class DenseRetrieval:\n",
    "    def __init__(self,\n",
    "        args,\n",
    "        dataset,\n",
    "        tokenizer,\n",
    "        p_encoder,\n",
    "        q_encoder,\n",
    "        sampler\n",
    "    ):\n",
    "        \"\"\"\n",
    "        학습과 추론에 사용될 여러 셋업을 마쳐봅시다.\n",
    "        \"\"\"\n",
    "\n",
    "        self.args = args\n",
    "        self.dataset = dataset\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.p_encoder = p_encoder\n",
    "        self.q_encoder = q_encoder\n",
    "        self.sampler = sampler\n",
    "\n",
    "    def train(self, args=None, tokenizer = None):\n",
    "        if args is None:\n",
    "            args = self.args\n",
    "        if tokenizer is None :\n",
    "            tokenizer = self.tokenizer\n",
    "\n",
    "        for i in (range(len(self.dataset))) :\n",
    "            if i == 0 :\n",
    "                q_seqs = tokenizer(\n",
    "                    self.dataset[i]['question'],\n",
    "                    padding='max_length',\n",
    "                    max_length=512,\n",
    "                    truncation = True,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                p_seqs = tokenizer(\n",
    "                    self.dataset[i]['context'],\n",
    "                    truncation = True,\n",
    "                    stride = 128,\n",
    "                    padding='max_length',\n",
    "                    max_length=512,\n",
    "                    return_overflowing_tokens=True,\n",
    "                    return_offsets_mapping=True,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "\n",
    "                p_seqs.pop('overflow_to_sample_mapping')\n",
    "                p_seqs.pop('offset_mapping')\n",
    "\n",
    "                for k in q_seqs.keys() :\n",
    "                    q_seqs[k] = q_seqs[k].tolist()\n",
    "                    p_seqs[k] = p_seqs[k].tolist()\n",
    "                \n",
    "                initial_p_seqs_length = len(p_seqs['input_ids'])\n",
    "                for j in range(len(p_seqs['input_ids'])) :\n",
    "                    q_seqs['input_ids'].append(q_seqs['input_ids'][0])\n",
    "                    q_seqs['token_type_ids'].append(q_seqs['token_type_ids'][0])\n",
    "                    q_seqs['attention_mask'].append(q_seqs['attention_mask'][0])\n",
    "                    p_seqs['input_ids'].append(p_seqs['input_ids'][j])\n",
    "                    p_seqs['token_type_ids'].append(p_seqs['token_type_ids'][j])\n",
    "                    p_seqs['attention_mask'].append(p_seqs['attention_mask'][j])\n",
    "\n",
    "                q_seqs['input_ids'] = q_seqs['input_ids'][1:]\n",
    "                q_seqs['token_type_ids'] = q_seqs['token_type_ids'][1:]\n",
    "                q_seqs['attention_mask'] = q_seqs['attention_mask'][1:]\n",
    "                p_seqs['input_ids'] = p_seqs['input_ids'][initial_p_seqs_length:]\n",
    "                p_seqs['token_type_ids'] = p_seqs['token_type_ids'][initial_p_seqs_length:]\n",
    "                p_seqs['attention_mask'] = p_seqs['attention_mask'][initial_p_seqs_length:]\n",
    "\n",
    "            else :\n",
    "                tmp_q_seq = tokenizer(\n",
    "                    self.dataset[i]['question'],\n",
    "                    padding='max_length',\n",
    "                    max_length=512,\n",
    "                    truncation = True,\n",
    "                    return_tensors='pt')\n",
    "                tmp_p_seq = tokenizer(\n",
    "                    self.dataset[i]['context'],\n",
    "                    truncation = True,\n",
    "                    stride = 128,\n",
    "                    padding='max_length',\n",
    "                    max_length=512,\n",
    "                    return_overflowing_tokens=True,\n",
    "                    return_offsets_mapping=True,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "\n",
    "                tmp_p_seq.pop('overflow_to_sample_mapping')\n",
    "                tmp_p_seq.pop('offset_mapping')\n",
    "\n",
    "                for k in tmp_p_seq.keys() :\n",
    "                    tmp_p_seq[k] = tmp_p_seq[k].tolist()\n",
    "                    tmp_q_seq[k] = tmp_q_seq[k].tolist()\n",
    "\n",
    "\n",
    "                for j in range(len(tmp_p_seq['input_ids'])) :\n",
    "                    q_seqs['input_ids'].append(tmp_q_seq['input_ids'][0])\n",
    "                    q_seqs['token_type_ids'].append(tmp_q_seq['token_type_ids'][0])\n",
    "                    q_seqs['attention_mask'].append(tmp_q_seq['attention_mask'][0])\n",
    "                    p_seqs['input_ids'].append(tmp_p_seq['input_ids'][j])\n",
    "                    p_seqs['token_type_ids'].append(tmp_p_seq['token_type_ids'][j])\n",
    "                    p_seqs['attention_mask'].append(tmp_p_seq['attention_mask'][j])\n",
    "\n",
    "        for k in q_seqs.keys() :\n",
    "            q_seqs[k] = torch.tensor(q_seqs[k])\n",
    "            p_seqs[k] = torch.tensor(p_seqs[k])\n",
    "\n",
    "        train_dataset = TensorDataset(p_seqs['input_ids'], p_seqs['attention_mask'], p_seqs['token_type_ids'], \n",
    "                        q_seqs['input_ids'], q_seqs['attention_mask'], q_seqs['token_type_ids'])\n",
    "        sampler = self.sampler(train_dataset, args.per_device_train_batch_size)\n",
    "        train_dataloader = DataLoader(train_dataset,\n",
    "                                      batch_size=args.per_device_train_batch_size,\n",
    "                                      sampler = sampler)\n",
    "\n",
    "        no_decay = [\"bias\" ,\"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\"params\": [p for n, p in self.p_encoder.named_parameters() if not any(nd in n for nd in no_decay)], \"weight_decay\": args.weight_decay},\n",
    "            {\"params\": [p for n, p in self.p_encoder.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "            {\"params\": [p for n, p in self.q_encoder.named_parameters() if not any(nd in n for nd in no_decay)], \"weight_decay\": args.weight_decay},\n",
    "            {\"params\": [p for n, p in self.q_encoder.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n",
    "        ]\n",
    "        optimizer = AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=args.learning_rate,\n",
    "            # eps=args.adam_epsilon\n",
    "        )\n",
    "\n",
    "        t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
    "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total)\n",
    "        \n",
    "        global_step = 0\n",
    "\n",
    "        self.p_encoder.zero_grad()\n",
    "        self.q_encoder.zero_grad()\n",
    "        # torch.cuda.empty_cache()\n",
    "\n",
    "        train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\")\n",
    "        self.q_encoder.train()\n",
    "        self.p_encoder.train()\n",
    "        for epoch, _ in enumerate(train_iterator):\n",
    "            epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
    "            loss_value=0 # Accumulation할 때 진행\n",
    "            losses = 0\n",
    "            for step, batch in enumerate(epoch_iterator):\n",
    "                if torch.cuda.is_available():\n",
    "                    batch = tuple(t.cuda() for t in batch)\n",
    "\n",
    "                p_inputs = {'input_ids': batch[0],\n",
    "                            'attention_mask': batch[1],\n",
    "                            'token_type_ids': batch[2]\n",
    "                            }\n",
    "                \n",
    "                q_inputs = {'input_ids': batch[3],\n",
    "                            'attention_mask': batch[4],\n",
    "                            'token_type_ids': batch[5]}\n",
    "\n",
    "                p_outputs = self.p_encoder(**p_inputs)  # (batch_size, emb_dim)\n",
    "                q_outputs = self.q_encoder(**q_inputs)  # (batch_size, emb_dim)\n",
    "\n",
    "                # Calculate similarity score & loss\n",
    "                sim_scores = torch.matmul(q_outputs, torch.transpose(p_outputs, 0, 1))  # (batch_size, emb_dim) x (emb_dim, batch_size) = (batch_size, batch_size)\n",
    "\n",
    "                # target: position of positive samples = diagonal element \n",
    "                # targets = torch.arange(0, args.per_device_train_batch_size).long()\n",
    "                targets = torch.arange(0, len(p_inputs['input_ids'])).long()\n",
    "                \n",
    "                if torch.cuda.is_available():\n",
    "                    targets = targets.to('cuda')\n",
    "                    \n",
    "                sim_scores = F.log_softmax(sim_scores, dim=1)\n",
    "\n",
    "                loss = F.nll_loss(sim_scores, targets)\n",
    "                losses += loss.item()\n",
    "                if step % 100 == 0 :\n",
    "                    print(f'{epoch}epoch loss: {losses/(step+1)}') # Accumulation할 경우 주석처리\n",
    "\n",
    "                # ################ACCUMULATION###############################\n",
    "                # if (step+1) % args.gradient_accumulation_steps == 0 :\n",
    "                #     optimizer.step()\n",
    "                #     scheduler.step()\n",
    "                #     self.q_encoder.zero_grad()\n",
    "                #     self.p_encoder.zero_grad()\n",
    "\n",
    "                # losses += loss.item()\n",
    "                # if (step+1) % 64 == 0:\n",
    "                #     train_loss = losses / 64\n",
    "                #     print(f'training loss: {train_loss:4.4}')\n",
    "                #     losses = 0\n",
    "                # ###########################################################\n",
    "                self.q_encoder.zero_grad()\n",
    "                self.p_encoder.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                # global_step += 1\n",
    "                \n",
    "                #torch.cuda.empty_cache()\n",
    "                del p_inputs, q_inputs\n",
    "\n",
    "        return self.p_encoder, self.q_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"dense_retireval\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "model_checkpoint = \"klue/bert-base\"\n",
    "\n",
    "# 혹시 위에서 사용한 encoder가 있다면 주석처리 후 진행해주세요 (CUDA ...)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "# num_added_toks = tokenizer.add_tokens(['\\\\n']) # 32000번째로 삽입\n",
    "p_encoder = BertEncoder.from_pretrained(model_checkpoint).to(args.device)\n",
    "q_encoder = BertEncoder.from_pretrained(model_checkpoint).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d6d6a8d34f41d999a7a9ad9e30bf70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2663.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0epoch loss: 18.882301330566406\n",
      "0epoch loss: 2.747803631681248\n",
      "0epoch loss: 1.8054619641900433\n",
      "0epoch loss: 1.4123133636636955\n",
      "0epoch loss: 1.1848713733812755\n",
      "0epoch loss: 1.0417346696662655\n",
      "0epoch loss: 0.9306071474814306\n",
      "0epoch loss: 0.8390770195624015\n",
      "0epoch loss: 0.7728449736591047\n",
      "0epoch loss: 0.7189405193238176\n",
      "0epoch loss: 0.6735993443199785\n",
      "0epoch loss: 0.6318205580153833\n",
      "0epoch loss: 0.6004730541335069\n",
      "0epoch loss: 0.5747150797251602\n",
      "0epoch loss: 0.5516593690286893\n",
      "0epoch loss: 0.5282819543282045\n",
      "0epoch loss: 0.509971809012273\n",
      "0epoch loss: 0.49323402389324744\n",
      "0epoch loss: 0.47776585388611437\n",
      "0epoch loss: 0.4650395929750753\n",
      "0epoch loss: 0.4524701598909352\n",
      "0epoch loss: 0.44089864972736387\n",
      "0epoch loss: 0.42957448807852655\n",
      "0epoch loss: 0.419596689456713\n",
      "0epoch loss: 0.41118150971156925\n",
      "0epoch loss: 0.4011327781237818\n",
      "0epoch loss: 0.3935750661385359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   5%|▌         | 1/20 [49:01<15:31:19, 2941.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345eb90d7a99497b9ee88d9860f25a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2663.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1epoch loss: 0.7511616349220276\n",
      "1epoch loss: 0.16321438028117513\n",
      "1epoch loss: 0.14410351590017106\n",
      "1epoch loss: 0.1356538531519461\n",
      "1epoch loss: 0.12847854031590708\n",
      "1epoch loss: 0.13271724936847915\n",
      "1epoch loss: 0.12802190902596805\n",
      "1epoch loss: 0.1296040934319382\n",
      "1epoch loss: 0.1321448438298585\n",
      "1epoch loss: 0.1359717246027125\n",
      "1epoch loss: 0.13792185790834746\n",
      "1epoch loss: 0.14020746292643907\n",
      "1epoch loss: 0.13952978648308753\n",
      "1epoch loss: 0.1402367392770272\n",
      "1epoch loss: 0.1403175803218403\n",
      "1epoch loss: 0.13982271013818287\n",
      "1epoch loss: 0.13844243153770702\n",
      "1epoch loss: 0.1372594161404947\n",
      "1epoch loss: 0.13693721700956035\n",
      "1epoch loss: 0.13726230938535916\n",
      "1epoch loss: 0.13675700249016076\n",
      "1epoch loss: 0.13692868274312436\n",
      "1epoch loss: 0.13826964409903858\n",
      "1epoch loss: 0.13765156910536266\n",
      "1epoch loss: 0.13666977752814025\n",
      "1epoch loss: 0.13681827195988003\n",
      "1epoch loss: 0.13593342950848566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 2/20 [1:49:04<15:41:54, 3139.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5e039605374a2bb59bdd0ae6f1dffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2663.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2epoch loss: 0.007763679139316082\n",
      "2epoch loss: 0.08825566637226596\n",
      "2epoch loss: 0.08698202444232342\n",
      "2epoch loss: 0.09124828076237222\n",
      "2epoch loss: 0.08716737583912201\n",
      "2epoch loss: 0.08735670023163253\n",
      "2epoch loss: 0.08903909053254645\n",
      "2epoch loss: 0.08899323599065202\n",
      "2epoch loss: 0.09122958182966288\n",
      "2epoch loss: 0.09238426927950018\n",
      "2epoch loss: 0.09108896682698435\n",
      "2epoch loss: 0.09041132712712671\n",
      "2epoch loss: 0.0915475081301921\n",
      "2epoch loss: 0.09185384694505602\n",
      "2epoch loss: 0.09113718145681916\n",
      "2epoch loss: 0.09032655353261965\n",
      "2epoch loss: 0.09212168157090589\n",
      "2epoch loss: 0.0910065274064731\n",
      "2epoch loss: 0.09078199004754327\n",
      "2epoch loss: 0.09104163705231604\n",
      "2epoch loss: 0.09191796127064547\n",
      "2epoch loss: 0.09195659400834828\n",
      "2epoch loss: 0.09104120861186132\n",
      "2epoch loss: 0.09162927383335344\n",
      "2epoch loss: 0.09131146227044777\n",
      "2epoch loss: 0.09082713832504305\n",
      "2epoch loss: 0.09106869321609427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  15%|█▌        | 3/20 [2:38:40<14:35:40, 3090.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13bb93609c145e2a5d43ab4cc325cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2663.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3epoch loss: 0.04122619330883026\n",
      "3epoch loss: 0.052865210643581614\n",
      "3epoch loss: 0.058364454257168484\n",
      "3epoch loss: 0.06478566712992513\n",
      "3epoch loss: 0.06682240479546053\n",
      "3epoch loss: 0.06535700859069743\n",
      "3epoch loss: 0.06504507717539743\n",
      "3epoch loss: 0.06541823410249206\n",
      "3epoch loss: 0.06412726471012972\n",
      "3epoch loss: 0.062160380532382244\n",
      "3epoch loss: 0.0632121975494457\n",
      "3epoch loss: 0.06482717621534682\n",
      "3epoch loss: 0.06354080632016479\n",
      "3epoch loss: 0.06465575388410015\n",
      "3epoch loss: 0.06468484456379119\n",
      "3epoch loss: 0.06573525933454571\n",
      "3epoch loss: 0.06722514709698255\n",
      "3epoch loss: 0.06772213765178256\n",
      "3epoch loss: 0.06769718890470991\n",
      "3epoch loss: 0.06857564016399847\n",
      "3epoch loss: 0.06818672790107565\n",
      "3epoch loss: 0.06802390167119693\n",
      "3epoch loss: 0.06794432435769412\n",
      "3epoch loss: 0.06769889704087645\n",
      "3epoch loss: 0.0678313069343867\n",
      "3epoch loss: 0.06796109588438475\n",
      "3epoch loss: 0.06798575875148855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 4/20 [3:28:09<13:34:25, 3054.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c709af8c0eb74a3fbb91f8444db6403a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2663.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4epoch loss: 0.0026811868883669376\n",
      "4epoch loss: 0.06647193891557895\n",
      "4epoch loss: 0.05876003609962674\n",
      "4epoch loss: 0.056513115543879264\n",
      "4epoch loss: 0.05755748955478888\n",
      "4epoch loss: 0.056616972846084086\n",
      "4epoch loss: 0.054613025192708685\n",
      "4epoch loss: 0.05575891390274886\n",
      "4epoch loss: 0.05345471175147036\n",
      "4epoch loss: 0.05310272766506855\n",
      "4epoch loss: 0.05484525754019086\n",
      "4epoch loss: 0.05450681639959144\n",
      "4epoch loss: 0.05529385116286063\n",
      "4epoch loss: 0.05569726868754772\n",
      "4epoch loss: 0.05630592090705967\n",
      "4epoch loss: 0.05545337929111153\n",
      "4epoch loss: 0.05565160839530899\n",
      "4epoch loss: 0.05555988624909183\n",
      "4epoch loss: 0.05635934032778945\n",
      "4epoch loss: 0.05596593000125785\n",
      "4epoch loss: 0.05523817701027147\n",
      "4epoch loss: 0.055197560983081394\n",
      "4epoch loss: 0.055486777895183616\n",
      "4epoch loss: 0.05620977661040418\n",
      "4epoch loss: 0.056431085458984315\n",
      "4epoch loss: 0.05697010399658644\n",
      "4epoch loss: 0.05621083811526379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 5/20 [4:45:14<14:41:19, 3525.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1dd69f711aa46f689909412f6c81d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2663.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5epoch loss: 9.511800453765318e-05\n",
      "5epoch loss: 0.034927003226557916\n",
      "5epoch loss: 0.03319913854328439\n",
      "5epoch loss: 0.03759600826443085\n",
      "5epoch loss: 0.03728396542605073\n",
      "5epoch loss: 0.037056101301837015\n",
      "5epoch loss: 0.037591365234931826\n",
      "5epoch loss: 0.03881895109191824\n",
      "5epoch loss: 0.03972232892502529\n",
      "5epoch loss: 0.04032098132051715\n",
      "5epoch loss: 0.04035350077395884\n",
      "5epoch loss: 0.04018796786687718\n",
      "5epoch loss: 0.0400456768206499\n",
      "5epoch loss: 0.04010884726292888\n",
      "5epoch loss: 0.04094672597442079\n",
      "5epoch loss: 0.041027607561889834\n",
      "5epoch loss: 0.040838528076758446\n",
      "5epoch loss: 0.042139763338486694\n",
      "5epoch loss: 0.042342371162584984\n",
      "5epoch loss: 0.0427219349482905\n",
      "5epoch loss: 0.04240123390495646\n",
      "5epoch loss: 0.042404228715377384\n",
      "5epoch loss: 0.04160721873893785\n",
      "5epoch loss: 0.04146077774443725\n",
      "5epoch loss: 0.04168574307278712\n",
      "5epoch loss: 0.041329070193053506\n",
      "5epoch loss: 0.041409686281731126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 6/20 [5:34:15<13:01:43, 3350.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b7524544aa45458790f479c8a122ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2663.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6epoch loss: 0.010956690646708012\n",
      "6epoch loss: 0.03134032486365085\n",
      "6epoch loss: 0.03433535057271868\n",
      "6epoch loss: 0.036942428865844375\n",
      "6epoch loss: 0.0412732129295606\n",
      "6epoch loss: 0.03904360281177072\n",
      "6epoch loss: 0.03771873735572093\n",
      "6epoch loss: 0.038491236684231336\n",
      "6epoch loss: 0.03856657928534315\n",
      "6epoch loss: 0.03875095745298885\n",
      "6epoch loss: 0.03752509420891173\n",
      "6epoch loss: 0.03716006972340894\n",
      "6epoch loss: 0.03763101525414767\n",
      "6epoch loss: 0.037484534219592705\n",
      "6epoch loss: 0.03771246675218337\n",
      "6epoch loss: 0.039480210463538494\n",
      "6epoch loss: 0.039767279863161524\n",
      "6epoch loss: 0.03925749414605257\n",
      "6epoch loss: 0.03807785396251579\n",
      "6epoch loss: 0.03802188016377943\n",
      "6epoch loss: 0.03745981442968439\n",
      "6epoch loss: 0.03710469225097946\n",
      "6epoch loss: 0.03674464987672148\n",
      "6epoch loss: 0.036671473058015006\n",
      "6epoch loss: 0.03647697445232626\n",
      "6epoch loss: 0.03668966249305325\n",
      "6epoch loss: 0.03717230566505189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  35%|███▌      | 7/20 [6:23:08<11:38:45, 3225.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26aba0aee3624ba19b73c774f0c8c8d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2663.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7epoch loss: 0.05905475839972496\n",
      "7epoch loss: 0.030461209313801706\n",
      "7epoch loss: 0.027848273200458438\n",
      "7epoch loss: 0.030789533991861674\n",
      "7epoch loss: 0.03176456519152208\n",
      "7epoch loss: 0.029146606855386448\n",
      "7epoch loss: 0.031422907286145656\n",
      "7epoch loss: 0.031695667320118005\n",
      "7epoch loss: 0.031488692080495796\n",
      "7epoch loss: 0.032433131691703324\n",
      "7epoch loss: 0.03250395721673155\n",
      "7epoch loss: 0.0316516014839841\n",
      "7epoch loss: 0.03146049086797352\n",
      "7epoch loss: 0.031083177799117165\n",
      "7epoch loss: 0.03156151607259298\n",
      "7epoch loss: 0.031361840209207584\n",
      "7epoch loss: 0.03111973625604937\n",
      "7epoch loss: 0.03110459341825073\n",
      "7epoch loss: 0.03118924599298747\n",
      "7epoch loss: 0.030382275667096455\n",
      "7epoch loss: 0.031033565900964153\n",
      "7epoch loss: 0.030855187353367675\n",
      "7epoch loss: 0.03086829757010128\n",
      "7epoch loss: 0.030332968360525278\n",
      "7epoch loss: 0.03043940640104159\n",
      "7epoch loss: 0.030685321563340313\n",
      "7epoch loss: 0.031076278710601653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 8/20 [7:12:30<10:29:11, 3145.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d092209f564a0a927c62cb01d91277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2663.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8epoch loss: 0.00014339550398290157\n",
      "8epoch loss: 0.04908157797357341\n",
      "8epoch loss: 0.0400167804376724\n",
      "8epoch loss: 0.03730869235878881\n",
      "8epoch loss: 0.03792313358509004\n",
      "8epoch loss: 0.036490290958876195\n",
      "8epoch loss: 0.03571409058429215\n",
      "8epoch loss: 0.033984692012289576\n",
      "8epoch loss: 0.033201059974036363\n",
      "8epoch loss: 0.033600973192820426\n",
      "8epoch loss: 0.03342707569110174\n",
      "8epoch loss: 0.032318708040234276\n",
      "8epoch loss: 0.03163528212262989\n",
      "8epoch loss: 0.031133815626995107\n",
      "8epoch loss: 0.031277343423853805\n",
      "8epoch loss: 0.03104922738154022\n",
      "8epoch loss: 0.03125815956484612\n",
      "8epoch loss: 0.031157990007369307\n",
      "8epoch loss: 0.03046653608938138\n",
      "8epoch loss: 0.030337156988176173\n",
      "8epoch loss: 0.029913958625430226\n",
      "8epoch loss: 0.030218150120019924\n",
      "8epoch loss: 0.02995407467267858\n",
      "8epoch loss: 0.02981848185647147\n",
      "8epoch loss: 0.03021241654479095\n",
      "8epoch loss: 0.03000265734064584\n",
      "8epoch loss: 0.02939313131083644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  45%|████▌     | 9/20 [8:01:18<9:24:47, 3080.64s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5efaeac297437bba35f61a06d3fbe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2663.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9epoch loss: 0.0037641157396137714\n",
      "9epoch loss: 0.013735295104764884\n",
      "9epoch loss: 0.01957248253741369\n",
      "9epoch loss: 0.021326236147869656\n",
      "9epoch loss: 0.021490539780443182\n",
      "9epoch loss: 0.02062804631762756\n",
      "9epoch loss: 0.0218541521167494\n",
      "9epoch loss: 0.023238665784067622\n",
      "9epoch loss: 0.023492891963572207\n",
      "9epoch loss: 0.02326914058606494\n",
      "9epoch loss: 0.02194559172413386\n",
      "9epoch loss: 0.02228037760050942\n",
      "9epoch loss: 0.02184717296125668\n",
      "9epoch loss: 0.021976527814394995\n",
      "9epoch loss: 0.02183824800253198\n",
      "9epoch loss: 0.022772401252221908\n",
      "9epoch loss: 0.02331817228537876\n",
      "9epoch loss: 0.023303892850271152\n",
      "9epoch loss: 0.023772291881244006\n",
      "9epoch loss: 0.024301090720461015\n",
      "9epoch loss: 0.02408335340400858\n",
      "9epoch loss: 0.024043801545560784\n",
      "9epoch loss: 0.02413553380869567\n",
      "9epoch loss: 0.024147355923794644\n",
      "9epoch loss: 0.024289763912567666\n",
      "9epoch loss: 0.024487510842647175\n",
      "9epoch loss: 0.024060061361205514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 10/20 [8:50:22<8:26:35, 3039.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a692d604e04f4e8c8fe380d55e880b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2663.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10epoch loss: 0.0001587505976203829\n",
      "10epoch loss: 0.020939867297345087\n",
      "10epoch loss: 0.017780160216153123\n",
      "10epoch loss: 0.01911538986027806\n",
      "10epoch loss: 0.021357800703937183\n",
      "10epoch loss: 0.024600801380261002\n",
      "10epoch loss: 0.02518479975528102\n",
      "10epoch loss: 0.025104808474647126\n",
      "10epoch loss: 0.026035724526642535\n",
      "10epoch loss: 0.025693760753416728\n",
      "10epoch loss: 0.02485208372044\n",
      "10epoch loss: 0.023982676228610677\n",
      "10epoch loss: 0.02374673383746138\n",
      "10epoch loss: 0.02347151284893753\n",
      "10epoch loss: 0.023598324592667686\n",
      "10epoch loss: 0.024019248424461043\n",
      "10epoch loss: 0.024111699679799405\n",
      "10epoch loss: 0.023743139014124396\n",
      "10epoch loss: 0.023648302760569916\n",
      "10epoch loss: 0.023387905805408876\n",
      "10epoch loss: 0.023068657789718637\n",
      "10epoch loss: 0.023298608537573574\n",
      "10epoch loss: 0.02271477852849764\n",
      "10epoch loss: 0.0230467027540465\n",
      "10epoch loss: 0.02261174606216441\n",
      "10epoch loss: 0.022584098364052403\n",
      "10epoch loss: 0.0224585889831095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  55%|█████▌    | 11/20 [9:39:18<7:31:18, 3008.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8815227265c149ba9fe7a0160ba3db14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2663.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11epoch loss: 0.010604449547827244\n",
      "11epoch loss: 0.012376709894919492\n",
      "11epoch loss: 0.01740743691410999\n",
      "11epoch loss: 0.01720485625310591\n",
      "11epoch loss: 0.015610767998487686\n",
      "11epoch loss: 0.017643817043433534\n",
      "11epoch loss: 0.0178880312261658\n",
      "11epoch loss: 0.017668079973911108\n",
      "11epoch loss: 0.019151421959064056\n",
      "11epoch loss: 0.02043848443159299\n",
      "11epoch loss: 0.020568021223607662\n",
      "11epoch loss: 0.020347540244071177\n",
      "11epoch loss: 0.020450635887103746\n",
      "11epoch loss: 0.02021647221674869\n",
      "11epoch loss: 0.019967820288628795\n",
      "11epoch loss: 0.01945004501042639\n",
      "11epoch loss: 0.01977380076846089\n",
      "11epoch loss: 0.019596298532337814\n",
      "11epoch loss: 0.019940075834643103\n",
      "11epoch loss: 0.019565971476871457\n",
      "11epoch loss: 0.019432439255692175\n",
      "11epoch loss: 0.019305291377558202\n",
      "11epoch loss: 0.02007750102832638\n",
      "11epoch loss: 0.019803326811462865\n",
      "11epoch loss: 0.020121938963016395\n",
      "11epoch loss: 0.020592112338416905\n",
      "11epoch loss: 0.02054204849363453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 12/20 [10:28:12<6:38:09, 2986.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a99f920b3a4bd3b888c6eada05a7ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2663.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12epoch loss: 3.0617757147410884e-05\n",
      "12epoch loss: 0.011195245826975437\n",
      "12epoch loss: 0.015403448970383196\n",
      "12epoch loss: 0.014131729053947722\n",
      "12epoch loss: 0.014754825974663566\n",
      "12epoch loss: 0.017579102274973293\n",
      "12epoch loss: 0.017437508741109373\n",
      "12epoch loss: 0.01841590007289862\n",
      "12epoch loss: 0.018786859626064217\n",
      "12epoch loss: 0.018787196943166024\n",
      "12epoch loss: 0.018124008283940035\n",
      "12epoch loss: 0.018119894101338983\n",
      "12epoch loss: 0.017756516943029665\n",
      "12epoch loss: 0.017952024493405883\n",
      "12epoch loss: 0.017926700004300713\n",
      "12epoch loss: 0.018081480602742277\n",
      "12epoch loss: 0.018271662399859237\n",
      "12epoch loss: 0.018113428675265726\n",
      "12epoch loss: 0.01818285728522461\n",
      "12epoch loss: 0.01863058787251358\n",
      "12epoch loss: 0.01830331001441495\n",
      "12epoch loss: 0.018148339574728858\n",
      "12epoch loss: 0.018056331590307905\n",
      "12epoch loss: 0.017976091428282374\n",
      "12epoch loss: 0.01777730662919456\n",
      "12epoch loss: 0.017545249237043963\n",
      "12epoch loss: 0.017729764673588947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  65%|██████▌   | 13/20 [11:18:23<5:49:16, 2993.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4404bc2e8c44e0eab661aa6c719801e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2663.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13epoch loss: 1.0758226380858105e-05\n",
      "13epoch loss: 0.012360822353955\n",
      "13epoch loss: 0.012778847349845909\n",
      "13epoch loss: 0.01327108878782546\n",
      "13epoch loss: 0.014130710084987941\n",
      "13epoch loss: 0.013442651685552573\n",
      "13epoch loss: 0.014066294876317172\n",
      "13epoch loss: 0.01369943343693539\n",
      "13epoch loss: 0.013400510297625465\n",
      "13epoch loss: 0.014002785521239687\n",
      "13epoch loss: 0.01403095510850914\n",
      "13epoch loss: 0.013890023970200642\n",
      "13epoch loss: 0.01338647038815667\n",
      "13epoch loss: 0.01310573599068023\n",
      "13epoch loss: 0.012721769697180193\n",
      "13epoch loss: 0.012882444292133076\n",
      "13epoch loss: 0.013110262378555627\n",
      "13epoch loss: 0.012802785140431316\n",
      "13epoch loss: 0.012752863255362698\n",
      "13epoch loss: 0.012634265637207915\n",
      "13epoch loss: 0.01323529568965336\n",
      "13epoch loss: 0.013540852527115753\n",
      "13epoch loss: 0.013186249077560176\n",
      "13epoch loss: 0.013121358081113586\n",
      "13epoch loss: 0.013114542351503593\n",
      "13epoch loss: 0.013124997965995868\n",
      "13epoch loss: 0.012837521740548575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 14/20 [12:07:10<4:57:21, 2973.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3687bf6ebd241f4a5878ad4b13f1926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2663.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14epoch loss: 4.267623808118515e-05\n",
      "14epoch loss: 0.006842044358073522\n",
      "14epoch loss: 0.011172034565258096\n",
      "14epoch loss: 0.009316236779204115\n",
      "14epoch loss: 0.008883859261830015\n",
      "14epoch loss: 0.009735961699896491\n",
      "14epoch loss: 0.010101346796241075\n",
      "14epoch loss: 0.010137508934959183\n",
      "14epoch loss: 0.0105509377376564\n",
      "14epoch loss: 0.011111047717921827\n",
      "14epoch loss: 0.011486696324110387\n",
      "14epoch loss: 0.0121854665930578\n",
      "14epoch loss: 0.012529594987197686\n",
      "14epoch loss: 0.013059914084309072\n",
      "14epoch loss: 0.013006377697907131\n",
      "14epoch loss: 0.013075902743151017\n",
      "14epoch loss: 0.012996672552296827\n",
      "14epoch loss: 0.013049495761604609\n",
      "14epoch loss: 0.013518000964172404\n",
      "14epoch loss: 0.013852643164384278\n",
      "14epoch loss: 0.014116879065103914\n",
      "14epoch loss: 0.01397370300084745\n",
      "14epoch loss: 0.014101290204707455\n",
      "14epoch loss: 0.014186770904283014\n",
      "14epoch loss: 0.014654136625213785\n",
      "14epoch loss: 0.01470658724332873\n",
      "14epoch loss: 0.014438172656005695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  75%|███████▌  | 15/20 [12:56:26<4:07:21, 2968.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26443e50d5bb4c6dbc451f47edf46c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2663.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15epoch loss: 8.575472747907043e-06\n",
      "15epoch loss: 0.00963923910165256\n",
      "15epoch loss: 0.007877981564541614\n",
      "15epoch loss: 0.00949252961652641\n",
      "15epoch loss: 0.009412457601334759\n",
      "15epoch loss: 0.008459751415736736\n",
      "15epoch loss: 0.008532374713878245\n",
      "15epoch loss: 0.008527630422495491\n",
      "15epoch loss: 0.008284106334759329\n",
      "15epoch loss: 0.009499655738681303\n",
      "15epoch loss: 0.009246264278464434\n",
      "15epoch loss: 0.009259242811441443\n",
      "15epoch loss: 0.008731722941095109\n",
      "15epoch loss: 0.009016997744265681\n",
      "15epoch loss: 0.009606523190659386\n",
      "15epoch loss: 0.009553988014119065\n",
      "15epoch loss: 0.00943459554393515\n",
      "15epoch loss: 0.009471771532356999\n",
      "15epoch loss: 0.009757023224239323\n",
      "15epoch loss: 0.009849931392091978\n",
      "15epoch loss: 0.00974393676246682\n",
      "15epoch loss: 0.009487583073604498\n",
      "15epoch loss: 0.009617617460463686\n",
      "15epoch loss: 0.009740394023628888\n",
      "15epoch loss: 0.010187842304254244\n",
      "15epoch loss: 0.01024908027403127\n",
      "15epoch loss: 0.010360626698222821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 16/20 [13:45:21<3:17:13, 2958.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95069207ab3a4d22851385f5e9089241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2663.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16epoch loss: 0.00014006874698679894\n",
      "16epoch loss: 0.006170652665918899\n",
      "16epoch loss: 0.011331214248309351\n",
      "16epoch loss: 0.012542305229582352\n",
      "16epoch loss: 0.010826803874576433\n",
      "16epoch loss: 0.010133925452210629\n",
      "16epoch loss: 0.010706036420256707\n",
      "16epoch loss: 0.01009544326148267\n",
      "16epoch loss: 0.01002887838773759\n",
      "16epoch loss: 0.009836685984852796\n",
      "16epoch loss: 0.009727800448831174\n",
      "16epoch loss: 0.009997679780630717\n",
      "16epoch loss: 0.009710250120860676\n",
      "16epoch loss: 0.009615120227264823\n",
      "16epoch loss: 0.009976210518837033\n",
      "16epoch loss: 0.009860326089622494\n",
      "16epoch loss: 0.009765597822758728\n",
      "16epoch loss: 0.009578342363386344\n",
      "16epoch loss: 0.009753232728520128\n",
      "16epoch loss: 0.009646931870177034\n",
      "16epoch loss: 0.010446922988886678\n",
      "16epoch loss: 0.010568032652136922\n",
      "16epoch loss: 0.010412313777591716\n",
      "16epoch loss: 0.010437640065044124\n",
      "16epoch loss: 0.01020256137439018\n",
      "16epoch loss: 0.010416382848015958\n",
      "16epoch loss: 0.010395162323317362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  85%|████████▌ | 17/20 [14:34:32<2:27:48, 2956.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd740c59f984f0a9954e1759e481ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2663.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17epoch loss: 2.9131449537089793e-06\n",
      "17epoch loss: 0.018183709642569934\n",
      "17epoch loss: 0.014833919613672248\n",
      "17epoch loss: 0.013239795144933937\n",
      "17epoch loss: 0.010881244543277307\n",
      "17epoch loss: 0.0125884402417538\n",
      "17epoch loss: 0.012637715399903911\n",
      "17epoch loss: 0.011633039949809583\n",
      "17epoch loss: 0.011062886443210684\n",
      "17epoch loss: 0.010876724264822514\n",
      "17epoch loss: 0.010884066435830514\n",
      "17epoch loss: 0.011880059418295992\n",
      "17epoch loss: 0.011676458096524865\n",
      "17epoch loss: 0.012106176420673584\n",
      "17epoch loss: 0.01171514876283003\n",
      "17epoch loss: 0.011415878801714043\n",
      "17epoch loss: 0.011519504943972596\n",
      "17epoch loss: 0.011575391748706832\n",
      "17epoch loss: 0.011241770476733573\n",
      "17epoch loss: 0.011273882274029432\n",
      "17epoch loss: 0.011200671000575427\n",
      "17epoch loss: 0.011356978021391973\n",
      "17epoch loss: 0.011245764199024759\n",
      "17epoch loss: 0.011109224129158412\n",
      "17epoch loss: 0.01127489944307123\n",
      "17epoch loss: 0.011056860801899434\n",
      "17epoch loss: 0.011287465685729822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 18/20 [15:23:38<1:38:26, 2953.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b6ee7ad9c14c90929a31abfab10539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2663.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18epoch loss: 6.109276910137851e-06\n",
      "18epoch loss: 0.011822838373672815\n",
      "18epoch loss: 0.008052835978643468\n",
      "18epoch loss: 0.009698969755850993\n",
      "18epoch loss: 0.009932743235720014\n",
      "18epoch loss: 0.010677051638307906\n",
      "18epoch loss: 0.010179665626137629\n",
      "18epoch loss: 0.010082219929933854\n",
      "18epoch loss: 0.009838267705593727\n",
      "18epoch loss: 0.009296356699436785\n",
      "18epoch loss: 0.009589929846220663\n",
      "18epoch loss: 0.009551733702201602\n",
      "18epoch loss: 0.008983928652083294\n",
      "18epoch loss: 0.00914125485405062\n",
      "18epoch loss: 0.009034382514421005\n",
      "18epoch loss: 0.00890624743524677\n",
      "18epoch loss: 0.008948986403667022\n",
      "18epoch loss: 0.008903065558291045\n",
      "18epoch loss: 0.00869791022497675\n",
      "18epoch loss: 0.008585539964981152\n",
      "18epoch loss: 0.008557495076888869\n",
      "18epoch loss: 0.008527439435911211\n",
      "18epoch loss: 0.008690235737563733\n",
      "18epoch loss: 0.008632488081525991\n",
      "18epoch loss: 0.008411602816089563\n",
      "18epoch loss: 0.008624376329850702\n",
      "18epoch loss: 0.008701413930790039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  95%|█████████▌| 19/20 [16:12:55<49:14, 2954.32s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8dc4411e69942d6a59288a3cdc3c5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=2663.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19epoch loss: 0.00018654382438398898\n",
      "19epoch loss: 0.011227520171333633\n",
      "19epoch loss: 0.011887181312152792\n",
      "19epoch loss: 0.012592037845984382\n",
      "19epoch loss: 0.011079731446928594\n",
      "19epoch loss: 0.010283380245244977\n",
      "19epoch loss: 0.010067659976776316\n",
      "19epoch loss: 0.009476075752871002\n",
      "19epoch loss: 0.008828560373742073\n",
      "19epoch loss: 0.008281208019345924\n",
      "19epoch loss: 0.008165714428255729\n",
      "19epoch loss: 0.009063670515746504\n",
      "19epoch loss: 0.00929253076349785\n",
      "19epoch loss: 0.009231522420546428\n",
      "19epoch loss: 0.009170287471323571\n",
      "19epoch loss: 0.008929619658945735\n",
      "19epoch loss: 0.009352687166659409\n",
      "19epoch loss: 0.009027382925977562\n",
      "19epoch loss: 0.008893892449996\n",
      "19epoch loss: 0.008763936685610964\n",
      "19epoch loss: 0.008917171130896975\n",
      "19epoch loss: 0.008786972284632195\n",
      "19epoch loss: 0.00873491856303588\n",
      "19epoch loss: 0.00873052417237153\n",
      "19epoch loss: 0.008568023868725193\n",
      "19epoch loss: 0.00856221605094252\n",
      "19epoch loss: 0.008484285103997225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [17:02:24<00:00, 3067.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# sampler = CustomSampler()\n",
    "# Retriever는 아래와 같이 사용할 수 있도록 코드를 짜봅시다.\n",
    "retriever = DenseRetrieval(\n",
    "    args=args,\n",
    "    dataset=dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    p_encoder=p_encoder,\n",
    "    q_encoder=q_encoder,\n",
    "    sampler = CustomSampler\n",
    ")\n",
    "p_encoder, q_encoder = retriever.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/data/wikipedia_documents.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    wiki = json.load(f)\n",
    "\n",
    "corpus = list(\n",
    "    dict.fromkeys([v[\"text\"] for v in wiki.values()])\n",
    ")  # set 은 매번 순서가 바뀌므로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a9c3d3cbea4f7daf7a966c481c7582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=56737.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# p_encoder = retriever.p_encoder\n",
    "# q_encoder = retriever.q_encoder\n",
    "with torch.no_grad() :\n",
    "    p_encoder.eval()\n",
    "\n",
    "    p_embs = []\n",
    "    for p in tqdm(corpus) :\n",
    "        p = tokenizer(p, padding='max_length', truncation=True, return_tensors='pt').to('cuda')\n",
    "        p_emb = p_encoder(**p).to('cpu').numpy()\n",
    "        p_embs.append(p_emb)\n",
    "p_embs = torch.Tensor(p_embs).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_path = '/opt/ml/custom/passage_embedding_special_customsample_augmentation_20.bin'\n",
    "with open(file_path, 'wb') as file :\n",
    "    pickle.dump(p_embs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_encoder.cpu()\n",
    "del p_encoder\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(q_encoder, '/opt/ml/custom/q_encoder_special_customsample_augmentation_20.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Relavant Documnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/data/wikipedia_documents.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    wiki = json.load(f)\n",
    "\n",
    "corpus = list(\n",
    "    dict.fromkeys([v[\"text\"] for v in wiki.values()])\n",
    ")  # set 은 매번 순서가 바뀌므로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"klue/bert-base\"\n",
    "\n",
    "# 혹시 위에서 사용한 encoder가 있다면 주석처리 후 진행해주세요 (CUDA ...)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/opt/ml/custom/passage_embedding_special_shuffle_100.bin', 'rb') as file :\n",
    "    p_embs = pickle.load(file)\n",
    "p_embs = p_embs\n",
    "\n",
    "q_encoder = torch.load('/opt/ml/custom/q_encoder_special_customsample_70.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relavant_doc(queries, q_encoder, p_embs, k=1) :\n",
    "    with torch.no_grad() :\n",
    "        q_encoder.eval()\n",
    "        q_seqs_val = tokenizer(queries, padding='max_length',truncation=True,return_tensors='pt').to(device)\n",
    "        q_emb = q_encoder(**q_seqs_val).to('cpu')\n",
    "    dot_prod_scores = torch.mm(q_emb, p_embs.T)\n",
    "    sort_result = torch.sort(dot_prod_scores, dim=1, descending=True)\n",
    "\n",
    "    scores, ranks = sort_result[0], sort_result[1]\n",
    "\n",
    "    result_scores = []\n",
    "    result_indices = []\n",
    "    for i in range(len(ranks)) :\n",
    "        result_scores.append(scores[i].tolist()[:k])\n",
    "        result_indices.append(ranks[i].tolist()[:k])\n",
    "    \n",
    "    return result_scores, result_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연산 시작 - Augmentation/Batch_size/epoch:20/CustomSampling/512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = load_from_disk('/opt/ml/data/train_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885e65baf38b47cfbf0d2a9e11b1ac19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dense retrieval: ', max=240.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "doc_scores, doc_indices = get_relavant_doc(original_dataset['validation']['question'], q_encoder, p_embs, k = 500)\n",
    "\n",
    "total = []\n",
    "for idx, example in enumerate(\n",
    "        tqdm(original_dataset['validation'], desc=\"Dense retrieval: \")\n",
    "    ):\n",
    "        tmp = {\n",
    "            # Query와 해당 id를 반환합니다.\n",
    "            \"question\": example[\"question\"],\n",
    "            \"id\": example[\"id\"],\n",
    "            # Retrieve한 Passage의 id, context를 반환합니다.\n",
    "            \"context_id\": doc_indices[idx],\n",
    "            \"context\": \" \".join(  # 기존에는 ' '.join()\n",
    "                [corpus[pid] for pid in doc_indices[idx]]\n",
    "            ),\n",
    "        }\n",
    "        if \"context\" in example.keys() and \"answers\" in example.keys():\n",
    "            # validation 데이터를 사용하면 ground_truth context와 answer도 반환합니다.\n",
    "            tmp[\"original_context\"] = example[\"context\"]\n",
    "            tmp[\"answers\"] = example[\"answers\"]\n",
    "        total.append(tmp)\n",
    "\n",
    "cqas_100 = pd.DataFrame(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9541666666666667\n"
     ]
    }
   ],
   "source": [
    "correct_length_100 = []\n",
    "for i in range(len(cqas_100)) :\n",
    "    if cqas_100['original_context'][i] in cqas_100['context'][i] :\n",
    "        correct_length_100.append(i)\n",
    "print(len(correct_length_100) / len(original_dataset['validation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cqas_100.to_csv('/opt/ml/custom/valid_dpr_b16_speical_customsampling_augmentation_e20_t500.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연산 시작 - Batch_size 16/epoch:10/CustomSampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c3ea31c36f146a6be92851635d740cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dense retrieval: ', max=240.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "doc_scores, doc_indices = get_relavant_doc(dataset['validation']['question'], q_encoder, p_embs, k = 50)\n",
    "\n",
    "total = []\n",
    "for idx, example in enumerate(\n",
    "        tqdm(dataset['validation'], desc=\"Dense retrieval: \")\n",
    "    ):\n",
    "        tmp = {\n",
    "            # Query와 해당 id를 반환합니다.\n",
    "            \"question\": example[\"question\"],\n",
    "            \"id\": example[\"id\"],\n",
    "            # Retrieve한 Passage의 id, context를 반환합니다.\n",
    "            \"context_id\": doc_indices[idx],\n",
    "            \"context\": \" \".join(  # 기존에는 ' '.join()\n",
    "                [corpus[pid] for pid in doc_indices[idx]]\n",
    "            ),\n",
    "        }\n",
    "        if \"context\" in example.keys() and \"answers\" in example.keys():\n",
    "            # validation 데이터를 사용하면 ground_truth context와 answer도 반환합니다.\n",
    "            tmp[\"original_context\"] = example[\"context\"]\n",
    "            tmp[\"answers\"] = example[\"answers\"]\n",
    "        total.append(tmp)\n",
    "\n",
    "cqas_100 = pd.DataFrame(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6916666666666667\n"
     ]
    }
   ],
   "source": [
    "correct_length_100 = []\n",
    "for i in range(len(cqas_100)) :\n",
    "    if cqas_100['original_context'][i] in cqas_100['context'][i] :\n",
    "        correct_length_100.append(i)\n",
    "print(len(correct_length_100) / len(dataset['validation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cqas_100.to_csv('/opt/ml/custom/valid_dpr_b_16_speical_customsampling_e10_t50.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연산 시작 - Batch_size 16/epoch:10/CustomSampling/384\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e459ea4c6f54c9eba483c409a7304b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dense retrieval: ', max=240.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "doc_scores, doc_indices = get_relavant_doc(dataset['validation']['question'], q_encoder, p_embs, k = 50)\n",
    "\n",
    "total = []\n",
    "for idx, example in enumerate(\n",
    "        tqdm(dataset['validation'], desc=\"Dense retrieval: \")\n",
    "    ):\n",
    "        tmp = {\n",
    "            # Query와 해당 id를 반환합니다.\n",
    "            \"question\": example[\"question\"],\n",
    "            \"id\": example[\"id\"],\n",
    "            # Retrieve한 Passage의 id, context를 반환합니다.\n",
    "            \"context_id\": doc_indices[idx],\n",
    "            \"context\": \" \".join(  # 기존에는 ' '.join()\n",
    "                [corpus[pid] for pid in doc_indices[idx]]\n",
    "            ),\n",
    "        }\n",
    "        if \"context\" in example.keys() and \"answers\" in example.keys():\n",
    "            # validation 데이터를 사용하면 ground_truth context와 answer도 반환합니다.\n",
    "            tmp[\"original_context\"] = example[\"context\"]\n",
    "            tmp[\"answers\"] = example[\"answers\"]\n",
    "        total.append(tmp)\n",
    "\n",
    "cqas_100 = pd.DataFrame(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7166666666666667\n"
     ]
    }
   ],
   "source": [
    "correct_length_100 = []\n",
    "for i in range(len(cqas_100)) :\n",
    "    if cqas_100['original_context'][i] in cqas_100['context'][i] :\n",
    "        correct_length_100.append(i)\n",
    "print(len(correct_length_100) / len(dataset['validation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cqas_100.to_csv('/opt/ml/custom/valid_dpr_b_16_speical_customsampling_e70_t50.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
