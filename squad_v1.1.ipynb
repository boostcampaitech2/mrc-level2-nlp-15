{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "- [Chris Mccormick finetuning BERT for SQUAD](https://colab.research.google.com/drive/16VjEulbATgok4mELTSaq7GTQdh3JGhGy#scrollTo=Xm1wTn09RAR7)\n",
    "- [Discussion Regarding finetuning T5](https://github.com/huggingface/transformers/issues/4426) | [Exploring T5 by patil suraj](https://github.com/patil-suraj/exploring-T5)\n",
    "    - [SQUAD QA finetuning for T5](https://colab.research.google.com/github/patil-suraj/exploring-T5/blob/master/T5_on_TPU.ipynb#scrollTo=KdmKlMkfcLa0)\n",
    "    - [T5 finetuning for non extractive tasks](https://colab.research.google.com/drive/176NSaYjc2eeI-78oLH_F9-YV3po3qQQO?usp=sharing)\n",
    "- [Google's T5 fine tuning example for QA](https://colab.research.google.com/github/google-research/text-to-text-transfer-transformer/blob/master/notebooks/t5-trivia.ipynb#scrollTo=6rU32DjyeLuL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import from Baseline Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/2352181/how-to-use-a-dot-to-access-members-of-dictionary\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes, as dict.key_name, not as dict[\"key_name\"] \"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from typing import List, Callable, NoReturn, NewType, Any\n",
    "import dataclasses\n",
    "from datasets import load_metric, load_from_disk, Dataset, DatasetDict\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForQuestionAnswering, AutoTokenizer\n",
    "\n",
    "from transformers import (\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordPiece\n",
    "\n",
    "from baseline.utils_qa import postprocess_qa_predictions, check_no_error\n",
    "from baseline.trainer_qa import QuestionAnsweringTrainer\n",
    "from baseline.retrieval import SparseRetrieval\n",
    "\n",
    "import yaml\n",
    "\n",
    "# Read config.yaml file\n",
    "with open(\"config.yaml\") as infile:\n",
    "    SAVED_CFG = yaml.load(infile, Loader=yaml.FullLoader)\n",
    "    SAVED_CFG = dotdict(SAVED_CFG)\n",
    "\n",
    "# arguments setting\n",
    "data_args = dotdict(SAVED_CFG.data)\n",
    "model_args = dotdict(SAVED_CFG.custom_model)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",  # output directory\n",
    "    save_total_limit=5,  # number of total save model.\n",
    "    save_steps=model_args.save_steps,  # model saving step.\n",
    "    num_train_epochs=model_args.num_train_epochs,  # total number of training epochs\n",
    "    learning_rate=model_args.learning_rate,  # learning_rate\n",
    "    per_device_train_batch_size=model_args.batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=model_args.batch_size,  # batch size for evaluation\n",
    "    warmup_steps=model_args.warmup_steps,  # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=model_args.weight_decay,  # strength of weight decay\n",
    "    logging_dir=\"./logs\",  # directory for storing logs\n",
    "    logging_steps=100,  # log saving step.\n",
    "    evaluation_strategy=\"steps\",  # evaluation strategy to adopt during training\n",
    "    # `no`: No evaluation during training.\n",
    "    # `steps`: Evaluate every `eval_steps`.\n",
    "    # `epoch`: Evaluate every end of epoch.\n",
    "    eval_steps=500,  # evaluation step.\n",
    "    load_best_model_at_end=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3206612b93f743349f4a89591cf82209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=547.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce354a9b6b64ef4b23f0ae5974244f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=248477.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f7ecdee4454c1f9b0bc37a7fceb6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=173.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b805bfb3c9c343f28889af93c441dfd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=337.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertModel, BertPreTrainedModel, AdamW,AutoTokenizer, TrainingArguments, get_linear_schedule_with_warmup\n",
    "from datasets import load_metric, load_from_disk, Dataset, DatasetDict\n",
    "from torch.utils.data import (DataLoader, RandomSampler, TensorDataset)\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_args.model_name_or_path)\n",
    "datasets = load_from_disk(data_args.dataset_name)\n",
    "train_dataset_from_huggingface = datasets['train']\n",
    "valid_dataset_from_huggingface = datasets['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train dataset, train dataloader\n",
    "q_seqs = tokenizer(\n",
    "    train_dataset_from_huggingface['question'], \n",
    "    padding=\"max_length\", \n",
    "    truncation=True, \n",
    "    return_tensors='pt',\n",
    "    return_token_type_ids=False,  # for RoBERTa\n",
    "    )\n",
    "p_seqs = tokenizer(\n",
    "    train_dataset_from_huggingface['context'], \n",
    "    padding=\"max_length\", \n",
    "    truncation=True, \n",
    "    return_tensors='pt',\n",
    "    return_token_type_ids=False,  # for RoBERTa\n",
    "    )\n",
    "# print(q_seqs[0])\n",
    "train_dataset = TensorDataset(\n",
    "    p_seqs['input_ids'], \n",
    "    p_seqs['attention_mask'], \n",
    "    # p_seqs['token_type_ids'],\n",
    "    q_seqs['input_ids'], \n",
    "    q_seqs['attention_mask'], \n",
    "    # q_seqs['token_type_ids']\n",
    "    )\n",
    "train_loader = DataLoader(train_dataset,batch_size=model_args.batch_size)\n",
    "\n",
    "#valid dataset, valid dataloader\n",
    "q_seqs = tokenizer(\n",
    "    valid_dataset_from_huggingface['question'], \n",
    "    padding=\"max_length\", \n",
    "    truncation=True, \n",
    "    return_tensors='pt',\n",
    "    return_token_type_ids=False,  # for RoBERTa\n",
    "    )\n",
    "p_seqs = tokenizer(\n",
    "    valid_dataset_from_huggingface['context'], \n",
    "    padding=\"max_length\", \n",
    "    truncation=True, \n",
    "    return_tensors='pt',\n",
    "    return_token_type_ids=False,  # for RoBERTa\n",
    "    )\n",
    "# print(q_seqs[0])\n",
    "valid_dataset = TensorDataset(\n",
    "    p_seqs['input_ids'], \n",
    "    p_seqs['attention_mask'], \n",
    "    # p_seqs['token_type_ids'],\n",
    "    q_seqs['input_ids'], \n",
    "    q_seqs['attention_mask'], \n",
    "    # q_seqs['token_type_ids']\n",
    "    )\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=model_args.batch_size\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import from Fine_Tune_BERT_on_SQuAD_v1_1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_info': DatasetInfo(description='', citation='', homepage='', license='', features={'__index_level_0__': Value(dtype='int64', id=None), 'answers': {'answer_start': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), 'text': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}, 'context': Value(dtype='string', id=None), 'document_id': Value(dtype='int64', id=None), 'id': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None)}, post_processed=None, supervised_keys=None, builder_name=None, config_name=None, version=None, splits=None, download_checksums=None, download_size=None, post_processing_size=None, dataset_size=None, size_in_bytes=None),\n",
       " '_split': None,\n",
       " '_indexes': {},\n",
       " '_data': pyarrow.Table\n",
       " title: string\n",
       " context: string\n",
       " question: string\n",
       " id: string\n",
       " answers: struct<answer_start: list<item: int64>, text: list<item: string>>\n",
       "   child 0, answer_start: list<item: int64>\n",
       "       child 0, item: int64\n",
       "   child 1, text: list<item: string>\n",
       "       child 0, item: string\n",
       " document_id: int64\n",
       " __index_level_0__: int64,\n",
       " '_indices': pyarrow.Table\n",
       " indices: uint64,\n",
       " '_data_files': [{'filename': '/opt/ml/data/train_dataset/train/dataset.arrow'}],\n",
       " '_indices_data_files': [{'filename': '/opt/ml/data/train_dataset/train/indices.arrow'}],\n",
       " '_inplace_history': [{'transforms': []}],\n",
       " '_format_type': None,\n",
       " '_format_kwargs': {},\n",
       " '_format_columns': None,\n",
       " '_output_all_columns': False,\n",
       " '_fingerprint': 'd8cf0ec86e1a54fc'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look inside dataset at huggingface\n",
    "vars(train_dataset_from_huggingface)\n",
    "\n",
    "#  title: string\n",
    "#  context: string\n",
    "#  question: string\n",
    "#  id: string\n",
    "#  answers: struct < answer_start: list<item: int64>, text: list<item: string> >\n",
    "#    child 0, answer_start: list<item: int64>\n",
    "#        child 0, item: int64\n",
    "#    child 1, text: list<item: string>\n",
    "#        child 0, item: string\n",
    "#  document_id: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '인사조직관리',\n",
       " 'context': \"'근대적 경영학' 또는 '고전적 경영학'에서 현대적 경영학으로 전환되는 시기는 1950년대이다. 2차 세계대전을 마치고, 6.25전쟁의 시기로 유럽은 전후 재건에 집중하고, 유럽 제국주의의 식민지가 독립하여 아프리카, 아시아, 아메리카 대륙에서 신생국가가 형성되는 시기였고, 미국은 전쟁 이후 경제적 변화에 기업이 적응을 해야 하던 시기였다. 특히 1954년 피터 드러커의 저서 《경영의 실제》는 현대적 경영의 기준을 제시하여서, 기존 근대적 인사조직관리를 넘어선 현대적 인사조직관리의 전환점이 된다. 드러커는 경영자의 역할을 강조하며 경영이 현시대 최고의 예술이자 과학이라고 주장하였고 , 이 주장은 21세기 인사조직관리의 역할을 자리매김했다.\\\\n\\\\n현대적 인사조직관리와 근대 인사조직관리의 가장 큰 차이는 통합이다. 19세기의 영향을 받던 근대적 경영학(고전적 경영)의 흐름은 기능을 강조하였지만, 1950년대 이후의 현대 경영학은 통합을 강조하였다. 기능이 분화된 '기계적인 기업조직' 이해에서 다양한 기능을 인사조직관리의 목적, 경영의 목적을 위해서 다양한 분야를 통합하여 '유기적 기업 조직' 이해로 전환되었다. 이 통합적 접근방식은 과정, 시스템, 상황을 중심으로 하는 인사조직관리 방식을 형성했다.\",\n",
       " 'question': '현대적 인사조직관리의 시발점이 된 책은?',\n",
       " 'id': 'mrc-0-004397',\n",
       " 'answers': {'answer_start': [212], 'text': ['《경영의 실제》']},\n",
       " 'document_id': 51638,\n",
       " '__index_level_0__': 2873}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_from_huggingface[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_args.model_name_or_path)\n",
    "config = AutoConfig.from_pretrained(model_args.model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'현대 ##적 인사 ##조 ##직 ##관리 ##의 시발점 ##이 된 책 ##은 ?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(train_dataset_from_huggingface[1]['question'])\n",
    "\" \".join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing 3,952 examples...\n",
      "  Tokenized 0.\n",
      "  Tokenized 3,000.\n",
      "DONE.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# By default, the tokenizer will spit out a warning whenever we tokenize a \n",
    "# sample which ends up being more than 512 tokens. We don't care about that for\n",
    "# now, though, and this cell will produce a lot of those warnings! So we'll \n",
    "# adjust the logging settings to suppress those warnings and keep the output\n",
    "# cell cleaner.\n",
    "logging.getLogger(\"transformers.tokenization_utils_base\").setLevel(logging.ERROR)\n",
    "\n",
    "# Record the length of each sequence (in terms of BERT tokens).\n",
    "lengths = []\n",
    "\n",
    "print('Tokenizing {:,} examples...'.format(len(train_dataset_from_huggingface)))\n",
    "\n",
    "# For each example...\n",
    "for (i, ex) in enumerate(train_dataset_from_huggingface):\n",
    "\n",
    "    # Report progress.\n",
    "    if ((i % 3000) == 0):\n",
    "        print('  Tokenized {:,}.'.format(i))\n",
    "\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    input_ids = tokenizer.encode(ex['question'], \n",
    "                                 ex['context'],\n",
    "                                 add_special_tokens = True,\n",
    "                                 truncation=False\n",
    "                                 )\n",
    "\n",
    "    # Record the non-truncated length.\n",
    "    lengths.append(len(input_ids))\n",
    "\n",
    "print('DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Min length: 256 tokens\n",
      "   Max length: 1,190 tokens\n",
      "Median length: 462.0 tokens\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print('   Min length: {:,} tokens'.format(min(lengths)))\n",
    "print('   Max length: {:,} tokens'.format(max(lengths)))\n",
    "print('Median length: {:,} tokens'.format(np.median(lengths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "\n",
    "# Truncate any sequence lengths greater than 512.\n",
    "# trunc_lengths = [min(l, 512) for l in lengths]\n",
    "\n",
    "# Plot the distribution of truncated lengths.\n",
    "sns.distplot(lengths, kde=False, rug=False)\n",
    "\n",
    "# Alternatively, you might try using a log scale on the x-axis, but this is \n",
    "# tricky. See here for one approach:\n",
    "# https://stackoverflow.com/questions/47850202/plotting-a-histogram-on-a-log-scale-with-matplotlib?rq=1\n",
    "#plt.xscale('log')\n",
    "\n",
    "plt.title('Sequence Lengths\\n(Truncated to 512)')\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('# of Samples')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many comments will be truncated?\n",
      "\n",
      "max_len = 128  -->    3,952 of   3,952  (100.0%)  will be truncated \n",
      "max_len = 256  -->    3,951 of   3,952  (100.0%)  will be truncated \n",
      "max_len = 300  -->    3,788 of   3,952  (95.9%)  will be truncated \n",
      "max_len = 384  -->    2,742 of   3,952  (69.4%)  will be truncated \n",
      "max_len = 512  -->    1,545 of   3,952  (39.1%)  will be truncated \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Cast the list to a numpy array so we can use some numpy features.\n",
    "lengths = np.asarray(lengths)\n",
    "\n",
    "# Get the total number of comments.\n",
    "num_comments = len(lengths)\n",
    "\n",
    "# Check the following lengths:\n",
    "max_lens = [128, 256, 300, 384, 512]\n",
    "\n",
    "print('How many comments will be truncated?\\n')\n",
    "\n",
    "# For each choice...\n",
    "for max_len in max_lens:\n",
    "\n",
    "    # Calculate how many comments will be truncacted.\n",
    "    num_over = np.sum(lengths > max_len)\n",
    "\n",
    "    # And as a percentage.\n",
    "    prcnt_over = float(num_over) / float(num_comments)\n",
    "\n",
    "    print('max_len = {:}  -->  {:>7,} of {:>7,}  ({:>5.1%})  ' \\\n",
    "          'will be truncated '.format(\n",
    "              max_len, num_over, num_comments, prcnt_over\n",
    "          ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2073: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "1064it [00:02, 393.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processed 1,000 examples in 3 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2069it [00:05, 423.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processed 2,000 examples in 5 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3052it [00:07, 402.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processed 3,000 examples in 7 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3952it [00:09, 408.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 246 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "time_elapsed = time.time()\n",
    "\n",
    "list_input_ids = []\n",
    "list_attention_masks = []\n",
    "# list_token_type_ids = []\n",
    "list_start_positions = []\n",
    "list_end_positions = []\n",
    "\n",
    "num_dropped = 0\n",
    "\n",
    "for (item_num, item) in tqdm(enumerate(train_dataset_from_huggingface)):\n",
    "    # print(item)\n",
    "    # Report progress.\n",
    "    if ((item_num % 1000) == 0) and (not item_num == 0):\n",
    "        print('    Processed {:,} examples in {:.0f} seconds.'.format(\n",
    "            item_num, time.time() - time_elapsed\n",
    "        ))\n",
    "    # print(item['answers']['text'][0])\n",
    "    answer_tokens = tokenizer.tokenize(item['answers']['text'][0])\n",
    "    # print(answer_tokens)\n",
    "    len_answer_tokens = len(answer_tokens)\n",
    "\n",
    "    str_masked = ' '.join([tokenizer.mask_token]*len_answer_tokens)\n",
    "\n",
    "    start_char_i = item['answers']['answer_start'][0]\n",
    "    end_char_i = start_char_i + len(item['answers']['text'])\n",
    "\n",
    "    masked_context = \\\n",
    "        item['context'][:start_char_i] + \\\n",
    "        str_masked + \\\n",
    "        item['context'][end_char_i:]\n",
    "\n",
    "    # Tokenize the context and the answer.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        item['question'],\n",
    "        masked_context,\n",
    "        add_special_tokens = True,\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=False,\n",
    "        pad_to_max_length=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = encoded_dict['input_ids']\n",
    "    \n",
    "    is_mask_token = (input_ids[0] == tokenizer.mask_token_id)\n",
    "    mask_token_indices = is_mask_token.nonzero(as_tuple=False)[:, 0]\n",
    "\n",
    "    if not len(mask_token_indices) == len_answer_tokens:\n",
    "        num_dropped += 1\n",
    "        continue\n",
    "\n",
    "    start_index = mask_token_indices[0]\n",
    "    end_index = mask_token_indices[-1]\n",
    "\n",
    "    answer_token_ids = tokenizer.encode(\n",
    "        answer_tokens[0],\n",
    "        add_special_tokens=False,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    input_ids[0, start_index:end_index+1] = answer_token_ids\n",
    "\n",
    "    list_input_ids.append(input_ids)\n",
    "    list_attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    list_start_positions.append(start_index)\n",
    "    list_end_positions.append(end_index)\n",
    "\n",
    "list_input_ids = torch.cat(list_input_ids, dim=0)\n",
    "list_attention_masks = torch.cat(list_attention_masks, dim=0)\n",
    "list_start_positions = torch.tensor(list_start_positions)\n",
    "list_end_positions = torch.tensor(list_end_positions)\n",
    "\n",
    "print('Dropped {:,} examples.'.format(num_dropped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized 3,706 examples.\n",
      "\n",
      "Dropped 246 examples.\n"
     ]
    }
   ],
   "source": [
    "print('Tokenized {:,} examples.'.format(len(list_input_ids)))\n",
    "\n",
    "print('\\nDropped {:,} examples.'.format(num_dropped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaForQuestionAnswering: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForQuestionAnswering(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoConfig\n",
    "from adamp import AdamP\n",
    "\n",
    "model_config = AutoConfig.from_pretrained(model_args.model_name_or_path)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    config=model_config,\n",
    "    )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config.DEBUG = True\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() and model_config.DEBUG == False else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3706"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 3706 samples\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "dataset = TensorDataset(list_input_ids, \n",
    "                            list_attention_masks, \n",
    "                            list_start_positions, \n",
    "                            list_end_positions)\n",
    "\n",
    "print('Dataset size: {:} samples'.format(len(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,335 training samples\n",
      "  371 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.90 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Tue Oct 19 08:23:33 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| N/A   30C    P0    26W / 250W |      4MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209 training batches & 24 validation batches\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SubsetRandomSampler, SequentialSampler\n",
    "\n",
    "import numpy.random\n",
    "import numpy as np\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 16\n",
    "\n",
    "# Randomly select 10,000 indeces from the training set to use. \n",
    "#indeces = np.random.permutation(len(train_dataset))[:10000]\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            #sampler = SubsetRandomSampler(indeces, train_dataset),\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )\n",
    "\n",
    "print('{:,} training batches & {:,} validation batches'.format(len(train_dataloader), len(validation_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamP(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 3\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /opt/ml/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/happyface-boostcamp/KLUE-QA/runs/1celzsxn\" target=\"_blank\">likely-cloud-1</a></strong> to <a href=\"https://wandb.ai/happyface-boostcamp/KLUE-QA\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training 209 batches...\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Flexible integration for any Python script\n",
    "import wandb\n",
    "\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "wandb.init(project='KLUE-QA', entity='happyface-boostcamp')\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    \n",
    "    print('Training {:,} batches...'.format(len(train_dataloader)))\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    # The total number of batches per epoch.\n",
    "    num_batches = len(train_dataloader)\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        # b_seg_ids = batch[2].to(device)\n",
    "        b_start_pos = batch[2].to(device)\n",
    "        b_end_pos = batch[3].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        # The results are returned in a results object, documented here:\n",
    "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.QuestionAnsweringModelOutput\n",
    "        # For our useage here, it returns the loss (because we provided labels)\n",
    "        # and the \"logits\"--the model outputs prior to activation.\n",
    "        outputs = model(b_input_ids, \n",
    "                        attention_mask=b_input_mask, \n",
    "                        # token_type_ids = b_seg_ids,\n",
    "                        start_positions=b_start_pos,\n",
    "                        end_positions=b_end_pos,\n",
    "                        return_dict=True)\n",
    "\n",
    "        # You can see the outputs in the source code here:\n",
    "        # https://github.com/huggingface/transformers/blob/master/src/transformers/modeling_bert.py#L1601\n",
    "        # \n",
    "        # The forward pass returns the loss, start_logits, and end_logits.\n",
    "        loss = outputs.loss\n",
    "        start_logits = outputs.start_logits\n",
    "        end_logits = outputs.end_logits\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    \n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "\n",
    "    t0_val = time.time()\n",
    "\n",
    "    # Tracking results. \n",
    "    pred_start, pred_end, true_start, true_end = [], [], [], []\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
    "        # the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        # b_seg_ids = batch[2].to(device)\n",
    "        b_start_pos = batch[2].to(device)\n",
    "        b_end_pos = batch[3].to(device)\n",
    "        \n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # token_type_ids is the same as the \"segment ids\", which \n",
    "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "            # values prior to applying an activation function like the softmax.\n",
    "            outputs = model(b_input_ids, \n",
    "                            # token_type_ids=b_seg_ids, \n",
    "                            attention_mask=b_input_mask,\n",
    "                            start_positions=b_start_pos,\n",
    "                            end_positions=b_end_pos,\n",
    "                            return_dict=True)\n",
    "\n",
    "        # The forward pass returns the loss, start_logits, and end_logits.\n",
    "        loss = outputs.loss\n",
    "        start_logits = outputs.start_logits\n",
    "        end_logits = outputs.end_logits        \n",
    "\n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        start_logits = start_logits.detach().cpu().numpy()\n",
    "        end_logits = end_logits.detach().cpu().numpy()\n",
    "        \n",
    "        # Move the correct start and end positions back to the CPU.\n",
    "        b_start_pos = b_start_pos.to('cpu').numpy()\n",
    "        b_end_pos = b_end_pos.to('cpu').numpy()\n",
    "\n",
    "        # Find the tokens with the highest `start` and `end` scores.\n",
    "        answer_start = np.argmax(start_logits, axis=1)\n",
    "        answer_end = np.argmax(end_logits, axis=1)\n",
    "\n",
    "        # Store predictions and true labels\n",
    "        pred_start.append(answer_start)\n",
    "        pred_end.append(answer_end)\n",
    "        true_start.append(b_start_pos)\n",
    "        true_end.append(b_end_pos)\n",
    "\n",
    "    # Combine the results across the batches.\n",
    "    pred_start = np.concatenate(pred_start, axis=0)\n",
    "    pred_end = np.concatenate(pred_end, axis=0)\n",
    "    true_start = np.concatenate(true_start, axis=0)\n",
    "    true_end = np.concatenate(true_end, axis=0)\n",
    "        \n",
    "    # Count up the number of start index predictions and end index predictions \n",
    "    # which match the correct indeces.\n",
    "    num_start_correct = np.sum(pred_start == true_start)\n",
    "    num_end_correct = np.sum(pred_end == true_end)\n",
    "\n",
    "    total_correct = num_start_correct + num_end_correct\n",
    "    total_indeces = len(true_start) + len(true_end)\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = float(total_correct) / float(total_indeces)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # validation_time = format_time(time.time() - t0_val)\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    # print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    wandb.log(\n",
    "                    {\n",
    "                        'train/loss':avg_train_loss, \n",
    "                        'train/learning_rate':optimizer.param_groups[0]['lr'], \n",
    "                        'eval/loss':avg_val_loss,\n",
    "                        'eval/accuracy':avg_val_accuracy,\n",
    "                        }\n",
    "                        )\n",
    "    \n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
