{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf0014a3-05e2-4d67-957e-77efb761e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "\n",
    "class elastic:\n",
    "    def __init__(self, INDEX_NAME, context_path=\"../data/wikipedia_documents.json\"):\n",
    "        self.index_name = INDEX_NAME\n",
    "        try:\n",
    "            self.es.transport.close()\n",
    "        except:\n",
    "            pass\n",
    "        self.context_path = context_path\n",
    "        config = {\n",
    "            \"host\": \"localhost\", \n",
    "            \"port\": 9200,\n",
    "            \"timeout\": 100,\n",
    "            \"max_retries\": 10,\n",
    "            \"retry_on_timeout\": True,\n",
    "            }\n",
    "        self.es = Elasticsearch([config])\n",
    "        \n",
    "        self.index_setting = {\n",
    "            \"settings\": {\n",
    "                \"index\": {\n",
    "                    \"analysis\": {\n",
    "                        \"analyzer\": {\n",
    "                            \"korean\": {\n",
    "                                \"type\": \"custom\",\n",
    "                                \"tokenizer\": \"nori_tokenizer\",\n",
    "                                \"filter\": [\"shingle\"],\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"mappings\": {\n",
    "                \"properties\": {\n",
    "                    \"text\": {\n",
    "                        \"type\": \"text\",\n",
    "                        \"analyzer\": \"korean\",\n",
    "                        \"search_analyzer\": \"korean\",\n",
    "                    },\n",
    "                    \"title\": {\n",
    "                        \"type\": \"text\",\n",
    "                        \"analyzer\": \"korean\",\n",
    "                        \"search_analyzer\": \"korean\",\n",
    "                    },\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def build_elatic(self):\n",
    "        with open(self.context_path) as file:\n",
    "            json_data = json.load(file)\n",
    "        docs = []\n",
    "        for i, j in json_data.items():\n",
    "            docs.append(\n",
    "                {\n",
    "                    \"_index\": \"wikipedia\",\n",
    "                    \"_source\": {\"text\": j[\"text\"], \"title\": j[\"title\"]},\n",
    "                }\n",
    "            )\n",
    "\n",
    "        if self.es.indices.exists(self.index_name):\n",
    "            pass\n",
    "        else:\n",
    "            self.es.indices.create(index=self.index_name, body=self.index_setting)\n",
    "            helpers.bulk(self.es, docs)\n",
    "\n",
    "    def retrieve(self, query_or_dataset, topk):\n",
    "        datas = []\n",
    "\n",
    "        # changing the key into integer type\n",
    "        for i in tqdm(range(len(query_or_dataset))):\n",
    "            cp = {i: v for i, v in query_or_dataset[i].items()}\n",
    "            if (\n",
    "                \"context\" in query_or_dataset[i].keys()\n",
    "                and \"answers\" in query_or_dataset[i].keys()\n",
    "            ):\n",
    "                cp[\"original_context\"] = query_or_dataset[i][\"context\"]\n",
    "\n",
    "            query = query_or_dataset[i][\"question\"]\n",
    "            query = query.replace(\"/\", \"\")\n",
    "            query = query.replace(\"~\", \" \")\n",
    "            res = self.es.search(index=self.index_name, q=query, size=topk+1)\n",
    "            x = res[\"hits\"][\"hits\"]\n",
    "            context = []\n",
    "            for docu in x:\n",
    "                context.append(docu[\"_source\"][\"text\"])\n",
    "            cp[\"context\"] = \"///\".join(context)\n",
    "            datas.append(cp)\n",
    "\n",
    "        return pd.DataFrame(datas)\n",
    "\n",
    "    def retrieve_false(self, query_or_dataset, topk):\n",
    "        datas = []\n",
    "        for i in tqdm(range(len(query_or_dataset))):\n",
    "            cp = {i: v for i, v in query_or_dataset[i].items()}\n",
    "            if (\n",
    "                \"context\" in query_or_dataset[i].keys()\n",
    "                and \"answers\" in query_or_dataset[i].keys()\n",
    "            ):\n",
    "                cp[\"original_context\"] = query_or_dataset[i][\"context\"]\n",
    "\n",
    "            query = query_or_dataset[i][\"question\"]\n",
    "            query = query.replace(\"/\", \"\")\n",
    "            query = query.replace(\"~\", \" \")\n",
    "            res = self.es.search(index=self.index_name, q=query, size=topk+1)\n",
    "            x = res[\"hits\"][\"hits\"]\n",
    "            context = []\n",
    "            for docu in x:\n",
    "                cont = docu[\"_source\"][\"text\"]\n",
    "                # groud truth 제거\n",
    "                if cont == cp[\"original_context\"]: continue\n",
    "                context.append(docu[\"_source\"][\"text\"])\n",
    "            context = context[:topk]\n",
    "            cp[\"context\"] = \"///\".join(context)\n",
    "            datas.append(cp)\n",
    "\n",
    "        return pd.DataFrame(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f9a1d193-bf62-422e-852b-4709bbf6a1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk(\"../data/train_dataset\")\n",
    "train_datasets = dataset[\"train\"]\n",
    "valid_datasets = dataset[\"validation\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "54517cae-02e3-4a30-84af-bee8562ee878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-50-2385cbbed766>:67: DeprecationWarning: Using positional arguments for APIs is deprecated and will be disabled in 8.0.0. Instead use only keyword arguments for all APIs. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  if self.es.indices.exists(self.index_name):\n",
      "/opt/conda/lib/python3.8/site-packages/elasticsearch/connection/base.py:209: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.15/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n"
     ]
    }
   ],
   "source": [
    "x = elastic(\"wikipedia\")\n",
    "x.build_elatic()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train dataset retrieving for hard negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a1eca8b-70b6-4d02-bfca-3df95496e759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3952/3952 [03:29<00:00, 18.84it/s]\n"
     ]
    }
   ],
   "source": [
    "p = x.retrieve_false(train_datasets, 100)\n",
    "p.to_csv(\"/opt/ml/data/train_elastic_top100_noanswer.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation dataset retrieving for hard negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 240/240 [00:12<00:00, 19.16it/s]\n"
     ]
    }
   ],
   "source": [
    "val = x.retrieve_false(valid_datasets, 100)\n",
    "val.to_csv(\"/opt/ml/data/valid_elastic_top100_noanswer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'내각(內閣, cabinet)은 행정부의 주요 각료들로 구성되는 국가의 주요기관이다.\\n\\n의원내각제에서 내각은 수상과 여러 장관으로 조직되는 합의체로, 국가의 행정권을 담당하고 국회에 대한 연대책임을 갖는다. 의원내각제에 있어서 내각은 국가행정의 최고기관인 한편 국민이 구성시키는 의회에 의하여 철저히 견제되어 의회민주주의 체제를 이룬다.\\n\\n그 직접적 유래는 영국에서 국왕의 정치를 자문하던 추밀원에서 찾을 수 있다. 특히 내각은 추밀원의 일개 회의에서 시작하였다가 권한이 집중되어 분리된 기관으로, 이후 국왕의 실권이 사라지고 일명 웨스트민스터 시스템으로 불리는 의원내각제가 성립하면서 의회에 의한 민주적 행정부를 이루게 되었다.\\n\\n한편 국가원수에게 대부분의 권력이 집중되는 대통령중심제와 군주제에서 내각은 원칙적으로 의결권이 없거나 의결의 구속력이 없는 보좌기관에 불과한 경우가 많다.(예: 대한민국의 국무회의)\\n\\n대한민국은 국무회의가 내각에 속하며 권한이 대통령에 비해 제한적이다. 과거 왕조시대 때는 고려시대의 중서문하성, 중추원, 육부 또는 조선시대의 의정부와 육조가 내각과 비슷한 성향을 지니고 있었다.///이하의 국가들은 의회에서 행정부 수반을 선출한다는 점에서 내각제와 닮았다. 그리고 이들 국가들 중 상당수는 행정부 수반이 의회해산권을 갖고, 의회는 내각불신임권을 갖는데 이점 역시 내각제와 닮았다. 하지만 내각제와 달리 의회에서 선출되는 자는 행정부 수반의 지위 뿐만 아니라 국가 원수의 지위도 가진다. 그래서 의회에서 선출되는 자의 직위는 총리가 아니라, 대통령이다. 이처럼 1인이 행정부 수반과 국가 원수의 지위를 겸한다는 점에서 대통령중심제와 닮았다. 이상과 같은 이유로 이들 국가들의 정부 형태는 대통령제와 내각제의 절충형이지만, 행정 권한이 2인에게로 분리되어 있지 않으므로 이원집정부제는 아니다.\\n\\n \\n* 나우루\\n* 남아프리카 공화국\\n* 마셜 제도\\n* 마카오\\n* 미얀마\\n* 미크로네시아 연방\\n* 보츠와나\\n* 산마리노\\n* 수리남\\n* 키리바시\\n* 홍콩///이하의 국'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.context[0][:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test dataset retrieval for elastic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이 문서는 나라 목록이며, 전 세계 206개 나라의 각 현황과 주권 승인 정보를 개요 형태로 나열하고 있다.\\n\\n이 목록은 명료화를 위해 두 부분으로 나뉘어 있다.\\n\\n# 첫 번째 부분은 바티칸 시국과 팔레스타인을 포함하여 유엔 등 국제 기구에 가입되어 국제적인 승인을 널리 받았다고 여기는 195개 나라를 나열하고 있다.\\n# 두 번째 부분은 일부 지역의 주권을 사실상 (데 팍토) 행사하고 있지만, 아직 국제적인 승인을 널리 받지 않았다고 여기는 11개 나라를 나열하고 있다.\\n\\n두 목록은 모두 가나다 순이다.\\n\\n일부 국가의 경우 국가로서의 자격에 논쟁의 여부가 있으며, 이 때문에 이러한 목록을 엮는 것은 매우 어렵고 논란이 생길 수 있는 과정이다. 이 목록을 구성하고 있는 국가를 선정하는 기준에 대한 정보는 \"포함 기준\" 단락을 통해 설명하였다. 나라에 대한 일반적인 정보는 \"국가\" 문서에서 설명하고 있다.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_path = '../data/wikipedia_documents.json'\n",
    "with open(context_path, 'r', encoding= \"utf-8\") as f:\n",
    "    wiki = json.load(f)\n",
    "search_corpus = list(dict.fromkeys([v['text'] for v in wiki.values()]))\n",
    "search_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '이 문서는 나라 목록이며, 전 세계 206개 나라의 각 현황과 주권 승인 정보를 개요 형태로 나열하고 있다.\\n\\n이 목록은 명료화를 위해 두 부분으로 나뉘어 있다.\\n\\n# 첫 번째 부분은 바티칸 시국과 팔레스타인을 포함하여 유엔 등 국제 기구에 가입되어 국제적인 승인을 널리 받았다고 여기는 195개 나라를 나열하고 있다.\\n# 두 번째 부분은 일부 지역의 주권을 사실상 (데 팍토) 행사하고 있지만, 아직 국제적인 승인을 널리 받지 않았다고 여기는 11개 나라를 나열하고 있다.\\n\\n두 목록은 모두 가나다 순이다.\\n\\n일부 국가의 경우 국가로서의 자격에 논쟁의 여부가 있으며, 이 때문에 이러한 목록을 엮는 것은 매우 어렵고 논란이 생길 수 있는 과정이다. 이 목록을 구성하고 있는 국가를 선정하는 기준에 대한 정보는 \"포함 기준\" 단락을 통해 설명하였다. 나라에 대한 일반적인 정보는 \"국가\" 문서에서 설명하고 있다.',\n",
       " 'corpus_source': '위키피디아',\n",
       " 'url': 'TODO',\n",
       " 'domain': None,\n",
       " 'title': '나라 목록',\n",
       " 'author': None,\n",
       " 'html': None,\n",
       " 'document_id': 0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki[\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_or_dataset = {int(k):v for k,v in wiki.items()}\n",
    "query_or_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'question'],\n",
       "    num_rows: 600\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# load test dataset as dataframe\n",
    "test = load_from_disk('../data/test_dataset')\n",
    "test_datasets = test['validation']\n",
    "test_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"유령'은 어느 행성에서 지구로 왔는가?\", 'id': 'mrc-1-000653'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 401/600 [00:20<00:08, 22.20it/s]"
     ]
    }
   ],
   "source": [
    "test = x.retrieve(test_datasets, 100)\n",
    "test.to_csv(\"/opt/ml/data/test_elastic_top100.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
