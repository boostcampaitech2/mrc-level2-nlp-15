{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BertModel, RobertaModel,\n",
    "    BertPreTrainedModel,\n",
    "    AdamW, get_linear_schedule_with_warmup,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import (\n",
    "    Dataset,\n",
    "    load_from_disk,\n",
    "    concatenate_datasets,\n",
    ")\n",
    "\n",
    "from typing import List\n",
    "from torch.utils.data import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 난수 고정\n",
    "def set_seed(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    \n",
    "set_seed(42) # magic number :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:[1.7.1].\n",
      "device:[cuda:0].\n"
     ]
    }
   ],
   "source": [
    "print (\"PyTorch version:[%s].\"%(torch.__version__))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (\"device:[%s].\"%(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('/opt/ml/data/train_dataset')\n",
    "train_dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/opt/ml/custom/top100_wikipedia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_indices = []\n",
    "doc_scores = []\n",
    "for i in range(len(data)) :\n",
    "    tmp_indices = eval(data['document_id'][i])\n",
    "    tmp_scores = eval(data['score'][i])\n",
    "    doc_indices.append(tmp_indices)\n",
    "    doc_scores.append(tmp_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/data/wikipedia_documents.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    wiki = json.load(f)\n",
    "\n",
    "corpus = []\n",
    "for v in wiki.values() :\n",
    "    corpus.append(v['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEncoder(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertEncoder, self).__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.init_weights()\n",
    "        classifier_dropout=(\n",
    "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = torch.nn.Dropout(classifier_dropout)\n",
    "        self.linear = torch.nn.Linear(config.hidden_size, 1)\n",
    "      \n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids, \n",
    "            attention_mask=None,\n",
    "            token_type_ids=None\n",
    "        ): \n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        output = self.linear(pooled_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_encoder = torch.load('/opt/ml/custom/c_encoder_e40_b16.pt')\n",
    "model_checkpoint = \"klue/bert-base\"\n",
    "# 혹시 위에서 사용한 encoder가 있다면 주석처리 후 진행해주세요 (CUDA ...)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc11d1579ba64042aba9f623ccea63f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=240.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-e8a615bf4e65>:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'input_ids' : torch.tensor(tokenized_examples['input_ids'][i].unsqueeze(dim=0)).to('cuda'),\n",
      "<ipython-input-11-e8a615bf4e65>:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'attention_mask' : torch.tensor(tokenized_examples['attention_mask'][i].unsqueeze(dim=0)).to('cuda'),\n",
      "<ipython-input-11-e8a615bf4e65>:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'token_type_ids' : torch.tensor(tokenized_examples['token_type_ids'][i].unsqueeze(dim=0)).to('cuda')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "question_data = dataset['validation']['question']\n",
    "with torch.no_grad() : \n",
    "    c_encoder.eval()\n",
    "\n",
    "    result_scores = []\n",
    "    result_indices = []\n",
    "    for i in tqdm(range(len(question_data))) :\n",
    "        question = question_data[i]\n",
    "        question_score = []\n",
    "        for indice in doc_indices[i] :\n",
    "            passage = corpus[indice]\n",
    "            tokenized_examples = tokenizer(\n",
    "                question,\n",
    "                passage,\n",
    "                truncation=\"only_second\",\n",
    "                max_length=512,\n",
    "                stride=128,\n",
    "                return_overflowing_tokens=True,\n",
    "                return_offsets_mapping=True,\n",
    "                #return_token_type_ids=False,  # roberta모델을 사용할 경우 False, bert를 사용할 경우 True로 표기해야합니다.\n",
    "                padding=\"max_length\",\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            score = 0\n",
    "            for i in range(len(tokenized_examples['input_ids'])) :\n",
    "                c_input = {\n",
    "                    'input_ids' : torch.tensor(tokenized_examples['input_ids'][i].unsqueeze(dim=0)).to('cuda'),\n",
    "                    'attention_mask' : torch.tensor(tokenized_examples['attention_mask'][i].unsqueeze(dim=0)).to('cuda'),\n",
    "                    'token_type_ids' : torch.tensor(tokenized_examples['token_type_ids'][i].unsqueeze(dim=0)).to('cuda')\n",
    "                }\n",
    "                tmp_score = c_encoder(**c_input).to('cpu')\n",
    "                score += tmp_score\n",
    "            score = score / len(tokenized_examples['input_ids'])\n",
    "            question_score.append(score)\n",
    "        sort_result = torch.sort(torch.tensor(question_score), descending=True)\n",
    "        scores, index_list = sort_result[0], sort_result[1]\n",
    "\n",
    "        result_scores.append(scores.tolist())\n",
    "        result_indices.append(index_list.tolist())        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 점수 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_indices = []\n",
    "for i in range(len(doc_indices)) :\n",
    "    t_list = [doc_indices[i][result_indices[i][k]] for k in range(100)]\n",
    "    final_indices.append(t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8ed289ba804748860807cabbff7641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dense retrieval: ', max=240.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CE\n",
    "total = []\n",
    "for idx, example in enumerate(\n",
    "        tqdm(dataset['validation'], desc=\"Dense retrieval: \")\n",
    "    ):\n",
    "        tmp = {\n",
    "            # Query와 해당 id를 반환합니다.\n",
    "            \"question\": example[\"question\"],\n",
    "            \"id\": example[\"id\"],\n",
    "            # Retrieve한 Passage의 id, context를 반환합니다.\n",
    "            \"context_id\": final_indices[idx],\n",
    "            \"context\": \" \".join(  # 기존에는 ' '.join()\n",
    "                [corpus[pid] for pid in final_indices[idx]]\n",
    "            ),\n",
    "        }\n",
    "        if \"context\" in example.keys() and \"answers\" in example.keys():\n",
    "            # validation 데이터를 사용하면 ground_truth context와 answer도 반환합니다.\n",
    "            tmp[\"original_context\"] = example[\"context\"]\n",
    "            tmp[\"answers\"] = example[\"answers\"]\n",
    "        total.append(tmp)\n",
    "\n",
    "CE_data = pd.DataFrame(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "correct_length = []\n",
    "for i in range(len(CE_data)) :\n",
    "    if CE_data['original_context'][i] in CE_data['context'][i] :\n",
    "        correct_length.append(i)\n",
    "print(len(correct_length) / len(dataset['validation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_indices = []\n",
    "for i in range(len(doc_indices)) :\n",
    "    t_list = [doc_indices[i][k] for k in range(100)]\n",
    "    elastic_indices.append(t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d794cc6a5a4be7b5833a607fc45c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dense retrieval: ', max=240.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Elastic\n",
    "total = []\n",
    "for idx, example in enumerate(\n",
    "        tqdm(dataset['validation'], desc=\"Dense retrieval: \")\n",
    "    ):\n",
    "        tmp = {\n",
    "            # Query와 해당 id를 반환합니다.\n",
    "            \"question\": example[\"question\"],\n",
    "            \"id\": example[\"id\"],\n",
    "            # Retrieve한 Passage의 id, context를 반환합니다.\n",
    "            \"context_id\": elastic_indices[idx],\n",
    "            \"context\": \" \".join(  # 기존에는 ' '.join()\n",
    "                [corpus[pid] for pid in elastic_indices[idx]]\n",
    "            ),\n",
    "        }\n",
    "        if \"context\" in example.keys() and \"answers\" in example.keys():\n",
    "            # validation 데이터를 사용하면 ground_truth context와 answer도 반환합니다.\n",
    "            tmp[\"original_context\"] = example[\"context\"]\n",
    "            tmp[\"answers\"] = example[\"answers\"]\n",
    "        total.append(tmp)\n",
    "\n",
    "elasitc_data = pd.DataFrame(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8541666666666666\n"
     ]
    }
   ],
   "source": [
    "correct_length = []\n",
    "for i in range(len(elasitc_data)) :\n",
    "    if elasitc_data['original_context'][i] in elasitc_data['context'][i] :\n",
    "        correct_length.append(i)\n",
    "print(len(correct_length) / len(dataset['validation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5d555fae82a4f309ce287ad232caa20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "scale_ce = []\n",
    "scale_elastic = []\n",
    "for ce, elastic in tqdm(zip(result_scores, doc_scores)) :\n",
    "    temp_ce = np.array(ce).reshape(-1, 1)\n",
    "    temp_el = np.array(elastic).reshape(-1, 1)\n",
    "    scale_ce.append(scaler.fit_transform(temp_ce).reshape(-1).tolist())\n",
    "    scale_elastic.append(scaler.fit_transform(temp_el).reshape(-1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_scores = []\n",
    "real_indices = []\n",
    "for i in range(len(scale_ce)) :\n",
    "    doc = {}\n",
    "    for j in range(len(scale_ce[0])) :\n",
    "        doc[final_indices[i][j]] = scale_ce[i][j]\n",
    "    \n",
    "    for j in range(len(scale_elastic[0])) :\n",
    "        if doc_indices[i][j] in doc.keys() :\n",
    "            doc[doc_indices[i][j]] += scale_elastic[i][j]\n",
    "    doc = dict(sorted(doc.items(), key = lambda x: x[1], reverse = True))\n",
    "    real_scores.append(list(doc.values()))\n",
    "    real_indices.append(list(doc.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_scores = []\n",
    "real_indices = []\n",
    "for i in range(len(scale_ce)) :\n",
    "    doc = {}\n",
    "    for j in range(len(scale_ce[0])) :\n",
    "        doc[final_indices[i][j]] = scale_ce[i][j] * 3 # cross 1.1배\n",
    "    \n",
    "    for j in range(len(scale_elastic[0])) :\n",
    "        if doc_indices[i][j] in doc.keys() :\n",
    "            doc[doc_indices[i][j]] += scale_elastic[i][j]\n",
    "    doc = dict(sorted(doc.items(), key = lambda x: x[1], reverse = True))\n",
    "    real_scores.append(list(doc.values()))\n",
    "    real_indices.append(list(doc.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastic indices: [17913, 17914, 9027, 4473, 49024, 49398, 46605, 15066, 20072, 41816]\n",
      "cross encoder: [9027, 4473, 22077, 38855, 24768, 20072, 15066, 15634, 1277, 5831]\n",
      "ensemble: [9027, 4473, 20072, 15066, 22077, 38855, 2321, 6875, 9497, 1277]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print('elastic indices:', doc_indices[i][:10])\n",
    "print('cross encoder:', final_indices[i][:10])\n",
    "print('ensemble:', real_indices[i][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9027, 4473, 17914, 20072, 17913, 15066, 2321, 6875, 49398, 9497]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " [9027, 4473, 17914, 20072, 17913, 15066, 2321, 6875, 49398, 9497]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_end_indices = []\n",
    "for i in range(len(real_indices)) :\n",
    "    t_list = [real_indices[i][k] for k in range(5)]\n",
    "    the_end_indices.append(t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eafea86bfacd4439a30295f407a09a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dense retrieval: ', max=240.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final = []\n",
    "for idx, example in enumerate(\n",
    "        tqdm(dataset['validation'], desc=\"Dense retrieval: \")\n",
    "    ):\n",
    "        tmp = {\n",
    "            # Query와 해당 id를 반환합니다.\n",
    "            \"question\": example[\"question\"],\n",
    "            \"id\": example[\"id\"],\n",
    "            # Retrieve한 Passage의 id, context를 반환합니다.\n",
    "            \"context_id\": the_end_indices[idx],\n",
    "            \"context\": \" \".join(  # 기존에는 ' '.join()\n",
    "                [corpus[pid] for pid in the_end_indices[idx]]\n",
    "            ),\n",
    "        }\n",
    "        if \"context\" in example.keys() and \"answers\" in example.keys():\n",
    "            # validation 데이터를 사용하면 ground_truth context와 answer도 반환합니다.\n",
    "            tmp[\"original_context\"] = example[\"context\"]\n",
    "            tmp[\"answers\"] = example[\"answers\"]\n",
    "        final.append(tmp)\n",
    "\n",
    "cqas_50 = pd.DataFrame(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9041666666666667\n"
     ]
    }
   ],
   "source": [
    "correct_length = []\n",
    "for i in range(len(cqas_50)) :\n",
    "    if cqas_50['original_context'][i] in cqas_50['context'][i] :\n",
    "        correct_length.append(i)\n",
    "print(len(correct_length) / len(dataset['validation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8791666666666667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "cqas_50.to_csv('retrieval_elastic_cross_ensemble_5_one_on_three.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>id</th>\n",
       "      <th>context_id</th>\n",
       "      <th>context</th>\n",
       "      <th>original_context</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>처음으로 부실 경영인에 대한 보상 선고를 받은 회사는?</td>\n",
       "      <td>mrc-0-003264</td>\n",
       "      <td>[9027, 4473, 20072, 15066, 22077]</td>\n",
       "      <td>순천여자고등학교 졸업, 1973년 이화여자대학교를 졸업하고 1975년 제17회 사법...</td>\n",
       "      <td>순천여자고등학교 졸업, 1973년 이화여자대학교를 졸업하고 1975년 제17회 사법...</td>\n",
       "      <td>{'answer_start': [284], 'text': ['한보철강']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>스카버러 남쪽과 코보콘그 마을의 철도 노선이 처음 연장된 연도는?</td>\n",
       "      <td>mrc-0-004762</td>\n",
       "      <td>[51765, 21916, 23373, 37730, 23603]</td>\n",
       "      <td>요크 카운티 동쪽에 처음으로 여객 열차 운행이 시작한 시점은 1868년 토론토 &amp; ...</td>\n",
       "      <td>요크 카운티 동쪽에 처음으로 여객 열차 운행이 시작한 시점은 1868년 토론토 &amp; ...</td>\n",
       "      <td>{'answer_start': [146], 'text': ['1871년']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>촌락에서 운영 위원 후보자 이름을 쓰기위해 사용된 것은?</td>\n",
       "      <td>mrc-1-001810</td>\n",
       "      <td>[15694, 746, 5300, 28167, 19853]</td>\n",
       "      <td>촐라 정부\\n 촐라의 정부 체제는 전제군주제였으며,2001 촐라의 군주는 절대적인 ...</td>\n",
       "      <td>촐라 정부\\n 촐라의 정부 체제는 전제군주제였으며,2001 촐라의 군주는 절대적인 ...</td>\n",
       "      <td>{'answer_start': [517], 'text': ['나뭇잎']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>로타이르가 백조를 구하기 위해 사용한 것은?</td>\n",
       "      <td>mrc-1-000219</td>\n",
       "      <td>[59536, 59537, 59533, 59534, 59527]</td>\n",
       "      <td>프랑스의 십자군 무훈시는 1099년 예루살렘 왕국의 통치자가 된 고드프루아 드 부용...</td>\n",
       "      <td>프랑스의 십자군 무훈시는 1099년 예루살렘 왕국의 통치자가 된 고드프루아 드 부용...</td>\n",
       "      <td>{'answer_start': [1109], 'text': ['금대야']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>의견을 자유롭게 나누는 것은 조직 내 어떤 관계에서 가능한가?</td>\n",
       "      <td>mrc-1-000285</td>\n",
       "      <td>[32991, 46612, 12709, 20645, 46412]</td>\n",
       "      <td>탈관료제화는 현대사회에서 관료제 성격이 약화되는 현상이다. 현대사회에서 관료제는 약...</td>\n",
       "      <td>탈관료제화는 현대사회에서 관료제 성격이 약화되는 현상이다. 현대사회에서 관료제는 약...</td>\n",
       "      <td>{'answer_start': [386], 'text': ['수평적 관계']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>전단이 연나라와의 전쟁에서 승리했을 당시 제나라의 왕은 누구인가?</td>\n",
       "      <td>mrc-0-000484</td>\n",
       "      <td>[53270, 53263, 52028, 53265, 53267]</td>\n",
       "      <td>기원전 265년, 전단은 조나라의 군사를 거느리고 연나라를 공격하여 중양(中陽)을 ...</td>\n",
       "      <td>연나라 군대의 사령관이 악의에서 기겁으로 교체되자, 전단은 스스로 신령의 계시를 받...</td>\n",
       "      <td>{'answer_start': [1084], 'text': ['제 양왕']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>공놀이 경기장 중 일부는 어디에 위치하고 있나?</td>\n",
       "      <td>mrc-0-002095</td>\n",
       "      <td>[12190, 36694, 7781, 3227, 11634]</td>\n",
       "      <td>현재 우리가 볼 수 있는 티칼의 모습은 펜실베이니아 대학교와 과테말라 정부의 협조 ...</td>\n",
       "      <td>현재 우리가 볼 수 있는 티칼의 모습은 펜실베이니아 대학교와 과테말라 정부의 협조 ...</td>\n",
       "      <td>{'answer_start': [343], 'text': [''일곱 개의 신전 광장...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>창씨개명령의 시행일을 미루는 것을 수락한 인물은?</td>\n",
       "      <td>mrc-0-003083</td>\n",
       "      <td>[772, 5326, 34671, 9029, 4475]</td>\n",
       "      <td>1940년 5월 1일 오전 창씨개명에 비협조적이라는 이유로 조선총독부 경무국에서 소...</td>\n",
       "      <td>1940년 5월 1일 오전 창씨개명에 비협조적이라는 이유로 조선총독부 경무국에서 소...</td>\n",
       "      <td>{'answer_start': [247], 'text': ['미나미 지로']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>망코 잉카가 쿠스코를 되찾기 위해 마련한 군사는 총 몇 명인가?</td>\n",
       "      <td>mrc-0-002978</td>\n",
       "      <td>[48575, 55432, 56329, 55430, 48576]</td>\n",
       "      <td>빌카밤바 지역은 파차쿠티 황제 때 부터 잉카 제국에 속해있던 지역이었다. 스페인 군...</td>\n",
       "      <td>빌카밤바 지역은 파차쿠티 황제 때 부터 잉카 제국에 속해있던 지역이었다. 스페인 군...</td>\n",
       "      <td>{'answer_start': [563], 'text': ['200,000명']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>마르크스주의자들의 사상은?</td>\n",
       "      <td>mrc-1-000622</td>\n",
       "      <td>[17847, 3222, 7776, 32874, 1227]</td>\n",
       "      <td>마르크스주의 법학(Marx主義法學)은 넓게 보아 유물론적 변증법에 입각해서 법을 인...</td>\n",
       "      <td>사회주의 혁명은 오로지 선진노동자계급에 기초한 계급투쟁으로서 이루어질 수 있다고 주...</td>\n",
       "      <td>{'answer_start': [811], 'text': ['공산주의']}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 question            id  \\\n",
       "0          처음으로 부실 경영인에 대한 보상 선고를 받은 회사는?  mrc-0-003264   \n",
       "1    스카버러 남쪽과 코보콘그 마을의 철도 노선이 처음 연장된 연도는?  mrc-0-004762   \n",
       "2         촌락에서 운영 위원 후보자 이름을 쓰기위해 사용된 것은?  mrc-1-001810   \n",
       "3                로타이르가 백조를 구하기 위해 사용한 것은?  mrc-1-000219   \n",
       "4      의견을 자유롭게 나누는 것은 조직 내 어떤 관계에서 가능한가?  mrc-1-000285   \n",
       "..                                    ...           ...   \n",
       "235  전단이 연나라와의 전쟁에서 승리했을 당시 제나라의 왕은 누구인가?  mrc-0-000484   \n",
       "236            공놀이 경기장 중 일부는 어디에 위치하고 있나?  mrc-0-002095   \n",
       "237           창씨개명령의 시행일을 미루는 것을 수락한 인물은?  mrc-0-003083   \n",
       "238   망코 잉카가 쿠스코를 되찾기 위해 마련한 군사는 총 몇 명인가?  mrc-0-002978   \n",
       "239                        마르크스주의자들의 사상은?  mrc-1-000622   \n",
       "\n",
       "                              context_id  \\\n",
       "0      [9027, 4473, 20072, 15066, 22077]   \n",
       "1    [51765, 21916, 23373, 37730, 23603]   \n",
       "2       [15694, 746, 5300, 28167, 19853]   \n",
       "3    [59536, 59537, 59533, 59534, 59527]   \n",
       "4    [32991, 46612, 12709, 20645, 46412]   \n",
       "..                                   ...   \n",
       "235  [53270, 53263, 52028, 53265, 53267]   \n",
       "236    [12190, 36694, 7781, 3227, 11634]   \n",
       "237       [772, 5326, 34671, 9029, 4475]   \n",
       "238  [48575, 55432, 56329, 55430, 48576]   \n",
       "239     [17847, 3222, 7776, 32874, 1227]   \n",
       "\n",
       "                                               context  \\\n",
       "0    순천여자고등학교 졸업, 1973년 이화여자대학교를 졸업하고 1975년 제17회 사법...   \n",
       "1    요크 카운티 동쪽에 처음으로 여객 열차 운행이 시작한 시점은 1868년 토론토 & ...   \n",
       "2    촐라 정부\\n 촐라의 정부 체제는 전제군주제였으며,2001 촐라의 군주는 절대적인 ...   \n",
       "3    프랑스의 십자군 무훈시는 1099년 예루살렘 왕국의 통치자가 된 고드프루아 드 부용...   \n",
       "4    탈관료제화는 현대사회에서 관료제 성격이 약화되는 현상이다. 현대사회에서 관료제는 약...   \n",
       "..                                                 ...   \n",
       "235  기원전 265년, 전단은 조나라의 군사를 거느리고 연나라를 공격하여 중양(中陽)을 ...   \n",
       "236  현재 우리가 볼 수 있는 티칼의 모습은 펜실베이니아 대학교와 과테말라 정부의 협조 ...   \n",
       "237  1940년 5월 1일 오전 창씨개명에 비협조적이라는 이유로 조선총독부 경무국에서 소...   \n",
       "238  빌카밤바 지역은 파차쿠티 황제 때 부터 잉카 제국에 속해있던 지역이었다. 스페인 군...   \n",
       "239  마르크스주의 법학(Marx主義法學)은 넓게 보아 유물론적 변증법에 입각해서 법을 인...   \n",
       "\n",
       "                                      original_context  \\\n",
       "0    순천여자고등학교 졸업, 1973년 이화여자대학교를 졸업하고 1975년 제17회 사법...   \n",
       "1    요크 카운티 동쪽에 처음으로 여객 열차 운행이 시작한 시점은 1868년 토론토 & ...   \n",
       "2    촐라 정부\\n 촐라의 정부 체제는 전제군주제였으며,2001 촐라의 군주는 절대적인 ...   \n",
       "3    프랑스의 십자군 무훈시는 1099년 예루살렘 왕국의 통치자가 된 고드프루아 드 부용...   \n",
       "4    탈관료제화는 현대사회에서 관료제 성격이 약화되는 현상이다. 현대사회에서 관료제는 약...   \n",
       "..                                                 ...   \n",
       "235  연나라 군대의 사령관이 악의에서 기겁으로 교체되자, 전단은 스스로 신령의 계시를 받...   \n",
       "236  현재 우리가 볼 수 있는 티칼의 모습은 펜실베이니아 대학교와 과테말라 정부의 협조 ...   \n",
       "237  1940년 5월 1일 오전 창씨개명에 비협조적이라는 이유로 조선총독부 경무국에서 소...   \n",
       "238  빌카밤바 지역은 파차쿠티 황제 때 부터 잉카 제국에 속해있던 지역이었다. 스페인 군...   \n",
       "239  사회주의 혁명은 오로지 선진노동자계급에 기초한 계급투쟁으로서 이루어질 수 있다고 주...   \n",
       "\n",
       "                                               answers  \n",
       "0            {'answer_start': [284], 'text': ['한보철강']}  \n",
       "1           {'answer_start': [146], 'text': ['1871년']}  \n",
       "2             {'answer_start': [517], 'text': ['나뭇잎']}  \n",
       "3            {'answer_start': [1109], 'text': ['금대야']}  \n",
       "4          {'answer_start': [386], 'text': ['수평적 관계']}  \n",
       "..                                                 ...  \n",
       "235         {'answer_start': [1084], 'text': ['제 양왕']}  \n",
       "236  {'answer_start': [343], 'text': [''일곱 개의 신전 광장...  \n",
       "237        {'answer_start': [247], 'text': ['미나미 지로']}  \n",
       "238      {'answer_start': [563], 'text': ['200,000명']}  \n",
       "239          {'answer_start': [811], 'text': ['공산주의']}  \n",
       "\n",
       "[240 rows x 6 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cqas_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Tue Nov  2 10:29:59 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-PCIE...  Off  | 00000000:00:05.0 Off |                  Off |\n",
      "| N/A   58C    P0   172W / 250W |  31682MiB / 32510MiB |     91%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_final = []\n",
    "for ce, ela in zip(scale_ce, scale_elastic) :\n",
    "    tmp = []\n",
    "    for i in range(len(ce)) :\n",
    "        tmp.append(1.1 * ce[i]+ela[i])\n",
    "    real_final.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([2.1000, 2.0982, 1.8127, 1.8107, 1.6259, 1.5978, 1.4961, 1.4187, 1.3991,\n",
       "        1.3954, 1.3876, 1.3740, 1.3413, 1.2848, 1.2575, 1.2426, 1.1784, 1.1174,\n",
       "        1.0878, 1.0532, 1.0370, 0.9837, 0.9260, 0.8683, 0.8343, 0.7762, 0.7731,\n",
       "        0.7653, 0.7610, 0.7204, 0.7159, 0.7084, 0.7009, 0.6846, 0.6565, 0.6267,\n",
       "        0.6198, 0.5877, 0.5691, 0.5605, 0.5348, 0.5290, 0.5242, 0.5179, 0.5124,\n",
       "        0.4975, 0.4758, 0.4556, 0.4359, 0.4260, 0.4100, 0.3862, 0.3787, 0.3689,\n",
       "        0.3548, 0.3487, 0.3296, 0.3193, 0.2950, 0.2881, 0.2771, 0.2761, 0.2637,\n",
       "        0.2528, 0.2493, 0.2343, 0.2275, 0.2177, 0.2175, 0.2107, 0.2016, 0.1967,\n",
       "        0.1899, 0.1865, 0.1862, 0.1691, 0.1612, 0.1585, 0.1397, 0.1347, 0.1314,\n",
       "        0.1302, 0.1278, 0.1180, 0.1147, 0.1051, 0.1000, 0.0915, 0.0873, 0.0757,\n",
       "        0.0710, 0.0702, 0.0687, 0.0664, 0.0441, 0.0359, 0.0274, 0.0193, 0.0134,\n",
       "        0.0000]),\n",
       "indices=tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
       "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "        90, 91, 92, 93, 94, 95, 96, 97, 98, 99]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sort(torch.tensor(real_final[0]), descending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "tttt = pd.read_csv('/opt/ml/custom/top100_wikipedia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tttt)) :\n",
    "    if len(list(set(eval(tttt['document_id'][i])))) != 100 :\n",
    "        print('ㅈ망')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('/opt/ml/data/test_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "print(len(set(eval(data['document_id'][6]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/opt/ml/custom/test_elastic_top100.csv')\n",
    "\n",
    "doc_indices = []\n",
    "doc_scores = []\n",
    "for i in range(len(data)) :\n",
    "    tmp_indices = eval(data['document_id'][i])\n",
    "    tmp_scores = eval(data['score'][i])\n",
    "    doc_indices.append(tmp_indices)\n",
    "    doc_scores.append(tmp_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a88125903eb49cb80424bdbfc7403cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# test에 대해서만 실행\n",
    "for i in tqdm(range(len(doc_indices))) :\n",
    "    for j in range(len(doc_indices[i])) :\n",
    "        doc_indices[i][j] = int(doc_indices[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/data/wikipedia_documents.json', \"r\", encoding=\"utf-8\") as f:\n",
    "    wiki = json.load(f)\n",
    "\n",
    "corpus = []\n",
    "for v in wiki.values() :\n",
    "    corpus.append(v['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertEncoder(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertEncoder, self).__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.init_weights()\n",
    "        classifier_dropout=(\n",
    "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = torch.nn.Dropout(classifier_dropout)\n",
    "        self.linear = torch.nn.Linear(config.hidden_size, 1)\n",
    "      \n",
    "    def forward(\n",
    "            self,\n",
    "            input_ids, \n",
    "            attention_mask=None,\n",
    "            token_type_ids=None\n",
    "        ): \n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        \n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        output = self.linear(pooled_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_encoder = torch.load('/opt/ml/custom/c_encoder_e40_b16.pt')\n",
    "model_checkpoint = \"klue/bert-base\"\n",
    "# 혹시 위에서 사용한 encoder가 있다면 주석처리 후 진행해주세요 (CUDA ...)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_data = dataset['validation']['question']\n",
    "with torch.no_grad() : \n",
    "    c_encoder.eval()\n",
    "\n",
    "    result_scores = []\n",
    "    result_indices = []\n",
    "    for i in tqdm(range(len(question_data))) :\n",
    "        question = question_data[i]\n",
    "        question_score = []\n",
    "        for indice in tqdm(doc_indices[i]) :\n",
    "            passage = corpus[int(indice)]\n",
    "            tokenized_examples = tokenizer(\n",
    "                question,\n",
    "                passage,\n",
    "                truncation=\"only_second\",\n",
    "                max_length=512,\n",
    "                stride=128,\n",
    "                return_overflowing_tokens=True,\n",
    "                return_offsets_mapping=True,\n",
    "                #return_token_type_ids=False,  # roberta모델을 사용할 경우 False, bert를 사용할 경우 True로 표기해야합니다.\n",
    "                padding=\"max_length\",\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            score = 0\n",
    "            for i in range(len(tokenized_examples['input_ids'])) :\n",
    "                c_input = {\n",
    "                    'input_ids' : torch.tensor(tokenized_examples['input_ids'][i].unsqueeze(dim=0)).to('cuda'),\n",
    "                    'attention_mask' : torch.tensor(tokenized_examples['attention_mask'][i].unsqueeze(dim=0)).to('cuda'),\n",
    "                    'token_type_ids' : torch.tensor(tokenized_examples['token_type_ids'][i].unsqueeze(dim=0)).to('cuda')\n",
    "                }\n",
    "                tmp_score = c_encoder(**c_input).to('cpu')\n",
    "                score += tmp_score\n",
    "            score = score / len(tokenized_examples['input_ids'])\n",
    "            question_score.append(score)\n",
    "        sort_result = torch.sort(torch.tensor(question_score), descending=True)\n",
    "        scores, index_list = sort_result[0], sort_result[1]\n",
    "\n",
    "        result_scores.append(scores.tolist())\n",
    "        result_indices.append(index_list.tolist())        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 점수 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_indices = []\n",
    "for i in range(len(doc_indices)) :\n",
    "    t_list = [doc_indices[i][result_indices[i][k]] for k in range(100)]\n",
    "    final_indices.append(t_list)\n",
    "\n",
    "elastic_indices = []\n",
    "for i in range(len(doc_indices)) :\n",
    "    t_list = [doc_indices[i][k] for k in range(100)]\n",
    "    elastic_indices.append(t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1776fd708ae34309a6104f71aa37dda3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "scaler = MinMaxScaler()\n",
    "scale_ce = []\n",
    "scale_elastic = []\n",
    "for ce, elastic in tqdm(zip(result_scores, doc_scores)) :\n",
    "    temp_ce = np.array(ce).reshape(-1, 1)\n",
    "    temp_el = np.array(elastic).reshape(-1, 1)\n",
    "    scale_ce.append(scaler.fit_transform(temp_ce).reshape(-1).tolist())\n",
    "    scale_elastic.append(scaler.fit_transform(temp_el).reshape(-1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_scores = []\n",
    "real_indices = []\n",
    "for i in range(len(scale_ce)) :\n",
    "    doc = {}\n",
    "    for j in range(len(scale_ce[0])) :\n",
    "        doc[final_indices[i][j]] = scale_ce[i][j] * 3\n",
    "    \n",
    "    for j in range(len(scale_elastic[0])) :\n",
    "        if doc_indices[i][j] in doc.keys() :\n",
    "            doc[doc_indices[i][j]] += scale_elastic[i][j]\n",
    "    doc = dict(sorted(doc.items(), key = lambda x: x[1], reverse = True))\n",
    "    real_scores.append(list(doc.values()))\n",
    "    real_indices.append(list(doc.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_end_indices = []\n",
    "for i in range(len(real_indices)) :\n",
    "    t_list = [real_indices[i][k] for k in range(4)]\n",
    "    the_end_indices.append(t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7234e0911ce4f988fd070bd556f3881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dense retrieval: ', max=600.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final = []\n",
    "for idx, example in enumerate(\n",
    "        tqdm(dataset['validation'], desc=\"Dense retrieval: \")\n",
    "    ):\n",
    "        tmp = {\n",
    "            # Query와 해당 id를 반환합니다.\n",
    "            \"question\": example[\"question\"],\n",
    "            \"id\": example[\"id\"],\n",
    "            # Retrieve한 Passage의 id, context를 반환합니다.\n",
    "            \"context_id\": the_end_indices[idx],\n",
    "            \"context\": \" \".join(  # 기존에는 ' '.join()\n",
    "                [corpus[pid] for pid in the_end_indices[idx]]\n",
    "            ),\n",
    "        }\n",
    "        if \"context\" in example.keys() and \"answers\" in example.keys():\n",
    "            # validation 데이터를 사용하면 ground_truth context와 answer도 반환합니다.\n",
    "            tmp[\"original_context\"] = example[\"context\"]\n",
    "            tmp[\"answers\"] = example[\"answers\"]\n",
    "        final.append(tmp)\n",
    "\n",
    "cqas_50 = pd.DataFrame(final)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elastic indices: [43280, 47081, 35064, 24024, 42242, 10509, 9781, 19993, 34043, 29886]\n",
      "cross encoder: [24024, 20956, 3674, 3674, 49784, 52764, 42242, 42244, 14130, 29886]\n",
      "ensemble: [24024, 42242, 47081, 3674, 42244, 43280, 35064, 29886, 20956, 9781]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print('elastic indices:', doc_indices[i][:10])\n",
    "print('cross encoder:', final_indices[i][:10])\n",
    "print('ensemble:', real_indices[i][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "cqas_50.to_csv('test_retrieval_elastic_cross_ensemble_4_one_on_three.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
